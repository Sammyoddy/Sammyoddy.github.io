[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\nSAMMY ODEYEMI\n",
    "section": "",
    "text": "SAMMY ODEYEMI\n\n\n\n\nHi!, I am a grounded and goal-oriented Computer Science professional with demonstrated expertise in Data Analytics. Skilled in SQL, R, and Power BI,\n\n\nI specialize in transforming complex data into clear insights for informed decision-making.\n\n\n\nMy Portfolio\n\n\n\nExcel Projects\n\n\n\n\n\n\n\n  \n    \n  \n  \n    This is an Analysis on Read-A-Lot Bookstore data for the year 2023. The company specializes in the sales of books. I employed Microsoft Excel to perform various operations, ranging from data cleaning up to visualization.\n  \n  View Project\n  \n\n\n\n\n\n  \n    \n  \n  \n    This is an Analysis on Quantum Sales Solutions data for the year 2023. The company specializes in the sales of edible products. I employed Microsoft Excel to perform various operations, ranging from data cleaning up to visualization.\n  \n  View Project\n  \n\n\n\n\n\n  \n    \n  \n  \n    This is an Analysis on the Israel-Palestine conflict and the fatalities that occurred. I employed Microsoft Excel to perform various operations, ranging from data cleaning to visualization.\n  \n  View Project\n  \n\n\n\n\n\n  \n    \n    \n  \n    This is a Video Game Sales Analysis for Synergy Ltd. I employed Microsoft Excel to perform various operations, ranging from data cleaning to visualization.\n  \n  View Project\n  \n\n\n\n\n\n\nR Projects\n\n\n\n\n   \n   \n    \n   \nThis is a Data Cleaning Project for Audible. I employed R and RStudio to perform Data Cleaning, and took it a nudge further by analysing and making Visualizations.     \nView Project    \n\n\n```{quarto-collapsible} ## Your H2 Heading Your content goes here."
  },
  {
    "objectID": "audible/audible.html#authornarrator",
    "href": "audible/audible.html#authornarrator",
    "title": "audible",
    "section": "Author and Narrator Columns",
    "text": "Author and Narrator Columns\nThe Author and Narrator columns contain the names of the Authors and Narrators of the Audiobooks.\n\n#select Author and Narrator columns\naudible %&gt;% select(author,narrator) %&gt;% head(10) %&gt;%kable()\n\n\n\n\nauthor\nnarrator\n\n\n\n\nWrittenby:GeronimoStilton\nNarratedby:BillLobely\n\n\nWrittenby:RickRiordan\nNarratedby:RobbieDaymond\n\n\nWrittenby:JeffKinney\nNarratedby:DanRussell\n\n\nWrittenby:RickRiordan\nNarratedby:SoneelaNankani\n\n\nWrittenby:RickRiordan\nNarratedby:JesseBernstein\n\n\nWrittenby:SuzanneCollins\nNarratedby:TatianaMaslany\n\n\nWrittenby:WinterMorgan\nNarratedby:LukeDaniels\n\n\nWrittenby:RickRiordan\nNarratedby:RobbieDaymond\n\n\nWrittenby:MaryPopeOsborne\nNarratedby:MaryPopeOsborne\n\n\nWrittenby:RickRiordan\nNarratedby:RobbieDaymond\n\n\n\n\n\nThese columns in the dataset have a common issue known as string concatenation errors. This occurs when two or more strings are joined together without appropriate spacing or delimiters. In this case, the names of authors and narrators are concatenated without spaces, making it difficult to distinguish between first and last names.\nAdditionally, the strings ‚ÄòWrittenby:‚Äô and ‚ÄòNarratedby:‚Äô are concatenated with the names, adding unnecessary clutter to our data; hence the need to remove unnecessary strings and add spaces between the names using regular expressions.\n\n\n#author and narrator column cleaned of unwanted characters and spaces added where necessary\naudible&lt;-audible %&gt;%mutate_at(vars(author,narrator),\n  ~if_else(str_detect(.,\"(Writtenby:)|(Narratedby:)\"),\n        str_replace_all(str_remove(.,\"(Writtenby:)|(Narratedby:)|\\\\d+\"),\n                        \"(?&lt;=[a-z])(?=[A-Z])\", \" \"),\n        .)\n  )\n\n\ncross-check\nIt becomes important to check the content of these columns after performing the operation\n\n\naudible %&gt;% select(author,narrator) %&gt;% head(5) %&gt;% kable()\n\n\n\n\nauthor\nnarrator\n\n\n\n\nGeronimo Stilton\nBill Lobely\n\n\nRick Riordan\nRobbie Daymond\n\n\nJeff Kinney\nDan Russell\n\n\nRick Riordan\nSoneela Nankani\n\n\nRick Riordan\nJesse Bernstein"
  },
  {
    "objectID": "audible/audible.html#time",
    "href": "audible/audible.html#time",
    "title": "audible",
    "section": "Time Column",
    "text": "Time Column\nThe Time column is the total duration of each audiobook\n\naudible %&gt;% select(time) %&gt;% head(5) %&gt;%kable()\n\n\n\n\ntime\n\n\n\n\n2 hrs and 20 mins\n\n\n13 hrs and 8 mins\n\n\n2 hrs and 3 mins\n\n\n11 hrs and 16 mins\n\n\n10 hrs\n\n\n\n\n\nIt is a column of string datatype and the contents are needed to be extracted and typecasted to numeric values to aid further analysis.\n\n# Create new columns off the time column and typecast to numeric \naudible &lt;- audible %&gt;%\n  mutate(\n    # Extract hours and minutes into separate columns\n    hours = as.numeric(str_extract(time, \"\\\\d+(?=\\\\s*hr)\")),\n    minutes = as.numeric(str_extract(time, \"\\\\d+(?=\\\\s*min)\")),\n    \n    # Convert time to seconds\n    time_seconds = case_when(\n      str_detect(time, \"hrs|hr\") & !str_detect(time, \"mins|min\") ~\n        as.numeric(str_extract(time, \"\\\\d+(?=\\\\s*hr)\")) * 3600,\n      str_detect(time, \"hrs|hr\") & str_detect(time, \"min|mins\") ~\n        as.numeric(str_extract(time, \"\\\\d+(?=\\\\s*hr)\")) * 3600 +\n        as.numeric(str_extract(time, \"\\\\d+(?=\\\\s*min)\")) * 60,\n      str_detect(time, \"mins|min\") ~\n        as.numeric(str_extract(time, \"\\\\d+\")) * 60,\n      TRUE ~ as.numeric(time)\n    )\n  )\n\nWarning: There was 1 warning in `mutate()`.\n‚Ñπ In argument: `time_seconds = case_when(...)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\n\n\n\n\n\n\nNA values\n\n\n\nThe NA values are introduced because there are some observations that may not have either hours or minutes. In such instances, since there is no hour or minute to extract as the case may be, the newly created ‚Äòhours‚Äô or ‚Äòminutes‚Äô columns return NA. This is a common occurrence in data processing when the expected data is not present in certain observations. And to handle such instances, NA values are replaced with zero\n\n\n\n# Handle NA values (if there are cases like \"2 hours\" with no mins or \"45 mins\" with no hours)\naudible$hours[is.na(audible$hours)] &lt;- 0\naudible$minutes[is.na(audible$minutes)] &lt;- 0 \n\ncross-check\n\naudible %&gt;% select(time,hours,minutes,time_seconds) %&gt;% head(6) %&gt;% kable()\n\n\n\n\ntime\nhours\nminutes\ntime_seconds\n\n\n\n\n2 hrs and 20 mins\n2\n20\n8400\n\n\n13 hrs and 8 mins\n13\n8\n47280\n\n\n2 hrs and 3 mins\n2\n3\n7380\n\n\n11 hrs and 16 mins\n11\n16\n40560\n\n\n10 hrs\n10\n0\n36000\n\n\n10 hrs and 35 mins\n10\n35\n38100"
  },
  {
    "objectID": "audible/audible.html#releasedate",
    "href": "audible/audible.html#releasedate",
    "title": "audible",
    "section": "Release Date Column",
    "text": "Release Date Column\nThe Release Date Column just as the name implies is the release date of each and every audiobook contained in the dataset.\n\naudible %&gt;% select(releasedate) %&gt;% head(5) %&gt;% kable()\n\n\n\n\nreleasedate\n\n\n\n\n04-08-08\n\n\n01-05-18\n\n\n06-11-20\n\n\n05-10-21\n\n\n13-01-10\n\n\n\n\n\nIt is of string datatype, hence the need to convert to Date in its truest form.\n\n#converted releasedate column of data type string to date as should be\naudible$releasedate&lt;- as.Date(audible$releasedate,format=\"%d-%m-%y\")\n#Extract the Year COlumn from the releasedate Column\naudible&lt;-audible %&gt;%mutate(Year=year(audible$releasedate))"
  },
  {
    "objectID": "audible/audible.html#stars",
    "href": "audible/audible.html#stars",
    "title": "audible",
    "section": "Stars Column",
    "text": "Stars Column\nThe Stars Column represents the average rating given by users for a particular audiobook. It has a band of 1 to 5. But during scraping of the data, the rating was scraped into the same column as the stars bringing about a string concatenation error. There should be a separate rating column that represents the number of users who have rated the audiobook.\n\naudible %&gt;% select(stars) %&gt;% head(6)\n\n# A tibble: 6 √ó 1\n  stars                        \n  &lt;chr&gt;                        \n1 5 out of 5 stars34 ratings   \n2 4.5 out of 5 stars41 ratings \n3 4.5 out of 5 stars38 ratings \n4 4.5 out of 5 stars12 ratings \n5 4.5 out of 5 stars181 ratings\n6 5 out of 5 stars72 ratings   \n\n\n\n#split stars column into Stars and Rating Column,remove unwanted characters and convert columns to numeric \n  audible &lt;- audible %&gt;% \n    separate(stars, into = c(\"Stars\", \"Rating\"), sep = \"out of 5 stars\") %&gt;% \n    mutate(\n      Stars = as.numeric(str_remove_all(Stars, \" \")),\n      Rating = as.numeric(str_remove_all(Rating, \",|ratings\"))\n    ) %&gt;% \n    mutate_at(\n      vars(Stars, Rating),\n      ~if_else(is.na(.), 0, .)\n    )\n\ncross-check\n\naudible %&gt;% select(Stars,Rating) %&gt;% head(7) %&gt;% kable()\n\n\n\n\nStars\nRating\n\n\n\n\n5.0\n34\n\n\n4.5\n41\n\n\n4.5\n38\n\n\n4.5\n12\n\n\n4.5\n181\n\n\n5.0\n72\n\n\n5.0\n11"
  },
  {
    "objectID": "audible/audible.html#price-column",
    "href": "audible/audible.html#price-column",
    "title": "audible",
    "section": "Price Column",
    "text": "Price Column\nThe Price column represents the price of the audiobook.\n\naudible %&gt;% select(price) %&gt;% head(10) \n\n# A tibble: 10 √ó 1\n   price   \n   &lt;chr&gt;   \n 1 468.00  \n 2 820.00  \n 3 410.00  \n 4 615.00  \n 5 820.00  \n 6 656.00  \n 7 233.00  \n 8 820.00  \n 9 1,256.00\n10 820.00  \n\n\nThis column is of string datatype and it has some unwanted characters such as the , and Free indicating that these books come at no cost at all.\n\naudible %&gt;% select(price) %&gt;% filter(price==\"Free\")%&gt;% head(3)\n\n# A tibble: 3 √ó 1\n  price\n  &lt;chr&gt;\n1 Free \n2 Free \n3 Free \n\n\nIt is imperative to remove these characters and typecast the data type\n\n  audible &lt;- audible %&gt;% mutate(\n    price = case_when(\n      str_detect(price, \",\") ~ as.numeric(str_remove(price, \",\")),\n      str_detect(price, \"Free\") ~ as.numeric(str_remove(price, \"Free\")),\n      TRUE ~ as.numeric(price)\n    ),price=if_else(is.na(price),0,price)\n  )\n\ncross-check\n\naudible %&gt;% select(price) %&gt;% head(10)\n\n# A tibble: 10 √ó 1\n   price\n   &lt;dbl&gt;\n 1   468\n 2   820\n 3   410\n 4   615\n 5   820\n 6   656\n 7   233\n 8   820\n 9  1256\n10   820"
  },
  {
    "objectID": "audible/audible.html#subsetting",
    "href": "audible/audible.html#subsetting",
    "title": "audible",
    "section": "Subsetting Needed Columns",
    "text": "Subsetting Needed Columns\nSelecting useful columns\n\naudible %&gt;% select(name:time,hours:time_seconds,releasedate,Year,language,Stars:price) %&gt;% head(10) %&gt;% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nauthor\nnarrator\ntime\nhours\nminutes\ntime_seconds\nreleasedate\nYear\nlanguage\nStars\nRating\nprice\n\n\n\n\nGeronimo Stilton #11 & #12\nGeronimo Stilton\nBill Lobely\n2 hrs and 20 mins\n2\n20\n8400\n2008-08-04\n2008\nEnglish\n5.0\n34\n468\n\n\nThe Burning Maze\nRick Riordan\nRobbie Daymond\n13 hrs and 8 mins\n13\n8\n47280\n2018-05-01\n2018\nEnglish\n4.5\n41\n820\n\n\nThe Deep End\nJeff Kinney\nDan Russell\n2 hrs and 3 mins\n2\n3\n7380\n2020-11-06\n2020\nEnglish\n4.5\n38\n410\n\n\nDaughter of the Deep\nRick Riordan\nSoneela Nankani\n11 hrs and 16 mins\n11\n16\n40560\n2021-10-05\n2021\nEnglish\n4.5\n12\n615\n\n\nThe Lightning Thief: Percy Jackson, Book 1\nRick Riordan\nJesse Bernstein\n10 hrs\n10\n0\n36000\n2010-01-13\n2010\nEnglish\n4.5\n181\n820\n\n\nThe Hunger Games: Special Edition\nSuzanne Collins\nTatiana Maslany\n10 hrs and 35 mins\n10\n35\n38100\n2018-10-30\n2018\nEnglish\n5.0\n72\n656\n\n\nQuest for the Diamond Sword\nWinter Morgan\nLuke Daniels\n2 hrs and 23 mins\n2\n23\n8580\n2014-11-25\n2014\nEnglish\n5.0\n11\n233\n\n\nThe Dark Prophecy\nRick Riordan\nRobbie Daymond\n12 hrs and 32 mins\n12\n32\n45120\n2017-05-02\n2017\nEnglish\n5.0\n50\n820\n\n\nMerlin Mission Collection\nMary Pope Osborne\nMary Pope Osborne\n10 hrs and 56 mins\n10\n56\n39360\n2017-05-02\n2017\nEnglish\n5.0\n5\n1256\n\n\nThe Tyrant‚Äôs Tomb\nRick Riordan\nRobbie Daymond\n13 hrs and 22 mins\n13\n22\n48120\n2019-09-24\n2019\nEnglish\n5.0\n58\n820"
  },
  {
    "objectID": "audible/audible.html#data-validity",
    "href": "audible/audible.html#data-validity",
    "title": "audible",
    "section": "Data Validity",
    "text": "Data Validity\nThis is measure to ensure that all columns have the right datatype\n\naudible %&gt;% str()\n\ntibble [87,489 √ó 13] (S3: tbl_df/tbl/data.frame)\n $ name        : chr [1:87489] \"Geronimo Stilton #11 & #12\" \"The Burning Maze\" \"The Deep End\" \"Daughter of the Deep\" ...\n $ author      : chr [1:87489] \"Geronimo Stilton\" \"Rick Riordan\" \"Jeff Kinney\" \"Rick Riordan\" ...\n $ narrator    : chr [1:87489] \"Bill Lobely\" \"Robbie Daymond\" \"Dan Russell\" \"Soneela Nankani\" ...\n $ time        : chr [1:87489] \"2 hrs and 20 mins\" \"13 hrs and 8 mins\" \"2 hrs and 3 mins\" \"11 hrs and 16 mins\" ...\n $ releasedate : Date[1:87489], format: \"2008-08-04\" \"2018-05-01\" ...\n $ language    : chr [1:87489] \"English\" \"English\" \"English\" \"English\" ...\n $ Stars       : num [1:87489] 5 4.5 4.5 4.5 4.5 5 5 5 5 5 ...\n $ Rating      : num [1:87489] 34 41 38 12 181 72 11 50 5 58 ...\n $ price       : num [1:87489] 468 820 410 615 820 ...\n $ hours       : num [1:87489] 2 13 2 11 10 10 2 12 10 13 ...\n $ minutes     : num [1:87489] 20 8 3 16 0 35 23 32 56 22 ...\n $ time_seconds: num [1:87489] 8400 47280 7380 40560 36000 ...\n $ Year        : num [1:87489] 2008 2018 2020 2021 2010 ..."
  },
  {
    "objectID": "audible/audible.html#saving-the-data",
    "href": "audible/audible.html#saving-the-data",
    "title": "audible",
    "section": "Saving the Data",
    "text": "Saving the Data\n\nwrite.csv(audible,\"C:/Users/SAMMY/Desktop/Audible/audible_cleaned.csv\")"
  },
  {
    "objectID": "audible/audible.html#top-5-authors-on-audible",
    "href": "audible/audible.html#top-5-authors-on-audible",
    "title": "audible",
    "section": "Top 5 Authors on Audible",
    "text": "Top 5 Authors on Audible\n\n# Filter top 5 authors\ntop_authors &lt;- audible %&gt;%\n  group_by(author) %&gt;%\n  summarise(n = n()) %&gt;%\n  arrange(n) %&gt;%\n  top_n(5)\n\nSelecting by n\n\n# Bar plot of top 5 Audible Authors\nggplot(top_authors, aes(x = reorder(author, n), y = n, fill = author)) +\n  geom_bar(stat = \"identity\") +\n   geom_text(aes(label = n), hjust = -0.1, color = \"black\", size = 3.5) +\n  scale_fill_manual(values = c(\"Áü¢Â≥∂ÈõÖÂºò,Áü≥Ê©ãÈÅä\"=\"#FFA000\",\"Smart Reading\"=\"#FFB347\",\"‰∏≠Ë•øË≤¥‰πã,BJ\"=\"#FFC680\",\"div.\"=\"#FFDAB3\",\"Online Studio Productions\"=\"#FFEFE0\")) +\n  coord_flip() +\n  labs(x = \"Author\", y = \"Book Count\", title = \"Top 5 Authors in Audible Dataset\") +\n  theme_classic() +\n  theme(legend.position = \"none\",plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "audible/audible.html#distribution-of-star-rating",
    "href": "audible/audible.html#distribution-of-star-rating",
    "title": "audible",
    "section": "Distribution of Star Rating",
    "text": "Distribution of Star Rating\n\nstar_summary &lt;- audible %&gt;%\n  group_by(Stars) %&gt;%\n  summarise(count = n()) %&gt;%\n  arrange(desc(Stars))\n\n# Create the bar plot\nggplot(star_summary, aes(x =reorder(Stars,Stars), y = count)) +\n  geom_bar(stat = \"identity\", fill = \"#FFA000\", color = \"#000000\") +\n  geom_text(aes(label = count), vjust = -.5,hjust=0.5, color= \"black\", size = 3.5)+\n  labs(x = \"Star Rating\", y = \"Count\", title = \"Distribution of Star Ratings\") +\n  theme_classic() +\n  theme(plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "audible/audible.html#heatmap-of-books-released-by-year",
    "href": "audible/audible.html#heatmap-of-books-released-by-year",
    "title": "audible",
    "section": "Heatmap of Books Released By Year",
    "text": "Heatmap of Books Released By Year\n\nunique_years &lt;- unique(audible$Year)\nyear_summary &lt;- audible %&gt;%\n  group_by(Year) %&gt;%\n  summarise(count = n()) %&gt;%\n  arrange(Year)\n\n# Create the heatmap\nggplot(year_summary, aes(x = \"\", y = Year, fill = count)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient(low = \"linen\", high = \"#FFA000\") +\n  geom_text(aes(label = count), vjust = 0.5, hjust = 1,color = \"black\", size = 2.8,alpha=1)+\n  scale_y_continuous(breaks = unique_years)+\n  labs(x = \"Book Count\", y = \"Year\", title = \"Heatmap of Books Released Each Year\") +\n  theme_classic() +\n  theme(plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Excel Projects/SYNERGY VIDEO GAME/synergy.html",
    "href": "Excel Projects/SYNERGY VIDEO GAME/synergy.html",
    "title": "synergy sales",
    "section": "",
    "text": "In this data analysis project, I delve into the fascinating world of video game sales at Synergy Sales. The goal is to explore trends, patterns, and insights related to video game sales worldwide. The dataset spans from 1980 to 2020, covering various regions, genres, and gaming platforms. By meticulously analyzing this data, I aim to provide valuable business insights for Synergy Ltd.\n\n\n\nThe analysis revolves around answering critical questions:\n\nWhich market has the highest video game sales from 1980 to 2016?\nWhat are the total sales of the top 5 game genres and top 5 platforms worldwide during this period?\nWhich game genres dominated different regions from 1980 to 2020?\nHow did the total sales trend evolve globally during specific time periods?\n\n\n\n\nThe dataset used is sourced from Kaggle and contains information on video games with sales exceeding 100,000 copies. It includes essential fields such as:\n\nRank: Overall sales ranking\nName: Game title\nPlatform: Release platform (e.g., PC, PS4)\nYear: Year of the game‚Äôs release\n\n\n\n\nI followed a structured approach, adhering to the six steps of the data analysis process:\n\nAsk: I defined the problem, communicated with stakeholders, and understood the business context. Synergy Ltd.¬†requested an interactive dashboard showcasing game sales trends by region, genre, and platform.\nPrepare: I obtained the dataset, ensuring data integrity and cleanliness. Our primary analysis occurred on a duplicate worksheet to preserve the original data.\nProcess: I cleaned and transformed the data, preparing it for visualization.\nShare: I created an interactive dashboard in Excel, allowing users to explore sales trends based on their preferences.\nAnalyze: I visualized the data, identifying patterns and drawing meaningful conclusions.\nAct: Our insights informed strategic decisions for Synergy Ltd.\n\n\n\n\nOur interactive dashboard fulfills the following requirements:\n\nUsers can select specific years, regions, platforms, and genres to compare sales trends.\nThe dashboard displays the top 5 game genres and platforms by sales, corresponding to the chosen criteria.\nIt provides the percentage of sales for genres and platforms based on selected years and regions among other things.\n\n\n\n\n\n\n\n\n\n\nIn conclusion, the video game sales analysis for Synergy Ltd.¬†has yielded valuable insights into the gaming industry:\n\nInsights:\n\nNorth America dominated video game sales and Europe and Japan follow closely.\nAction and Sports genres lead in sales.\nPlayStation and Xbox platforms remain popular globally.\nSales reached a peak in the year 2008 at $678.9M, followed by gradual decline."
  },
  {
    "objectID": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#introduction",
    "href": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#introduction",
    "title": "Video Game Sales Analysis for Synergy Ltd.",
    "section": "Introduction",
    "text": "Introduction\nIn this data analytics project, I delve into the fascinating world of video game sales at Synergy Sales. The goal is to explore trends, patterns, and insights related to video game sales worldwide. The dataset spans from 1980 to 2020, covering various regions, genres, and gaming platforms. By meticulously analyzing this data, I aim to provide valuable business insights for Synergy Ltd."
  },
  {
    "objectID": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#overview",
    "href": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#overview",
    "title": "Video Game Sales Analysis for Synergy Ltd.",
    "section": "Overview",
    "text": "Overview\nThe analysis revolves around answering critical questions:\n\nWhich market has the highest video game sales from 1980 to 2020?\nWhat are the total sales of the top 5 game genres and top 5 platforms worldwide during this period?\nWhich game genres dominated different regions from 1980 to 2020?\nHow did the total sales trend evolve globally during specific time periods?"
  },
  {
    "objectID": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#data-source",
    "href": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#data-source",
    "title": "Video Game Sales Analysis for Synergy Ltd.",
    "section": "Data Source",
    "text": "Data Source\nThe dataset used is sourced from Kaggle and contains information on video games with sales exceeding 16,000 copies. It includes essential fields such as:\n\nRank: Overall sales ranking\nName: Game title\nPlatform: Release platform (e.g., PC, PS4)\nYear: Year of the game‚Äôs release"
  },
  {
    "objectID": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#methodology",
    "href": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#methodology",
    "title": "Video Game Sales Analysis for Synergy Ltd.",
    "section": "Methodology",
    "text": "Methodology\nI followed a structured approach, adhering to the six steps of the data analysis process:\n\nAsk: I defined the problem, communicated with stakeholders, and understood the business context. Synergy Ltd.¬†requested an interactive dashboard showcasing game sales trends by region, genre, and platform.\nPrepare: I obtained the dataset, ensuring data integrity and cleanliness. Our primary analysis occurred on a duplicate worksheet to preserve the original data.\nProcess: I cleaned and transformed the data, preparing it for visualization.\nShare: I created an interactive dashboard in Excel, allowing users to explore sales trends based on their preferences.\nAnalyze: I visualized the data, identifying patterns and drawing meaningful conclusions.\nAct: Our insights informed strategic decisions for Synergy Ltd.\nExamine the Dataset\nA peek into the data; the first 10 rows of data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRank\nName\nPlatform\nYear\nGenre\nPublisher\nNA_Sales\nEU_Sales\nJP_Sales\nOther_Sales\nGlobal_Sales\n\n\n\n\n1\nWii Sports\nWii\n2006\nSports\nNintendo\n$41,490,000\n$29,020,000\n$3,770,000.00\n$8,460,000\n$82,740,000\n\n\n2\nSuper Mario Bros.\nNES\n1985\nPlatform\nNintendo\n$29,080,000\n$3,580,000\n$6,810,000.00\n$770,000\n$40,240,000\n\n\n3\nMario Kart Wii\nWii\n2008\nRacing\nNintendo\n$15,850,000\n$12,880,000\n$3,790,000.00\n$3,310,000\n$35,820,000\n\n\n4\nWii Sports Resort\nWii\n2009\nSports\nNintendo\n$15,750,000\n$11,010,000\n$3,280,000.00\n$2,960,000\n$33,000,000\n\n\n5\nPokemon Red/Pokemon Blue\nGB\n1996\nRole-Playing\nNintendo\n$11,270,000\n$8,890,000\n$10,220,000.00\n$1,000,000\n$31,370,000\n\n\n6\nTetris\nGB\n1989\nPuzzle\nNintendo\n$23,200,000\n$2,260,000\n$4,220,000.00\n$580,000\n$30,260,000\n\n\n7\nNew Super Mario Bros.\nDS\n2006\nPlatform\nNintendo\n$11,380,000\n$9,230,000\n$6,500,000.00\n$2,900,000\n$30,010,000\n\n\n8\nWii Play\nWii\n2006\nMisc\nNintendo\n$14,030,000\n$9,200,000\n$2,930,000.00\n$2,850,000\n$29,020,000\n\n\n9\nNew Super Mario Bros.¬†Wii\nWii\n2009\nPlatform\nNintendo\n$14,590,000\n$7,060,000\n$4,700,000.00\n$2,260,000\n$28,620,000\n\n\n10\nDuck Hunt\nNES\n1984\nShooter\nNintendo\n$26,930,000\n$630,000\n$280,000.00\n$470,000\n$28,310,000"
  },
  {
    "objectID": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#key-dashboard-requirements",
    "href": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#key-dashboard-requirements",
    "title": "Video Game Sales Analysis for Synergy Ltd.",
    "section": "Key Dashboard Requirements",
    "text": "Key Dashboard Requirements\nOur interactive dashboard fulfills the following requirements:\n\nUsers can select specific years, regions, platforms, and genres to compare sales trends.\nThe dashboard displays the top 5 game genres and platforms by sales, corresponding to the chosen criteria.\nIt provides the percentage of sales for genres and platforms based on selected years and regions among other things."
  },
  {
    "objectID": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#conclusion",
    "href": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#conclusion",
    "title": "Video Game Sales Analysis for Synergy Ltd.",
    "section": "Conclusion",
    "text": "Conclusion\nIn conclusion, the video game sales analysis for Synergy Ltd.¬†has yielded valuable insights into the gaming industry:\n\nInsights:\n\nNorth America dominated video game sales and Europe and Japan follow closely.\nAction and Sports genres lead in sales.\nPlayStation and Xbox platforms remain popular globally.\nSales reached a peak in the year 2008 at $678.9M, followed by gradual decline."
  },
  {
    "objectID": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#dashboard",
    "href": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#dashboard",
    "title": "Video Game Sales Analysis for Synergy Ltd.",
    "section": "Dashboard",
    "text": "Dashboard"
  },
  {
    "objectID": "Excel Projects/ISRPAL/isrpal.html",
    "href": "Excel Projects/ISRPAL/isrpal.html",
    "title": "FATALITIES IN THE ISRAEL-PALESTINE CONFLICT: 2000-2023 ANALYSIS",
    "section": "",
    "text": "The Israel-Palestine conflict has spanned decades, resulting in significant loss of life. The analysis aims to explore fatality trends, identify patterns, and provide insights based on the available data.\nThe Israel-Palestine conflict from 2000 to 2023 was a period marked by significant events and escalating tensions.This period was characterized by a cycle of violence and attempts at peace negotiations. It‚Äôs important to note that this is a complex issue with deep historical roots and differing narratives.The specific causes of the conflict during 2000-2003 are multifaceted and include:\n1. Al-Aqsa Intifada (2000)\n2. Failed Peace Negotiations (2000)\n3. Political Changes (2001)\n4. Violence and Retaliation (2002)\n5. Roadmap for Peace (2003)\n\n\n\n\nData Source: The dataset, sourced from Kaggle, contains information about fatalities in the Israel-Palestine conflict. Each record represents an individual who lost their life during specific incidents.\nFields:\n\nDate: The date of the incident.\nLocation: Where the incident occurred (e.g., Gaza, West Bank).\nFatalities: The number of people killed.\nCitizenship:The Citizenship of fatalities recorded\nPerpetrator: The group responsible (e.g., IDF, Hamas).\nTarget: The affected group (e.g., civilians, militants)\n\n\n\n\n\n\nTemporal Trends: How have fatalities evolved over time? Are there specific periods of heightened violence?\nGeographical Patterns: Which regions (Gaza, West Bank, etc.) have experienced the most fatalities?\nPerpetrators and Targets: Who are the main perpetrators, and who bears the brunt of the violence (civilians, militants, etc.)?\n\n\n\n\n\n\n\n\n\nImportant!!!\n\n\n\nRight-click on image to open dashboard in new tab, if content too tiny"
  },
  {
    "objectID": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#section",
    "href": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#section",
    "title": "Video Game Sales Analysis for Synergy Ltd.",
    "section": "",
    "text": "Important!!!\n\n\n\nRight-click on image to open dashboard in new tab, if content too tiny\n\n\n\nTo interact with the Excel Dashboard, click here"
  },
  {
    "objectID": "Excel Projects/ISRPAL/isrpal.html#conclusion",
    "href": "Excel Projects/ISRPAL/isrpal.html#conclusion",
    "title": "Fatalities in the Israel-Palestine Conflict: 2000-2023 Analysis",
    "section": "Conclusion",
    "text": "Conclusion\nIn conclusion, the Israel-Palestine analysis has yielded valuable insights into the deaths recorded and how distributed they are:\n\nInsights:\n\nPalestinians suffered a high fatality count at 10,092 and only 1 American Died.\n2014 is peak year for highest death toll at 2326.\nOver 9000 people died by Gunfire losely followed by Explosion at 555\n\n\n\n\nThese insights can guide strategic decisions for conflict resolution efforts. üïäÔ∏èüåç"
  },
  {
    "objectID": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#recommendations",
    "href": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#recommendations",
    "title": "Video Game Sales Analysis for Synergy Ltd.",
    "section": "Recommendations",
    "text": "Recommendations\n1. Regions aside from Europe, Japan and North America should be looked into as to why Video Game purchases are not made and strategic marketing of these video games should be upped in the region\n2. I strongly advise that marketing and promotion be reinforced to resolve the issue of low sales for Game Genres and less purchased games.\n3. Collaborations with brands and sponsorship deals can help Game Platforms and Publishers with low sales."
  },
  {
    "objectID": "Excel Projects/ISRPAL/isrpal.html#introduction",
    "href": "Excel Projects/ISRPAL/isrpal.html#introduction",
    "title": "Fatalities in the Israel-Palestine Conflict: 2000-2023 Analysis",
    "section": "Introduction",
    "text": "Introduction\nThe Israel-Palestine conflict has spanned decades, resulting in significant loss of life. The analysis aims to explore fatality trends, identify patterns, and provide insights based on the available data.\nThe Israel-Palestine conflict from 2000 to 2023 was a period marked by significant events and escalating tensions.This period was characterized by a cycle of violence and attempts at peace negotiations. It‚Äôs important to note that this is a complex issue with deep historical roots and differing narratives.The specific causes of the conflict during 2000-2023 are multifaceted and include:\n1. Al-Aqsa Intifada (2000)\n2. Failed Peace Negotiations (2000)\n3. Political Changes (2001)\n4. Violence and Retaliation (2002)\n5. Roadmap for Peace (2003)\nBeyond 2003, the conflict persisted with sporadic violence, peace talks, and ongoing tensions. Efforts toward a lasting resolution continued, but obstacles remained, including territorial disputes, security concerns, and differing visions for the future."
  },
  {
    "objectID": "Excel Projects/ISRPAL/isrpal.html#methodology",
    "href": "Excel Projects/ISRPAL/isrpal.html#methodology",
    "title": "Fatalities in the Israel-Palestine Conflict: 2000-2023 Analysis",
    "section": "Methodology",
    "text": "Methodology\nI followed a structured approach, adhering to the six steps of the data analysis process:\n\nDefine Objective and Stakeholders: Clearly state the goal (analyze Israel-Palestine fatalities) and identify who needs this information (researchers, policymakers).\nCollect and Validate Data: Get the fatality dataset and ensure it‚Äôs accurate.\nClean and Transform Data: Fix any issues in the data and make it ready for analysis.\nCreate Interactive Dashboard: Build a user-friendly tool for exploring the data.\nVisualize Trends: Use charts to see patterns (e.g., fatalities over time).\nDraw Conclusions: Analyze findings (e.g., age disparities, regional impact).\nInform Decisions: Share insights to guide conflict resolution efforts. üåçüîç\nExamine the Dataset\nA peek into the data; the first 10 rows of data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\ndate_of_event\nage\ncitizenship\nevent_location\nevent_location_district\nevent_location_region\ndate_of_death\ngender\ntook_part_in_the_hostilities\nplace_of_residence\nplace_of_residence_district\ntype_of_injury\nammunition\nkilled_by\n\n\n\n\n‚ÄôAbd a-Rahman Suleiman Muhammad Abu Daghash\n24/09/2023\n32\nPalestinian\nNur Shams R.C.\nTulkarm\nWest Bank\n24/09/2023\nM\nNA\nNur Shams R.C.\nTulkarm\ngunfire\nlive ammunition\nIsraeli security forces\n\n\nUsayed Farhan Muhammad ‚ÄôAli Abu ‚ÄôAli\n24/09/2023\n21\nPalestinian\nNur Shams R.C.\nTulkarm\nWest Bank\n24/09/2023\nM\nNA\nNur Shams R.C.\nTulkarm\ngunfire\nlive ammunition\nIsraeli security forces\n\n\n‚ÄôAbdallah ‚ÄôImad Sa‚Äôed Abu Hassan\n22/09/2023\n16\nPalestinian\nKfar Dan\nJenin\nWest Bank\n22/09/2023\nM\nNA\nal-Yamun\nJenin\ngunfire\nlive ammunition\nIsraeli security forces\n\n\nDurgham Muhammad Yihya al-Akhras\n20/09/2023\n19\nPalestinian\n‚ÄôAqbat Jaber R.C.\nJericho\nWest Bank\n20/09/2023\nM\nNA\n‚ÄôAqbat Jaber R.C.\nJericho\ngunfire\nlive ammunition\nIsraeli security forces\n\n\nRaafat ‚ÄôOmar Ahmad Khamaisah\n19/09/2023\n15\nPalestinian\nJenin R.C.\nJenin\nWest Bank\n19/09/2023\nM\nNA\nJenin\nJenin\ngunfire\nlive ammunition\nIsraeli security forces\n\n\n‚ÄôAta Yasser ‚ÄôAta Musa\n19/09/2023\n29\nPalestinian\nJenin R.C.\nJenin\nWest Bank\n20/09/2023\nM\nNA\nJenin\nJenin\ngunfire\nmissile\nIsraeli security forces\n\n\nYusef Salem Yusef Radwan\n19/09/2023\n24\nPalestinian\nGaza City\nGaza\nGaza Strip\n19/09/2023\nM\nNo\nKhan Yunis\nKhan Yunis\ngunfire\nlive ammunition\nIsraeli security forces\n\n\nMahmoud Khaled S‚Äôud ‚ÄôAr‚Äôarawi\n19/09/2023\n25\nPalestinian\nJenin R.C.\nJenin\nWest Bank\n19/09/2023\nM\nNA\nJenin R.C.\nJenin\ngunfire\nmissile\nIsraeli security forces\n\n\nMahmoud ‚ÄôAli Nafe‚Äôa a-S‚Äôadi\n19/09/2023\n23\nPalestinian\nJenin R.C.\nJenin\nWest Bank\n19/09/2023\nM\nNA\nJenin R.C.\nJenin\ngunfire\nmissile\nIsraeli security forces\n\n\nMilad Munzer Wajih a-Ra‚Äôi\n09/09/2023\n15\nPalestinian\nal-‚ÄôArrub R.C.\nHebron\nWest Bank\n09/09/2023\nM\nNA\nal-‚ÄôArrub Camp\nHebron\ngunfire\nlive ammunition\nIsraeli security forces"
  },
  {
    "objectID": "Excel Projects/ISRPAL/isrpal.html#key-dashboard-requirements",
    "href": "Excel Projects/ISRPAL/isrpal.html#key-dashboard-requirements",
    "title": "Fatalities in the Israel-Palestine Conflict: 2000-2023 Analysis",
    "section": "Key Dashboard Requirements",
    "text": "Key Dashboard Requirements\n\nKey Questions\n\nTemporal Trends: How have fatalities evolved over time? Are there specific periods of heightened violence?\nGeographical Patterns: Which regions (Gaza, West Bank, etc.) have experienced the most fatalities?\nPerpetrators and Targets: Who are the main perpetrators, and who bears the brunt of the violence (civilians, militants, etc.)?"
  },
  {
    "objectID": "Excel Projects/ISRPAL/isrpal.html#overview",
    "href": "Excel Projects/ISRPAL/isrpal.html#overview",
    "title": "Fatalities in the Israel-Palestine Conflict: 2000-2023 Analysis",
    "section": "Overview",
    "text": "Overview\nData Source: The dataset, sourced from Kaggle, contains information about fatalities in the Israel-Palestine conflict. Each record represents an individual who lost their life during specific incidents.\nThis dataset on fatalities related to the Israel-Palestine conflict can be explored to gain insights such as :\nInsights:\n\nFatality Trends\nDemographic Analysis\nGeospatial Analysis\nHostilities Participation Analysis\nWeapons Used\nPerpetrator Profiles"
  },
  {
    "objectID": "Excel Projects/ISRPAL/isrpal.html#dashboard",
    "href": "Excel Projects/ISRPAL/isrpal.html#dashboard",
    "title": "Fatalities in the Israel-Palestine Conflict: 2000-2023 Analysis",
    "section": "Dashboard",
    "text": "Dashboard\n\n\n\n\n\n\n\nImportant!!!\n\n\n\nRight-click on image to open dashboard in new tab, if content too tiny\n\n\n\nTo interact with the Excel Dashboard, click here"
  },
  {
    "objectID": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#introduction",
    "href": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#introduction",
    "title": "Quantum Sales Solutions Analysis",
    "section": "Introduction",
    "text": "Introduction\nWelcome to the Quantum Sales Solutions dataset documentation! In this comprehensive guide, we explore the captivating world of beverage and snack sales, focusing on the year 2023. Whether you‚Äôre a data analyst, a business strategist, or simply curious about the flavors that defined that era, this documentation promises valuable insights."
  },
  {
    "objectID": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#overview",
    "href": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#overview",
    "title": "Quantum Sales Solutions Analysis",
    "section": "Overview",
    "text": "Overview\nQuantum Sales Solutions, a dynamic player in the market, orchestrates the distribution and delight of delectable treats. The dataset spans the year 2023 and encompasses a rich tapestry of products, regions, and consumer preferences. Let‚Äôs dive into the pixelated aisles of Quantum Sales Solutions and uncover the stories behind the sales for the year."
  },
  {
    "objectID": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#data-source",
    "href": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#data-source",
    "title": "Quantum Sales Solutions Analysis",
    "section": "Data Source",
    "text": "Data Source\nThe dataset for this project was meticulously collected by Quantum Sales Solutions. It captures transactions, quantities, and other relevant information related to beverages, dried fruits, nuts, candy, and soups.This dataset has been cleaned, organized, and prepared for analysis."
  },
  {
    "objectID": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#methodology",
    "href": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#methodology",
    "title": "Quantum Sales Solutions Analysis",
    "section": "Methodology",
    "text": "Methodology\nI followed a structured approach, adhering to the six steps of the data analysis process:\n\nAsk: I defined the problem, communicated with stakeholders, and understood the business context. Synergy Ltd.¬†requested an interactive dashboard showcasing game sales trends by region, genre, and platform.\nPrepare: I obtained the dataset, ensuring data integrity and cleanliness. Our primary analysis occurred on a duplicate worksheet to preserve the original data.\nProcess: I cleaned and transformed the data, preparing it for visualization.\nShare: I created an interactive dashboard in Excel, allowing users to explore sales trends based on their preferences.\nAnalyze: I visualized the data, identifying patterns and drawing meaningful conclusions.\nAct: Our insights informed strategic decisions for Synergy Ltd.\nExamine the Dataset\nA peek into the data; the first 10 rows of data:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOrder ID\nOrder Date\nCustomer ID\nCustomer Name\nAddress\nCity\nState\nZIP/Postal Code\nCountry/Region\nSalesperson\nRegion\nShipped Date\nShipper Name\nShip Name\nShip Address\nShip City\nShip State\nShip ZIP/Postal Code\nShip Country/Region\nPayment Type\nProduct Name\nCategory\nUnit Price\nQuantity\nRevenue\nShipping Fee\n\n\n\n\n1001\n01/27/14\n27\nCompany AA\n789 27th Street\nLas Vegas\nNV\n99999\nUSA\nMariya Sergienko\nWest\n01/29/14\nShipping Company B\nKaren Toh\n789 27th Street\nLas Vegas\nNV\n99999\nUSA\nCheck\nBeer\nBeverages\n$14.00\n49\n$686.00\n$66.54\n\n\n1002\n01/27/14\n27\nCompany AA\n789 27th Street\nLas Vegas\nNV\n99999\nUSA\nMariya Sergienko\nWest\n01/29/14\nShipping Company B\nKaren Toh\n789 27th Street\nLas Vegas\nNV\n99999\nUSA\nCheck\nDried Plums\nDried Fruit & Nuts\n$3.50\n47\n$164.50\n$16.61\n\n\n1003\n01/04/2014\n4\nCompany D\n123 4th Street\nNew York\nNY\n99999\nUSA\nAndrew Cencini\nEast\n01/06/2014\nShipping Company A\nChristina Lee\n123 4th Street\nNew York\nNY\n99999\nUSA\nCredit Card\nDried Pears\nDried Fruit & Nuts\n$30.00\n69\n$2,070.00\n$198.72\n\n\n1004\n01/04/2014\n4\nCompany D\n123 4th Street\nNew York\nNY\n99999\nUSA\nAndrew Cencini\nEast\n01/06/2014\nShipping Company A\nChristina Lee\n123 4th Street\nNew York\nNY\n99999\nUSA\nCredit Card\nDried Apples\nDried Fruit & Nuts\n$53.00\n89\n$4,717.00\n$448.12\n\n\n1005\n01/04/2014\n4\nCompany D\n123 4th Street\nNew York\nNY\n99999\nUSA\nAndrew Cencini\nEast\n01/06/2014\nShipping Company A\nChristina Lee\n123 4th Street\nNew York\nNY\n99999\nUSA\nCredit Card\nDried Plums\nDried Fruit & Nuts\n$3.50\n11\n$38.50\n$3.73\n\n\n1006\n01/12/2014\n12\nCompany L\n123 12th Street\nLas Vegas\nNV\n99999\nUSA\nMariya Sergienko\nWest\n01/14/14\nShipping Company B\nJohn Edwards\n123 12th Street\nLas Vegas\nNV\n99999\nUSA\nCredit Card\nChai\nBeverages\n$18.00\n81\n$1,458.00\n$141.43\n\n\n1007\n01/12/2014\n12\nCompany L\n123 12th Street\nLas Vegas\nNV\n99999\nUSA\nMariya Sergienko\nWest\n01/14/14\nShipping Company B\nJohn Edwards\n123 12th Street\nLas Vegas\nNV\n99999\nUSA\nCredit Card\nCoffee\nBeverages\n$46.00\n44\n$2,024.00\n$198.35\n\n\n1008\n01/08/2014\n8\nCompany H\n123 8th Street\nPortland\nOR\n99999\nUSA\nNancy Freehafer\nNorth\n01/10/2014\nShipping Company C\nElizabeth Andersen\n123 8th Street\nPortland\nOR\n99999\nUSA\nCredit Card\nChocolate Biscuits Mix\nBaked Goods & Mixes\n$9.20\n38\n$349.60\n$36.01\n\n\n1009\n01/04/2014\n4\nCompany D\n123 4th Street\nNew York\nNY\n99999\nUSA\nAndrew Cencini\nEast\n01/06/2014\nShipping Company C\nChristina Lee\n123 4th Street\nNew York\nNY\n99999\nUSA\nCheck\nChocolate Biscuits Mix\nBaked Goods & Mixes\n$9.20\n88\n$809.60\n$79.34\n\n\n1010\n01/29/14\n29\nCompany CC\n789 29th Street\nDenver\nCO\n99999\nUSA\nJan Kotas\nWest\n01/31/14\nShipping Company B\nSoo Jung Lee\n789 29th Street\nDenver\nCO\n99999\nUSA\nCheck\nChocolate\nCandy\n$12.75\n94\n$1,198.50\n$122.25"
  },
  {
    "objectID": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#key-dashboard-requirements",
    "href": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#key-dashboard-requirements",
    "title": "Quantum Sales Solutions Analysis",
    "section": "Key Dashboard Requirements",
    "text": "Key Dashboard Requirements\n\nOur interactive dashboard fulfills the following requirements:\n\nUsers can select Customers that patronize Quantum Sales Solutions, Regions, Products and Cities to compare sales trends.\nThe dashboard displays the top 7 Salespersons, Sales by Product Category corresponding to the chosen criteria."
  },
  {
    "objectID": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#dashboard",
    "href": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#dashboard",
    "title": "Quantum Sales Solutions Analysis",
    "section": "Dashboard",
    "text": "Dashboard\n\n\n\n\n\n\n\nImportant!!!\n\n\n\nRight-click on image to open dashboard in new tab, if content too tiny\n\n\n\nTo interact with the Excel Dashboard, click here"
  },
  {
    "objectID": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#recommendations",
    "href": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#recommendations",
    "title": "Quantum Sales Solutions Analysis",
    "section": "Recommendations",
    "text": "Recommendations\n\nRecognize top performers like Nancy Freehafer with rewards and provide training opportunities for those underperforming to improve their skills.\nPromote top-selling product categories more prominently, and analyze low-performing categories for potential improvements or discontinuation.\nDevelop growth strategies for regions that are underperforming like in the West and Increase investment in high-performing regions"
  },
  {
    "objectID": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#conclusion",
    "href": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#conclusion",
    "title": "Quantum Sales Solutions Analysis",
    "section": "Conclusion",
    "text": "Conclusion\nIn conclusion, the product sales analysis for Quantum Sales Solutions has yielded valuable insights into the sales for the year 2023:\n\nInsights:\n\nThe North had more Sales garnering 32% of total sales .\nBeverages sold the most at ‚Ç¶110,577\nDecember grossed highest sales by month at ‚Ç¶66,643\nSales for the year 2023 totaled the sum of ‚Ç¶435,036"
  },
  {
    "objectID": "R Projects/audible/audible.html#authornarrator",
    "href": "R Projects/audible/audible.html#authornarrator",
    "title": "Audible Data Cleaning",
    "section": "Author and Narrator Columns",
    "text": "Author and Narrator Columns\nThe Author and Narrator columns contain the names of the Authors and Narrators of the Audiobooks.\n\n#select Author and Narrator columns\naudible %&gt;% select(author,narrator) %&gt;% head(10) %&gt;%kable()\n\n\n\n\nauthor\nnarrator\n\n\n\n\nWrittenby:GeronimoStilton\nNarratedby:BillLobely\n\n\nWrittenby:RickRiordan\nNarratedby:RobbieDaymond\n\n\nWrittenby:JeffKinney\nNarratedby:DanRussell\n\n\nWrittenby:RickRiordan\nNarratedby:SoneelaNankani\n\n\nWrittenby:RickRiordan\nNarratedby:JesseBernstein\n\n\nWrittenby:SuzanneCollins\nNarratedby:TatianaMaslany\n\n\nWrittenby:WinterMorgan\nNarratedby:LukeDaniels\n\n\nWrittenby:RickRiordan\nNarratedby:RobbieDaymond\n\n\nWrittenby:MaryPopeOsborne\nNarratedby:MaryPopeOsborne\n\n\nWrittenby:RickRiordan\nNarratedby:RobbieDaymond\n\n\n\n\n\nThese columns in the dataset have a common issue known as string concatenation errors. This occurs when two or more strings are joined together without appropriate spacing or delimiters. In this case, the names of authors and narrators are concatenated without spaces, making it difficult to distinguish between first and last names.\nAdditionally, the strings ‚ÄòWrittenby:‚Äô and ‚ÄòNarratedby:‚Äô are concatenated with the names, adding unnecessary clutter to our data; hence the need to remove unnecessary strings and add spaces between the names using regular expressions.\n\n\n#author and narrator column cleaned of unwanted characters and spaces added where necessary\naudible&lt;-audible %&gt;%mutate_at(vars(author,narrator),\n  ~if_else(str_detect(.,\"(Writtenby:)|(Narratedby:)\"),\n        str_replace_all(str_remove(.,\"(Writtenby:)|(Narratedby:)|\\\\d+\"),\n                        \"(?&lt;=[a-z])(?=[A-Z])\", \" \"),\n        .)\n  )\n\n\ncross-check\nIt becomes important to check the content of these columns after performing the operation\n\n\naudible %&gt;% select(author,narrator) %&gt;% head(5) %&gt;% kable()\n\n\n\n\nauthor\nnarrator\n\n\n\n\nGeronimo Stilton\nBill Lobely\n\n\nRick Riordan\nRobbie Daymond\n\n\nJeff Kinney\nDan Russell\n\n\nRick Riordan\nSoneela Nankani\n\n\nRick Riordan\nJesse Bernstein"
  },
  {
    "objectID": "R Projects/audible/audible.html#time",
    "href": "R Projects/audible/audible.html#time",
    "title": "Audible Data Cleaning",
    "section": "Time Column",
    "text": "Time Column\nThe Time column is the total duration of each audiobook\n\naudible %&gt;% select(time) %&gt;% head(5) %&gt;%kable()\n\n\n\n\ntime\n\n\n\n\n2 hrs and 20 mins\n\n\n13 hrs and 8 mins\n\n\n2 hrs and 3 mins\n\n\n11 hrs and 16 mins\n\n\n10 hrs\n\n\n\n\n\nIt is a column of string datatype and the contents are needed to be extracted and typecasted to numeric values to aid further analysis.\n\n# Create new columns off the time column and typecast to numeric \naudible &lt;- audible %&gt;%\n  mutate(\n    # Extract hours and minutes into separate columns\n    hours = as.numeric(str_extract(time, \"\\\\d+(?=\\\\s*hr)\")),\n    minutes = as.numeric(str_extract(time, \"\\\\d+(?=\\\\s*min)\")),\n    \n    # Convert time to seconds\n    time_seconds = case_when(\n      str_detect(time, \"hrs|hr\") & !str_detect(time, \"mins|min\") ~\n        as.numeric(str_extract(time, \"\\\\d+(?=\\\\s*hr)\")) * 3600,\n      str_detect(time, \"hrs|hr\") & str_detect(time, \"min|mins\") ~\n        as.numeric(str_extract(time, \"\\\\d+(?=\\\\s*hr)\")) * 3600 +\n        as.numeric(str_extract(time, \"\\\\d+(?=\\\\s*min)\")) * 60,\n      str_detect(time, \"mins|min\") ~\n        as.numeric(str_extract(time, \"\\\\d+\")) * 60,\n      TRUE ~ as.numeric(time)\n    )\n  )\n\nWarning: There was 1 warning in `mutate()`.\n‚Ñπ In argument: `time_seconds = case_when(...)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\n\n\n\n\n\n\nNA values\n\n\n\nThe NA values are introduced because there are some observations that may not have either hours or minutes. In such instances, since there is no hour or minute to extract as the case may be, the newly created ‚Äòhours‚Äô or ‚Äòminutes‚Äô columns return NA. This is a common occurrence in data processing when the expected data is not present in certain observations. And to handle such instances, NA values are replaced with zero\n\n\n\n# Handle NA values (if there are cases like \"2 hours\" with no mins or \"45 mins\" with no hours)\naudible$hours[is.na(audible$hours)] &lt;- 0\naudible$minutes[is.na(audible$minutes)] &lt;- 0 \n\ncross-check\n\naudible %&gt;% select(time,hours,minutes,time_seconds) %&gt;% head(6) %&gt;% kable()\n\n\n\n\ntime\nhours\nminutes\ntime_seconds\n\n\n\n\n2 hrs and 20 mins\n2\n20\n8400\n\n\n13 hrs and 8 mins\n13\n8\n47280\n\n\n2 hrs and 3 mins\n2\n3\n7380\n\n\n11 hrs and 16 mins\n11\n16\n40560\n\n\n10 hrs\n10\n0\n36000\n\n\n10 hrs and 35 mins\n10\n35\n38100"
  },
  {
    "objectID": "R Projects/audible/audible.html#releasedate",
    "href": "R Projects/audible/audible.html#releasedate",
    "title": "Audible Data Cleaning",
    "section": "Release Date Column",
    "text": "Release Date Column\nThe Release Date Column just as the name implies is the release date of each and every audiobook contained in the dataset.\n\naudible %&gt;% select(releasedate) %&gt;% head(5) %&gt;% kable()\n\n\n\n\nreleasedate\n\n\n\n\n04-08-08\n\n\n01-05-18\n\n\n06-11-20\n\n\n05-10-21\n\n\n13-01-10\n\n\n\n\n\nIt is of string datatype, hence the need to convert to Date in its truest form.\n\n#converted releasedate column of data type string to date as should be\naudible$releasedate&lt;- as.Date(audible$releasedate,format=\"%d-%m-%y\")\n#Extract the Year COlumn from the releasedate Column\naudible&lt;-audible %&gt;%mutate(Year=year(audible$releasedate)) \n\n\nstr(audible$releasedate)\n\n Date[1:87489], format: \"2008-08-04\" \"2018-05-01\" \"2020-11-06\" \"2021-10-05\" \"2010-01-13\" ..."
  },
  {
    "objectID": "R Projects/audible/audible.html#stars",
    "href": "R Projects/audible/audible.html#stars",
    "title": "Audible Data Cleaning",
    "section": "Stars Column",
    "text": "Stars Column\nThe Stars Column represents the average rating given by users for a particular audiobook. It has a band of 1 to 5. But during scraping of the data, the rating was scraped into the same column as the stars bringing about a string concatenation error. There should be a separate rating column that represents the number of users who have rated the audiobook.\n\naudible %&gt;% select(stars) %&gt;% head(6)\n\n# A tibble: 6 √ó 1\n  stars                        \n  &lt;chr&gt;                        \n1 5 out of 5 stars34 ratings   \n2 4.5 out of 5 stars41 ratings \n3 4.5 out of 5 stars38 ratings \n4 4.5 out of 5 stars12 ratings \n5 4.5 out of 5 stars181 ratings\n6 5 out of 5 stars72 ratings   \n\n\n\n#split stars column into Stars and Rating Column,remove unwanted characters and convert columns to numeric \n  audible &lt;- audible %&gt;% \n    separate(stars, into = c(\"Stars\", \"Rating\"), sep = \"out of 5 stars\") %&gt;% \n    mutate(\n      Stars = as.numeric(str_remove_all(Stars, \" \")),\n      Rating = as.numeric(str_remove_all(Rating, \",|ratings\"))\n    ) %&gt;% \n    mutate_at(\n      vars(Stars, Rating),\n      ~if_else(is.na(.), 0, .)\n    )\n\ncross-check\n\naudible %&gt;% select(Stars,Rating) %&gt;% head(7) %&gt;% kable()\n\n\n\n\nStars\nRating\n\n\n\n\n5.0\n34\n\n\n4.5\n41\n\n\n4.5\n38\n\n\n4.5\n12\n\n\n4.5\n181\n\n\n5.0\n72\n\n\n5.0\n11"
  },
  {
    "objectID": "R Projects/audible/audible.html#price-column",
    "href": "R Projects/audible/audible.html#price-column",
    "title": "Audible Data Cleaning",
    "section": "Price Column",
    "text": "Price Column\nThe Price column represents the price of the audiobook.\n\naudible %&gt;% select(price) %&gt;% head(10) \n\n# A tibble: 10 √ó 1\n   price   \n   &lt;chr&gt;   \n 1 468.00  \n 2 820.00  \n 3 410.00  \n 4 615.00  \n 5 820.00  \n 6 656.00  \n 7 233.00  \n 8 820.00  \n 9 1,256.00\n10 820.00  \n\n\nThis column is of string datatype and it has some unwanted characters such as the , and Free indicating that these books come at no cost at all.\n\naudible %&gt;% select(price) %&gt;% filter(price==\"Free\")%&gt;% head(3)\n\n# A tibble: 3 √ó 1\n  price\n  &lt;chr&gt;\n1 Free \n2 Free \n3 Free \n\n\nIt is imperative to remove these characters and typecast the data type\n\n  audible &lt;- audible %&gt;% mutate(\n    price = case_when(\n      str_detect(price, \",\") ~ as.numeric(str_remove(price, \",\")),\n      str_detect(price, \"Free\") ~ as.numeric(str_remove(price, \"Free\")),\n      TRUE ~ as.numeric(price)\n    ),price=if_else(is.na(price),0,price)\n  )\n\ncross-check\n\naudible %&gt;% select(price) %&gt;% head(10)\n\n# A tibble: 10 √ó 1\n   price\n   &lt;dbl&gt;\n 1   468\n 2   820\n 3   410\n 4   615\n 5   820\n 6   656\n 7   233\n 8   820\n 9  1256\n10   820"
  },
  {
    "objectID": "R Projects/audible/audible.html#subsetting",
    "href": "R Projects/audible/audible.html#subsetting",
    "title": "Audible Data Cleaning",
    "section": "Subsetting Needed Columns",
    "text": "Subsetting Needed Columns\nSelecting useful columns\n\naudible %&gt;% select(name:time,hours:time_seconds,releasedate,Year,language,Stars:price) %&gt;% head(10) %&gt;% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nauthor\nnarrator\ntime\nhours\nminutes\ntime_seconds\nreleasedate\nYear\nlanguage\nStars\nRating\nprice\n\n\n\n\nGeronimo Stilton #11 & #12\nGeronimo Stilton\nBill Lobely\n2 hrs and 20 mins\n2\n20\n8400\n2008-08-04\n2008\nEnglish\n5.0\n34\n468\n\n\nThe Burning Maze\nRick Riordan\nRobbie Daymond\n13 hrs and 8 mins\n13\n8\n47280\n2018-05-01\n2018\nEnglish\n4.5\n41\n820\n\n\nThe Deep End\nJeff Kinney\nDan Russell\n2 hrs and 3 mins\n2\n3\n7380\n2020-11-06\n2020\nEnglish\n4.5\n38\n410\n\n\nDaughter of the Deep\nRick Riordan\nSoneela Nankani\n11 hrs and 16 mins\n11\n16\n40560\n2021-10-05\n2021\nEnglish\n4.5\n12\n615\n\n\nThe Lightning Thief: Percy Jackson, Book 1\nRick Riordan\nJesse Bernstein\n10 hrs\n10\n0\n36000\n2010-01-13\n2010\nEnglish\n4.5\n181\n820\n\n\nThe Hunger Games: Special Edition\nSuzanne Collins\nTatiana Maslany\n10 hrs and 35 mins\n10\n35\n38100\n2018-10-30\n2018\nEnglish\n5.0\n72\n656\n\n\nQuest for the Diamond Sword\nWinter Morgan\nLuke Daniels\n2 hrs and 23 mins\n2\n23\n8580\n2014-11-25\n2014\nEnglish\n5.0\n11\n233\n\n\nThe Dark Prophecy\nRick Riordan\nRobbie Daymond\n12 hrs and 32 mins\n12\n32\n45120\n2017-05-02\n2017\nEnglish\n5.0\n50\n820\n\n\nMerlin Mission Collection\nMary Pope Osborne\nMary Pope Osborne\n10 hrs and 56 mins\n10\n56\n39360\n2017-05-02\n2017\nEnglish\n5.0\n5\n1256\n\n\nThe Tyrant‚Äôs Tomb\nRick Riordan\nRobbie Daymond\n13 hrs and 22 mins\n13\n22\n48120\n2019-09-24\n2019\nEnglish\n5.0\n58\n820"
  },
  {
    "objectID": "R Projects/audible/audible.html#data-validity",
    "href": "R Projects/audible/audible.html#data-validity",
    "title": "Audible Data Cleaning",
    "section": "Data Validity",
    "text": "Data Validity\nThis is measure to ensure that all columns have the right datatype\n\naudible %&gt;% str()\n\ntibble [87,489 √ó 13] (S3: tbl_df/tbl/data.frame)\n $ name        : chr [1:87489] \"Geronimo Stilton #11 & #12\" \"The Burning Maze\" \"The Deep End\" \"Daughter of the Deep\" ...\n $ author      : chr [1:87489] \"Geronimo Stilton\" \"Rick Riordan\" \"Jeff Kinney\" \"Rick Riordan\" ...\n $ narrator    : chr [1:87489] \"Bill Lobely\" \"Robbie Daymond\" \"Dan Russell\" \"Soneela Nankani\" ...\n $ time        : chr [1:87489] \"2 hrs and 20 mins\" \"13 hrs and 8 mins\" \"2 hrs and 3 mins\" \"11 hrs and 16 mins\" ...\n $ releasedate : Date[1:87489], format: \"2008-08-04\" \"2018-05-01\" ...\n $ language    : chr [1:87489] \"English\" \"English\" \"English\" \"English\" ...\n $ Stars       : num [1:87489] 5 4.5 4.5 4.5 4.5 5 5 5 5 5 ...\n $ Rating      : num [1:87489] 34 41 38 12 181 72 11 50 5 58 ...\n $ price       : num [1:87489] 468 820 410 615 820 ...\n $ hours       : num [1:87489] 2 13 2 11 10 10 2 12 10 13 ...\n $ minutes     : num [1:87489] 20 8 3 16 0 35 23 32 56 22 ...\n $ time_seconds: num [1:87489] 8400 47280 7380 40560 36000 ...\n $ Year        : num [1:87489] 2008 2018 2020 2021 2010 ..."
  },
  {
    "objectID": "R Projects/audible/audible.html#saving-the-data",
    "href": "R Projects/audible/audible.html#saving-the-data",
    "title": "Audible Data Cleaning",
    "section": "Saving the Data",
    "text": "Saving the Data\n\nwrite.csv(audible,\"C:/Users/SAMMY/Desktop/Audible/audible_cleaned.csv\")"
  },
  {
    "objectID": "R Projects/audible/audible.html#top-5-authors-on-audible",
    "href": "R Projects/audible/audible.html#top-5-authors-on-audible",
    "title": "Audible Data Cleaning",
    "section": "Top 5 Authors on Audible",
    "text": "Top 5 Authors on Audible\n\n# Filter top 5 authors\ntop_authors &lt;- audible %&gt;%\n  group_by(author) %&gt;%\n  summarise(n = n()) %&gt;%\n  arrange(n) %&gt;%\n  top_n(5)\n\nSelecting by n\n\n# Bar plot of top 5 Audible Authors\nggplot(top_authors, aes(x = reorder(author, n), y = n, fill = author)) +\n  geom_bar(stat = \"identity\") +\n   geom_text(aes(label = n), hjust = -0.1, color = \"black\", size = 3.5) +\n  scale_fill_manual(values = c(\"Áü¢Â≥∂ÈõÖÂºò,Áü≥Ê©ãÈÅä\"=\"#FFA000\",\"Smart Reading\"=\"#FFB347\",\"‰∏≠Ë•øË≤¥‰πã,BJ\"=\"#FFC680\",\"div.\"=\"#FFDAB3\",\"Online Studio Productions\"=\"#FFEFE0\")) +\n  coord_flip() +\n  labs(x = \"Author\", y = \"Book Count\", title = \"Top 5 Authors in Audible Dataset\") +\n  theme_classic() +\n  theme(legend.position = \"none\",plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "R Projects/audible/audible.html#distribution-of-star-rating",
    "href": "R Projects/audible/audible.html#distribution-of-star-rating",
    "title": "Audible Data Cleaning",
    "section": "Distribution of Star Rating",
    "text": "Distribution of Star Rating\n\nstar_summary &lt;- audible %&gt;%\n  group_by(Stars) %&gt;%\n  summarise(count = n()) %&gt;%\n  arrange(desc(Stars))\n\n# Create the bar plot\nggplot(star_summary, aes(x =reorder(Stars,Stars), y = count)) +\n  geom_bar(stat = \"identity\", fill = \"#FFA000\", color = \"#000000\") +\n  geom_text(aes(label = count), vjust = -.5,hjust=0.5, color= \"black\", size = 3.5)+\n  labs(x = \"Star Rating\", y = \"Count\", title = \"Distribution of Star Ratings\") +\n  theme_classic() +\n  theme(plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "R Projects/audible/audible.html#heatmap-of-books-released-by-year",
    "href": "R Projects/audible/audible.html#heatmap-of-books-released-by-year",
    "title": "Audible Data Cleaning",
    "section": "Heatmap of Books Released By Year",
    "text": "Heatmap of Books Released By Year\n\nunique_years &lt;- unique(audible$Year)\nyear_summary &lt;- audible %&gt;%\n  group_by(Year) %&gt;%\n  summarise(count = n()) %&gt;%\n  arrange(Year)\n\n# Create heatmap\nggplot(year_summary, aes(x = \"\", y = Year, fill = count)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient(low = \"linen\", high = \"#FFA000\") +\n  geom_text(aes(label = count), vjust = 0.5, hjust = 1,color = \"black\", size = 2.8,alpha=1)+\n  scale_y_continuous(breaks = unique_years)+\n  labs(x = \"Book Count\", y = \"Year\", title = \"Heatmap of Books Released Each Year\") +\n  theme_classic() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\nYou can access dataset here and source code here"
  },
  {
    "objectID": "R Projects/audible/audible.html",
    "href": "R Projects/audible/audible.html",
    "title": "Audible Data Cleaning",
    "section": "",
    "text": "The Audible dataset is a collection of data related to audiobooks gathered from Audible. It contains data from authors of audiobooks to release dates. The data represents the important details of audiobooks from 1998 till 2025 (pre-planned releases) and it was obtained from Kaggle. A peek into the Audible dataset indicates that there are some errors and inconsistencies which can be corrected using string manipulation techniques along side other data cleaning techniques."
  },
  {
    "objectID": "R Projects/audible/audible.html#top-5-authors-in-audible",
    "href": "R Projects/audible/audible.html#top-5-authors-in-audible",
    "title": "Audible Data Cleaning",
    "section": "Top 5 Authors in Audible",
    "text": "Top 5 Authors in Audible\n\n# Filter top 5 authors\ntop_authors &lt;- audible %&gt;%\n  group_by(author) %&gt;%\n  summarise(n = n()) %&gt;%\n  arrange(n) %&gt;%\n  top_n(5)\n\nSelecting by n\n\n# Bar plot of top 5 Audible Authors\nggplot(top_authors, aes(x = reorder(author, n), y = n, fill = author)) +\n  geom_bar(stat = \"identity\") +\n   geom_text(aes(label = n), hjust = -0.1, color = \"black\", size = 3.5) +\n  scale_fill_manual(values = c(\"Áü¢Â≥∂ÈõÖÂºò,Áü≥Ê©ãÈÅä\"=\"#FFA000\",\"Smart Reading\"=\"#FFB347\",\"‰∏≠Ë•øË≤¥‰πã,BJ\"=\"#FFC680\",\"div.\"=\"#FFDAB3\",\"Online Studio Productions\"=\"#FFEFE0\")) +\n  coord_flip() +\n  labs(x = \"Author\", y = \"Book Count\", title = \"Top 5 Authors in Audible\") +\n  theme_classic() +\n  theme(legend.position = \"none\",plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "Excel Projects/READALOT BOOKSTORE/Readalot.html#introduction",
    "href": "Excel Projects/READALOT BOOKSTORE/Readalot.html#introduction",
    "title": "Book Sales Analysis at Read-A-Lot Bookstore.",
    "section": "Introduction",
    "text": "Introduction\nIn this interesting data analysis project, I explore book sales at Read-A-Lot Bookstore. My goal is to understand trends, patterns, and insights related to global book sales at Read-A-Lot Bookstore. The dataset covers various genres, authors, and publishers from 1980 to 2020. By carefully analyzing this data, I aim to provide valuable business information for Read-A-Lot Ltd.¬†üìöüîç"
  },
  {
    "objectID": "Excel Projects/READALOT BOOKSTORE/Readalot.html#overview",
    "href": "Excel Projects/READALOT BOOKSTORE/Readalot.html#overview",
    "title": "Book Sales Analysis at Read-A-Lot Bookstore.",
    "section": "Overview",
    "text": "Overview\nThe analysis revolves around answering critical questions:\n\nHistorical Book Production : An examination of books published anually?\nGenre and Publisher Trends: What are the total sales of the top 5 book genres and top 5 publishers worldwide during this period?\nRegional Dominance: Which book genres dominated?\nGlobal Sales Trends: How did the total book sales trend evolve globally during specific time period."
  },
  {
    "objectID": "Excel Projects/READALOT BOOKSTORE/Readalot.html#data-source",
    "href": "Excel Projects/READALOT BOOKSTORE/Readalot.html#data-source",
    "title": "Book Sales Analysis at Read-A-Lot Bookstore.",
    "section": "Data Source",
    "text": "Data Source\nThe dataset used is sourced from Kaggleand contains information on books with sales exceeding a certain threshold."
  },
  {
    "objectID": "Excel Projects/READALOT BOOKSTORE/Readalot.html#examine-the-dataset",
    "href": "Excel Projects/READALOT BOOKSTORE/Readalot.html#examine-the-dataset",
    "title": "Book Sales Analysis at Read-A-Lot Bookstore.",
    "section": "Examine the Dataset",
    "text": "Examine the Dataset\nA peek into the data; the first 10 rows of data:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nindex\nPublishing Year\nBook Name\nAuthor\nlanguage_code\nAuthor_Rating\nBook_average_rating\nBook_ratings_count\ngenre\ngross sales\npublisher revenue\nsale price\nsales rank\nPublisher\nunits sold\nsales\n\n\n\n\n0\n1975\nBeowulf\nUnknown, Seamus Heaney\nen-US\nNovice\n3.42\n155903\ngenre fiction\n34160.00\n20496.0\n4.88\n1\nHarperCollins Publishers\n7000\n$34,160\n\n\n1\n1987\nBatman: Year One\nFrank Miller, David Mazzucchelli, Richmond Lewis, Dennis O‚ÄôNeil\neng\nIntermediate\n4.23\n145267\ngenre fiction\n12437.50\n7462.5\n1.99\n2\nHarperCollins Publishers\n6250\n$12,438\n\n\n2\n2015\nGo Set a Watchman\nHarper Lee\neng\nNovice\n3.31\n138669\ngenre fiction\n47795.00\n28677.0\n8.69\n3\nAmazon Digital Services, Inc.\n5500\n$47,795\n\n\n3\n2008\nWhen You Are Engulfed in Flames\nDavid Sedaris\nen-US\nIntermediate\n4.04\n150898\nfiction\n41250.00\n24750.0\n7.50\n3\nHachette Book Group\n5500\n$41,250\n\n\n4\n2011\nDaughter of Smoke & Bone\nLaini Taylor\neng\nIntermediate\n4.04\n198283\ngenre fiction\n37952.50\n22771.5\n7.99\n4\nPenguin Group (USA) LLC\n4750\n$37,953\n\n\n5\n2015\nRed Queen\nVictoria Aveyard\neng\nIntermediate\n4.08\n83354\ngenre fiction\n19960.00\n0.0\n4.99\n5\nAmazon Digital Services, Inc.\n4000\n$19,960\n\n\n6\n2011\nThe Power of Habit\nCharles Duhigg\neng\nIntermediate\n4.03\n155977\ngenre fiction\n27491.67\n16495.0\n6.99\n6\nHarperCollins Publishers\n3933\n$27,492\n\n\n7\n1994\nMidnight in the Garden of Good and Evil\nJohn Berendt\neng\nIntermediate\n3.90\n167997\nnonfiction\n26182.00\n15709.2\n6.89\n8\nHachette Book Group\n3800\n$26,182\n\n\n8\n2012\nHopeless\nColleen Hoover\neng\nIntermediate\n4.34\n189938\ngenre fiction\n26093.67\n15656.2\n6.99\n9\nHarperCollins Publishers\n3733\n$26,094\n\n\n10\n2004\nThe Truth About Forever\nSarah Dessen\nen-US\nIntermediate\n4.13\n179415\ngenre fiction\n17964.00\n0.0\n4.99\n11\nAmazon Digital Services, Inc.\n3600\n$17,964"
  },
  {
    "objectID": "Excel Projects/READALOT BOOKSTORE/Readalot.html#key-dashboard-requirements",
    "href": "Excel Projects/READALOT BOOKSTORE/Readalot.html#key-dashboard-requirements",
    "title": "Book Sales Analysis at Read-A-Lot Bookstore.",
    "section": "Key Dashboard Requirements",
    "text": "Key Dashboard Requirements\n\nThe interactive dashboard fulfills the following requirements:\n\nUsers can select Publishers and Authors that have their books on Read-A-Lot platformand Cities to compare sales and quantity trends.\nThe dashboard displays the top 5 Genres, top 5 Books by revenue corresponding to the chosen criteria."
  },
  {
    "objectID": "Excel Projects/READALOT BOOKSTORE/Readalot.html#dashboard",
    "href": "Excel Projects/READALOT BOOKSTORE/Readalot.html#dashboard",
    "title": "Book Sales Analysis at Read-A-Lot Bookstore.",
    "section": "Dashboard",
    "text": "Dashboard\n\n\n\n\n\n\n\nImportant!\n\n\n\nRight-click on image to open dashboard in new tab, if content too tiny\n\n\n\nTo interact with the Excel Dashboard, click here"
  },
  {
    "objectID": "Excel Projects/READALOT BOOKSTORE/Readalot.html#recommendations",
    "href": "Excel Projects/READALOT BOOKSTORE/Readalot.html#recommendations",
    "title": "Book Sales Analysis at Read-A-Lot Bookstore.",
    "section": "Recommendations",
    "text": "Recommendations\n\nIdentify a Target Audience: Understand your readers‚Äô demographics, psychographics, and online behavior to better market to them.\n\n\n\nBuild an Author Platform: This can help amplify a book‚Äôs exposure and reach more readers.\n\n\n\nDesign a Book‚Äôs Cover: A well-designed cover can attract potential readers."
  },
  {
    "objectID": "Excel Projects/READALOT BOOKSTORE/Readalot.html#conclusion",
    "href": "Excel Projects/READALOT BOOKSTORE/Readalot.html#conclusion",
    "title": "Book Sales Analysis at Read-A-Lot Bookstore.",
    "section": "Conclusion",
    "text": "Conclusion\nIn conclusion, the book sales analysis for Read-A-Lot Bookstore has yielded valuable insights into the sales for the year 2023:\n\nInsights:\n\nTotal Book Sales grossed $47.74M in the year 2023.\nFiction Genre sold the most of all Genres.\nAmazon Digital Services Inc. grossed in a Revenue of $19.69M topping all publishers.\n2010-2014 marked the years books were published the most, totalling a count of 226 Books."
  },
  {
    "objectID": "index.html#good-morning-oyindamola-adegoke",
    "href": "index.html#good-morning-oyindamola-adegoke",
    "title": "\nSAMMY ODEYEMI\n",
    "section": "Good Morning üåû ~ Oyindamola Adegoke   ",
    "text": "Good Morning üåû ~ Oyindamola Adegoke   \n\n\nMy Portfolio\n\n\n\nExcel Projects\n\n\n\n\n\n\n\n  \n    \n  \n  \n    This is an Analysis on Read-A-Lot Bookstore data for the year 2023. The company specializes in the sales of books. I employed Microsoft Excel to perform various operations, ranging from data cleaning up to visualization.\n  \n  View Project\n  \n\n\n\n\n\n  \n    \n  \n  \n    This is an Analysis on Quantum Sales Solutions data for the year 2023. The company specializes in the sales of edible products. I employed Microsoft Excel to perform various operations, ranging from data cleaning up to visualization.\n  \n  View Project\n  \n\n\n\n\n\n  \n    \n  \n  \n    This is an Analysis on the Israel-Palestine conflict and the fatalities that occurred. I employed Microsoft Excel to perform various operations, ranging from data cleaning to visualization.\n  \n  View Project\n  \n\n\n\n\n\n  \n    \n    \n  \n    This is a Video Game Sales Analysis for Synergy Ltd. I employed Microsoft Excel to perform various operations, ranging from data cleaning to visualization.\n  \n  View Project\n  \n\n\n\n\n\n\nR Projects\n\n\n\n\n   \n   \n    \n   \nThis is a Data Cleaning Project for Audible. I employed R and RStudio to perform Data Cleaning, and took it a nudge further by analysing and making Visualizations.     \nView Project"
  },
  {
    "objectID": "R Projects/audible/fistmarkdown.html",
    "href": "R Projects/audible/fistmarkdown.html",
    "title": "Ibrahim Alayo",
    "section": "",
    "text": "library(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.0     ‚úî readr     2.1.4\n‚úî forcats   1.0.0     ‚úî stringr   1.5.0\n‚úî ggplot2   3.4.1     ‚úî tibble    3.2.0\n‚úî lubridate 1.9.2     ‚úî tidyr     1.3.0\n‚úî purrr     1.0.1     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nlibrary(pROC)\n\nType 'citation(\"pROC\")' for a citation.\n\n\n\nAttaching package: 'pROC'\n\n\nThe following objects are masked from 'package:stats':\n\n    cov, smooth, var\n\n\n\nndhsrasheeddata &lt;- read_csv(\"ndhsrasheed.csv\") %&gt;% view()\n\n\nndhsrasheedselect&lt;-select(ndhsrasheeddata, wealth, edu, rworking, resid, relig, visithosp, teenmom, agefbirth, hofistula, tchild) \n\n\nndhsrasheedselect&lt;-drop_na(ndhsrasheedselect) %&gt;% view()\n\n\n# Factor the columns for logistic regression \nndhsrasheedselect$wealth &lt;- as.factor(ndhsrasheedselect$wealth) \nndhsrasheedselect$edu &lt;- as.factor(ndhsrasheedselect$edu) \nndhsrasheedselect$rworking &lt;- as.factor(ndhsrasheedselect$rworking) \nndhsrasheedselect$resid &lt;- as.factor(ndhsrasheedselect$resid)\nndhsrasheedselect$relig &lt;- as.factor(ndhsrasheedselect$relig)\nndhsrasheedselect$visithosp &lt;- as.factor(ndhsrasheedselect$visithosp) \nndhsrasheedselect$teenmom &lt;- as.factor(ndhsrasheedselect$teenmom)\n\n\nfistulamodel1 &lt;-    glm(ndhsrasheedselect$hofistula~ wealth + edu + rworking + resid + relig + visithosp + teenmom + agefbirth + tchild, family=binomial(link = \"logit\"), data=ndhsrasheedselect)\n\n\nsummary(fistulamodel1)\n\n\nCall:\nglm(formula = ndhsrasheedselect$hofistula ~ wealth + edu + rworking + \n    resid + relig + visithosp + teenmom + agefbirth + tchild, \n    family = binomial(link = \"logit\"), data = ndhsrasheedselect)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.0460  -1.0689   0.6700   0.9219   1.9440  \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.301056   0.086359 -15.066  &lt; 2e-16 ***\nwealth2     -0.377643   0.021212 -17.803  &lt; 2e-16 ***\nwealth3     -0.352264   0.023153 -15.215  &lt; 2e-16 ***\nedu1        -0.276620   0.022697 -12.187  &lt; 2e-16 ***\nedu2        -0.302114   0.025248 -11.966  &lt; 2e-16 ***\nedu3         0.304739   0.038866   7.841 4.48e-15 ***\nrworking1    0.101677   0.018614   5.462 4.70e-08 ***\nresid2       0.263481   0.018746  14.055  &lt; 2e-16 ***\nrelig2       0.913443   0.019232  47.496  &lt; 2e-16 ***\nrelig3      -0.894714   0.092886  -9.632  &lt; 2e-16 ***\nvisithosp1   0.563839   0.015825  35.629  &lt; 2e-16 ***\nteenmom1     0.264171   0.026870   9.831  &lt; 2e-16 ***\nagefbirth    0.018573   0.003277   5.668 1.45e-08 ***\ntchild       0.064631   0.003113  20.760  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 108090  on 79536  degrees of freedom\nResidual deviance:  97156  on 79523  degrees of freedom\nAIC: 97184\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nfistulamodel2 &lt;-    glm(hofistula~ wealth + edu + rworking + resid + relig + visithosp + teenmom + agefbirth + tchild, family=binomial(link = \"cloglog\"),       data=ndhsrasheedselect)\n\n\nsummary(fistulamodel2)\n\n\nCall:\nglm(formula = hofistula ~ wealth + edu + rworking + resid + relig + \n    visithosp + teenmom + agefbirth + tchild, family = binomial(link = \"cloglog\"), \n    data = ndhsrasheedselect)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1678  -1.0577   0.6513   0.9379   1.8849  \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.279116   0.057918 -22.085  &lt; 2e-16 ***\nwealth2     -0.232683   0.013836 -16.818  &lt; 2e-16 ***\nwealth3     -0.240078   0.015518 -15.471  &lt; 2e-16 ***\nedu1        -0.141903   0.014818  -9.576  &lt; 2e-16 ***\nedu2        -0.196713   0.017281 -11.383  &lt; 2e-16 ***\nedu3         0.241282   0.026031   9.269  &lt; 2e-16 ***\nrworking1    0.040466   0.011441   3.537 0.000405 ***\nresid2       0.155610   0.012603  12.347  &lt; 2e-16 ***\nrelig2       0.632866   0.013280  47.657  &lt; 2e-16 ***\nrelig3      -0.688587   0.078555  -8.766  &lt; 2e-16 ***\nvisithosp1   0.350590   0.009992  35.087  &lt; 2e-16 ***\nteenmom1     0.190890   0.017930  10.647  &lt; 2e-16 ***\nagefbirth    0.014073   0.002215   6.353 2.11e-10 ***\ntchild       0.040288   0.001886  21.367  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 108090  on 79536  degrees of freedom\nResidual deviance:  97193  on 79523  degrees of freedom\nAIC: 97221\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nfistulamodel3 &lt;-    glm(hofistula~ wealth + edu + rworking + resid + relig + visithosp + teenmom + agefbirth + tchild, family=binomial(link = \"probit\"),       data=ndhsrasheedselect)\n\n\nsummary(fistulamodel3)\n\n\nCall:\nglm(formula = hofistula ~ wealth + edu + rworking + resid + relig + \n    visithosp + teenmom + agefbirth + tchild, family = binomial(link = \"probit\"), \n    data = ndhsrasheedselect)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.0732  -1.0704   0.6680   0.9244   1.9671  \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.800068   0.052549 -15.225  &lt; 2e-16 ***\nwealth2     -0.230090   0.012927 -17.799  &lt; 2e-16 ***\nwealth3     -0.214818   0.014143 -15.189  &lt; 2e-16 ***\nedu1        -0.165623   0.013865 -11.946  &lt; 2e-16 ***\nedu2        -0.182596   0.015480 -11.796  &lt; 2e-16 ***\nedu3         0.188716   0.023829   7.920 2.38e-15 ***\nrworking1    0.057653   0.011234   5.132 2.87e-07 ***\nresid2       0.158214   0.011431  13.841  &lt; 2e-16 ***\nrelig2       0.563867   0.011822  47.698  &lt; 2e-16 ***\nrelig3      -0.549484   0.054597 -10.064  &lt; 2e-16 ***\nvisithosp1   0.339822   0.009558  35.553  &lt; 2e-16 ***\nteenmom1     0.163358   0.016378   9.974  &lt; 2e-16 ***\nagefbirth    0.011790   0.001997   5.903 3.56e-09 ***\ntchild       0.039144   0.001871  20.921  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 108090  on 79536  degrees of freedom\nResidual deviance:  97167  on 79523  degrees of freedom\nAIC: 97195\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nus &lt;- predict(fistulamodel1, type = \"response\")\n\n\nroc_curve&lt;- roc(ndhsrasheedselect$hofistula, us)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\n\n\nauc_value &lt;- auc(roc_curve)\n\n\nplot(roc_curve, main=\"ROC curve\", col=\"#007c80\")\ntext(0.5, 0.5, paste(\"AUC =\", round(auc_value, 4)), cex=0.8)"
  }
]