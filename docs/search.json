[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\nSAMMY ODEYEMI\n",
    "section": "",
    "text": "SAMMY ODEYEMI\n\n\n\n\nHi!, I am a grounded and goal-oriented Computer Science professional with demonstrated expertise in Data Analytics. Skilled in SQL, R, and Power BI,\n\n\nI specialize in transforming complex data into clear insights for informed decision-making.\n\n\n\nMy Portfolio\n\n\n\nSQL x POWER BI Projects\n\n\n\n\n\n\n\n  \n    \n  \n  \n    A murder has occurred in SQL City, and the objective is to solve it as the Detective assigned. Using SQL queries to search through the Police Department Database to find clues and evidence; the goal is to identify the murderer and bring them to justice.\n  \n  View Project\n  \n\n\n\n\n\n  \n    \n  \n  \n    This analysis delves into heart attack risk across different demographics globally, examining a comprehensive set of health metrics. The goal is to identify high-risk groups and inform targeted interventions to improve cardiovascular health outcomes globally.\n  \n  View Project\n  \n\n\n\n\n\n\n\nExcel Projects\n\n\n\n\n\n\n\n  \n    \n  \n  \n    This is an Analysis on Read-A-Lot Bookstore data for the year 2023. The company specializes in the sales of books. I employed Microsoft Excel to perform various operations, ranging from data cleaning up to visualization.\n  \n  View Project\n  \n\n\n\n\n\n  \n    \n  \n  \n    This is an Analysis on Quantum Sales Solutions data for the year 2023. The company specializes in the sales of edible products. I employed Microsoft Excel to perform various operations, ranging from data cleaning up to visualization.\n  \n  View Project\n  \n\n\n\n\n\n  \n    \n  \n  \n    This is an Analysis on the Israel-Palestine conflict and the fatalities that occurred. I employed Microsoft Excel to perform various operations, ranging from data cleaning to visualization.\n  \n  View Project\n  \n\n\n\n\n\n  \n    \n    \n  \n    This is a Video Game Sales Analysis for Synergy Ltd. I employed Microsoft Excel to perform various operations, ranging from data cleaning to visualization.\n  \n  View Project\n  \n\n\n\n\n\n\nR Projects\n\n\n\n\n\n\n   \n   \n    \n   \nThis project focuses on the comprehensive process of data wrangling, utilizing R and RStudio to perform data cleaning and transformation on the FIFA 21 dataset. The primary objective was to transform raw data into a clean, structured, and analyzable format, ensuring its accuracy, consistency, and readiness for further analysis.   \nView Project \n\n\n\n\n   \n   \n    \n   \nThis is a Data Cleaning Project for Audible. I employed R and RStudio to perform Data Cleaning, and took it a nudge further by analysing and making Visualizations.     \nView Project"
  },
  {
    "objectID": "audible/audible.html#authornarrator",
    "href": "audible/audible.html#authornarrator",
    "title": "audible",
    "section": "Author and Narrator Columns",
    "text": "Author and Narrator Columns\nThe Author and Narrator columns contain the names of the Authors and Narrators of the Audiobooks.\n\n#select Author and Narrator columns\naudible %&gt;% select(author,narrator) %&gt;% head(10) %&gt;%kable()\n\n\n\n\nauthor\nnarrator\n\n\n\n\nWrittenby:GeronimoStilton\nNarratedby:BillLobely\n\n\nWrittenby:RickRiordan\nNarratedby:RobbieDaymond\n\n\nWrittenby:JeffKinney\nNarratedby:DanRussell\n\n\nWrittenby:RickRiordan\nNarratedby:SoneelaNankani\n\n\nWrittenby:RickRiordan\nNarratedby:JesseBernstein\n\n\nWrittenby:SuzanneCollins\nNarratedby:TatianaMaslany\n\n\nWrittenby:WinterMorgan\nNarratedby:LukeDaniels\n\n\nWrittenby:RickRiordan\nNarratedby:RobbieDaymond\n\n\nWrittenby:MaryPopeOsborne\nNarratedby:MaryPopeOsborne\n\n\nWrittenby:RickRiordan\nNarratedby:RobbieDaymond\n\n\n\n\n\nThese columns in the dataset have a common issue known as string concatenation errors. This occurs when two or more strings are joined together without appropriate spacing or delimiters. In this case, the names of authors and narrators are concatenated without spaces, making it difficult to distinguish between first and last names.\nAdditionally, the strings ‘Writtenby:’ and ‘Narratedby:’ are concatenated with the names, adding unnecessary clutter to our data; hence the need to remove unnecessary strings and add spaces between the names using regular expressions.\n\n\n#author and narrator column cleaned of unwanted characters and spaces added where necessary\naudible&lt;-audible %&gt;%mutate_at(vars(author,narrator),\n  ~if_else(str_detect(.,\"(Writtenby:)|(Narratedby:)\"),\n        str_replace_all(str_remove(.,\"(Writtenby:)|(Narratedby:)|\\\\d+\"),\n                        \"(?&lt;=[a-z])(?=[A-Z])\", \" \"),\n        .)\n  )\n\n\ncross-check\nIt becomes important to check the content of these columns after performing the operation\n\n\naudible %&gt;% select(author,narrator) %&gt;% head(5) %&gt;% kable()\n\n\n\n\nauthor\nnarrator\n\n\n\n\nGeronimo Stilton\nBill Lobely\n\n\nRick Riordan\nRobbie Daymond\n\n\nJeff Kinney\nDan Russell\n\n\nRick Riordan\nSoneela Nankani\n\n\nRick Riordan\nJesse Bernstein"
  },
  {
    "objectID": "audible/audible.html#time",
    "href": "audible/audible.html#time",
    "title": "audible",
    "section": "Time Column",
    "text": "Time Column\nThe Time column is the total duration of each audiobook\n\naudible %&gt;% select(time) %&gt;% head(5) %&gt;%kable()\n\n\n\n\ntime\n\n\n\n\n2 hrs and 20 mins\n\n\n13 hrs and 8 mins\n\n\n2 hrs and 3 mins\n\n\n11 hrs and 16 mins\n\n\n10 hrs\n\n\n\n\n\nIt is a column of string datatype and the contents are needed to be extracted and typecasted to numeric values to aid further analysis.\n\n# Create new columns off the time column and typecast to numeric \naudible &lt;- audible %&gt;%\n  mutate(\n    # Extract hours and minutes into separate columns\n    hours = as.numeric(str_extract(time, \"\\\\d+(?=\\\\s*hr)\")),\n    minutes = as.numeric(str_extract(time, \"\\\\d+(?=\\\\s*min)\")),\n    \n    # Convert time to seconds\n    time_seconds = case_when(\n      str_detect(time, \"hrs|hr\") & !str_detect(time, \"mins|min\") ~\n        as.numeric(str_extract(time, \"\\\\d+(?=\\\\s*hr)\")) * 3600,\n      str_detect(time, \"hrs|hr\") & str_detect(time, \"min|mins\") ~\n        as.numeric(str_extract(time, \"\\\\d+(?=\\\\s*hr)\")) * 3600 +\n        as.numeric(str_extract(time, \"\\\\d+(?=\\\\s*min)\")) * 60,\n      str_detect(time, \"mins|min\") ~\n        as.numeric(str_extract(time, \"\\\\d+\")) * 60,\n      TRUE ~ as.numeric(time)\n    )\n  )\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `time_seconds = case_when(...)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\n\n\n\n\n\n\nNA values\n\n\n\nThe NA values are introduced because there are some observations that may not have either hours or minutes. In such instances, since there is no hour or minute to extract as the case may be, the newly created ‘hours’ or ‘minutes’ columns return NA. This is a common occurrence in data processing when the expected data is not present in certain observations. And to handle such instances, NA values are replaced with zero\n\n\n\n# Handle NA values (if there are cases like \"2 hours\" with no mins or \"45 mins\" with no hours)\naudible$hours[is.na(audible$hours)] &lt;- 0\naudible$minutes[is.na(audible$minutes)] &lt;- 0 \n\ncross-check\n\naudible %&gt;% select(time,hours,minutes,time_seconds) %&gt;% head(6) %&gt;% kable()\n\n\n\n\ntime\nhours\nminutes\ntime_seconds\n\n\n\n\n2 hrs and 20 mins\n2\n20\n8400\n\n\n13 hrs and 8 mins\n13\n8\n47280\n\n\n2 hrs and 3 mins\n2\n3\n7380\n\n\n11 hrs and 16 mins\n11\n16\n40560\n\n\n10 hrs\n10\n0\n36000\n\n\n10 hrs and 35 mins\n10\n35\n38100"
  },
  {
    "objectID": "audible/audible.html#releasedate",
    "href": "audible/audible.html#releasedate",
    "title": "audible",
    "section": "Release Date Column",
    "text": "Release Date Column\nThe Release Date Column just as the name implies is the release date of each and every audiobook contained in the dataset.\n\naudible %&gt;% select(releasedate) %&gt;% head(5) %&gt;% kable()\n\n\n\n\nreleasedate\n\n\n\n\n04-08-08\n\n\n01-05-18\n\n\n06-11-20\n\n\n05-10-21\n\n\n13-01-10\n\n\n\n\n\nIt is of string datatype, hence the need to convert to Date in its truest form.\n\n#converted releasedate column of data type string to date as should be\naudible$releasedate&lt;- as.Date(audible$releasedate,format=\"%d-%m-%y\")\n#Extract the Year COlumn from the releasedate Column\naudible&lt;-audible %&gt;%mutate(Year=year(audible$releasedate))"
  },
  {
    "objectID": "audible/audible.html#stars",
    "href": "audible/audible.html#stars",
    "title": "audible",
    "section": "Stars Column",
    "text": "Stars Column\nThe Stars Column represents the average rating given by users for a particular audiobook. It has a band of 1 to 5. But during scraping of the data, the rating was scraped into the same column as the stars bringing about a string concatenation error. There should be a separate rating column that represents the number of users who have rated the audiobook.\n\naudible %&gt;% select(stars) %&gt;% head(6)\n\n# A tibble: 6 × 1\n  stars                        \n  &lt;chr&gt;                        \n1 5 out of 5 stars34 ratings   \n2 4.5 out of 5 stars41 ratings \n3 4.5 out of 5 stars38 ratings \n4 4.5 out of 5 stars12 ratings \n5 4.5 out of 5 stars181 ratings\n6 5 out of 5 stars72 ratings   \n\n\n\n#split stars column into Stars and Rating Column,remove unwanted characters and convert columns to numeric \n  audible &lt;- audible %&gt;% \n    separate(stars, into = c(\"Stars\", \"Rating\"), sep = \"out of 5 stars\") %&gt;% \n    mutate(\n      Stars = as.numeric(str_remove_all(Stars, \" \")),\n      Rating = as.numeric(str_remove_all(Rating, \",|ratings\"))\n    ) %&gt;% \n    mutate_at(\n      vars(Stars, Rating),\n      ~if_else(is.na(.), 0, .)\n    )\n\ncross-check\n\naudible %&gt;% select(Stars,Rating) %&gt;% head(7) %&gt;% kable()\n\n\n\n\nStars\nRating\n\n\n\n\n5.0\n34\n\n\n4.5\n41\n\n\n4.5\n38\n\n\n4.5\n12\n\n\n4.5\n181\n\n\n5.0\n72\n\n\n5.0\n11"
  },
  {
    "objectID": "audible/audible.html#price-column",
    "href": "audible/audible.html#price-column",
    "title": "audible",
    "section": "Price Column",
    "text": "Price Column\nThe Price column represents the price of the audiobook.\n\naudible %&gt;% select(price) %&gt;% head(10) \n\n# A tibble: 10 × 1\n   price   \n   &lt;chr&gt;   \n 1 468.00  \n 2 820.00  \n 3 410.00  \n 4 615.00  \n 5 820.00  \n 6 656.00  \n 7 233.00  \n 8 820.00  \n 9 1,256.00\n10 820.00  \n\n\nThis column is of string datatype and it has some unwanted characters such as the , and Free indicating that these books come at no cost at all.\n\naudible %&gt;% select(price) %&gt;% filter(price==\"Free\")%&gt;% head(3)\n\n# A tibble: 3 × 1\n  price\n  &lt;chr&gt;\n1 Free \n2 Free \n3 Free \n\n\nIt is imperative to remove these characters and typecast the data type\n\n  audible &lt;- audible %&gt;% mutate(\n    price = case_when(\n      str_detect(price, \",\") ~ as.numeric(str_remove(price, \",\")),\n      str_detect(price, \"Free\") ~ as.numeric(str_remove(price, \"Free\")),\n      TRUE ~ as.numeric(price)\n    ),price=if_else(is.na(price),0,price)\n  )\n\ncross-check\n\naudible %&gt;% select(price) %&gt;% head(10)\n\n# A tibble: 10 × 1\n   price\n   &lt;dbl&gt;\n 1   468\n 2   820\n 3   410\n 4   615\n 5   820\n 6   656\n 7   233\n 8   820\n 9  1256\n10   820"
  },
  {
    "objectID": "audible/audible.html#subsetting",
    "href": "audible/audible.html#subsetting",
    "title": "audible",
    "section": "Subsetting Needed Columns",
    "text": "Subsetting Needed Columns\nSelecting useful columns\n\naudible %&gt;% select(name:time,hours:time_seconds,releasedate,Year,language,Stars:price) %&gt;% head(10) %&gt;% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nauthor\nnarrator\ntime\nhours\nminutes\ntime_seconds\nreleasedate\nYear\nlanguage\nStars\nRating\nprice\n\n\n\n\nGeronimo Stilton #11 & #12\nGeronimo Stilton\nBill Lobely\n2 hrs and 20 mins\n2\n20\n8400\n2008-08-04\n2008\nEnglish\n5.0\n34\n468\n\n\nThe Burning Maze\nRick Riordan\nRobbie Daymond\n13 hrs and 8 mins\n13\n8\n47280\n2018-05-01\n2018\nEnglish\n4.5\n41\n820\n\n\nThe Deep End\nJeff Kinney\nDan Russell\n2 hrs and 3 mins\n2\n3\n7380\n2020-11-06\n2020\nEnglish\n4.5\n38\n410\n\n\nDaughter of the Deep\nRick Riordan\nSoneela Nankani\n11 hrs and 16 mins\n11\n16\n40560\n2021-10-05\n2021\nEnglish\n4.5\n12\n615\n\n\nThe Lightning Thief: Percy Jackson, Book 1\nRick Riordan\nJesse Bernstein\n10 hrs\n10\n0\n36000\n2010-01-13\n2010\nEnglish\n4.5\n181\n820\n\n\nThe Hunger Games: Special Edition\nSuzanne Collins\nTatiana Maslany\n10 hrs and 35 mins\n10\n35\n38100\n2018-10-30\n2018\nEnglish\n5.0\n72\n656\n\n\nQuest for the Diamond Sword\nWinter Morgan\nLuke Daniels\n2 hrs and 23 mins\n2\n23\n8580\n2014-11-25\n2014\nEnglish\n5.0\n11\n233\n\n\nThe Dark Prophecy\nRick Riordan\nRobbie Daymond\n12 hrs and 32 mins\n12\n32\n45120\n2017-05-02\n2017\nEnglish\n5.0\n50\n820\n\n\nMerlin Mission Collection\nMary Pope Osborne\nMary Pope Osborne\n10 hrs and 56 mins\n10\n56\n39360\n2017-05-02\n2017\nEnglish\n5.0\n5\n1256\n\n\nThe Tyrant’s Tomb\nRick Riordan\nRobbie Daymond\n13 hrs and 22 mins\n13\n22\n48120\n2019-09-24\n2019\nEnglish\n5.0\n58\n820"
  },
  {
    "objectID": "audible/audible.html#data-validity",
    "href": "audible/audible.html#data-validity",
    "title": "audible",
    "section": "Data Validity",
    "text": "Data Validity\nThis is measure to ensure that all columns have the right datatype\n\naudible %&gt;% str()\n\ntibble [87,489 × 13] (S3: tbl_df/tbl/data.frame)\n $ name        : chr [1:87489] \"Geronimo Stilton #11 & #12\" \"The Burning Maze\" \"The Deep End\" \"Daughter of the Deep\" ...\n $ author      : chr [1:87489] \"Geronimo Stilton\" \"Rick Riordan\" \"Jeff Kinney\" \"Rick Riordan\" ...\n $ narrator    : chr [1:87489] \"Bill Lobely\" \"Robbie Daymond\" \"Dan Russell\" \"Soneela Nankani\" ...\n $ time        : chr [1:87489] \"2 hrs and 20 mins\" \"13 hrs and 8 mins\" \"2 hrs and 3 mins\" \"11 hrs and 16 mins\" ...\n $ releasedate : Date[1:87489], format: \"2008-08-04\" \"2018-05-01\" ...\n $ language    : chr [1:87489] \"English\" \"English\" \"English\" \"English\" ...\n $ Stars       : num [1:87489] 5 4.5 4.5 4.5 4.5 5 5 5 5 5 ...\n $ Rating      : num [1:87489] 34 41 38 12 181 72 11 50 5 58 ...\n $ price       : num [1:87489] 468 820 410 615 820 ...\n $ hours       : num [1:87489] 2 13 2 11 10 10 2 12 10 13 ...\n $ minutes     : num [1:87489] 20 8 3 16 0 35 23 32 56 22 ...\n $ time_seconds: num [1:87489] 8400 47280 7380 40560 36000 ...\n $ Year        : num [1:87489] 2008 2018 2020 2021 2010 ..."
  },
  {
    "objectID": "audible/audible.html#saving-the-data",
    "href": "audible/audible.html#saving-the-data",
    "title": "audible",
    "section": "Saving the Data",
    "text": "Saving the Data\n\nwrite.csv(audible,\"C:/Users/SAMMY/Desktop/Audible/audible_cleaned.csv\")"
  },
  {
    "objectID": "audible/audible.html#top-5-authors-on-audible",
    "href": "audible/audible.html#top-5-authors-on-audible",
    "title": "audible",
    "section": "Top 5 Authors on Audible",
    "text": "Top 5 Authors on Audible\n\n# Filter top 5 authors\ntop_authors &lt;- audible %&gt;%\n  group_by(author) %&gt;%\n  summarise(n = n()) %&gt;%\n  arrange(n) %&gt;%\n  top_n(5)\n\nSelecting by n\n\n# Bar plot of top 5 Audible Authors\nggplot(top_authors, aes(x = reorder(author, n), y = n, fill = author)) +\n  geom_bar(stat = \"identity\") +\n   geom_text(aes(label = n), hjust = -0.1, color = \"black\", size = 3.5) +\n  scale_fill_manual(values = c(\"矢島雅弘,石橋遊\"=\"#FFA000\",\"Smart Reading\"=\"#FFB347\",\"中西貴之,BJ\"=\"#FFC680\",\"div.\"=\"#FFDAB3\",\"Online Studio Productions\"=\"#FFEFE0\")) +\n  coord_flip() +\n  labs(x = \"Author\", y = \"Book Count\", title = \"Top 5 Authors in Audible Dataset\") +\n  theme_classic() +\n  theme(legend.position = \"none\",plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "audible/audible.html#distribution-of-star-rating",
    "href": "audible/audible.html#distribution-of-star-rating",
    "title": "audible",
    "section": "Distribution of Star Rating",
    "text": "Distribution of Star Rating\n\nstar_summary &lt;- audible %&gt;%\n  group_by(Stars) %&gt;%\n  summarise(count = n()) %&gt;%\n  arrange(desc(Stars))\n\n# Create the bar plot\nggplot(star_summary, aes(x =reorder(Stars,Stars), y = count)) +\n  geom_bar(stat = \"identity\", fill = \"#FFA000\", color = \"#000000\") +\n  geom_text(aes(label = count), vjust = -.5,hjust=0.5, color= \"black\", size = 3.5)+\n  labs(x = \"Star Rating\", y = \"Count\", title = \"Distribution of Star Ratings\") +\n  theme_classic() +\n  theme(plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "audible/audible.html#heatmap-of-books-released-by-year",
    "href": "audible/audible.html#heatmap-of-books-released-by-year",
    "title": "audible",
    "section": "Heatmap of Books Released By Year",
    "text": "Heatmap of Books Released By Year\n\nunique_years &lt;- unique(audible$Year)\nyear_summary &lt;- audible %&gt;%\n  group_by(Year) %&gt;%\n  summarise(count = n()) %&gt;%\n  arrange(Year)\n\n# Create the heatmap\nggplot(year_summary, aes(x = \"\", y = Year, fill = count)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient(low = \"linen\", high = \"#FFA000\") +\n  geom_text(aes(label = count), vjust = 0.5, hjust = 1,color = \"black\", size = 2.8,alpha=1)+\n  scale_y_continuous(breaks = unique_years)+\n  labs(x = \"Book Count\", y = \"Year\", title = \"Heatmap of Books Released Each Year\") +\n  theme_classic() +\n  theme(plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Excel Projects/SYNERGY VIDEO GAME/synergy.html",
    "href": "Excel Projects/SYNERGY VIDEO GAME/synergy.html",
    "title": "synergy sales",
    "section": "",
    "text": "In this data analysis project, I delve into the fascinating world of video game sales at Synergy Sales. The goal is to explore trends, patterns, and insights related to video game sales worldwide. The dataset spans from 1980 to 2020, covering various regions, genres, and gaming platforms. By meticulously analyzing this data, I aim to provide valuable business insights for Synergy Ltd.\n\n\n\nThe analysis revolves around answering critical questions:\n\nWhich market has the highest video game sales from 1980 to 2016?\nWhat are the total sales of the top 5 game genres and top 5 platforms worldwide during this period?\nWhich game genres dominated different regions from 1980 to 2020?\nHow did the total sales trend evolve globally during specific time periods?\n\n\n\n\nThe dataset used is sourced from Kaggle and contains information on video games with sales exceeding 100,000 copies. It includes essential fields such as:\n\nRank: Overall sales ranking\nName: Game title\nPlatform: Release platform (e.g., PC, PS4)\nYear: Year of the game’s release\n\n\n\n\nI followed a structured approach, adhering to the six steps of the data analysis process:\n\nAsk: I defined the problem, communicated with stakeholders, and understood the business context. Synergy Ltd. requested an interactive dashboard showcasing game sales trends by region, genre, and platform.\nPrepare: I obtained the dataset, ensuring data integrity and cleanliness. Our primary analysis occurred on a duplicate worksheet to preserve the original data.\nProcess: I cleaned and transformed the data, preparing it for visualization.\nShare: I created an interactive dashboard in Excel, allowing users to explore sales trends based on their preferences.\nAnalyze: I visualized the data, identifying patterns and drawing meaningful conclusions.\nAct: Our insights informed strategic decisions for Synergy Ltd.\n\n\n\n\nOur interactive dashboard fulfills the following requirements:\n\nUsers can select specific years, regions, platforms, and genres to compare sales trends.\nThe dashboard displays the top 5 game genres and platforms by sales, corresponding to the chosen criteria.\nIt provides the percentage of sales for genres and platforms based on selected years and regions among other things.\n\n\n\n\n\n\n\n\n\n\nIn conclusion, the video game sales analysis for Synergy Ltd. has yielded valuable insights into the gaming industry:\n\nInsights:\n\nNorth America dominated video game sales and Europe and Japan follow closely.\nAction and Sports genres lead in sales.\nPlayStation and Xbox platforms remain popular globally.\nSales reached a peak in the year 2008 at $678.9M, followed by gradual decline."
  },
  {
    "objectID": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#introduction",
    "href": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#introduction",
    "title": "Video Game Sales Analysis for Synergy Ltd.",
    "section": "Introduction",
    "text": "Introduction\nIn this data analytics project, I delve into the fascinating world of video game sales at Synergy Sales. The goal is to explore trends, patterns, and insights related to video game sales worldwide. The dataset spans from 1980 to 2020, covering various regions, genres, and gaming platforms. By meticulously analyzing this data, I aim to provide valuable business insights for Synergy Ltd."
  },
  {
    "objectID": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#overview",
    "href": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#overview",
    "title": "Video Game Sales Analysis for Synergy Ltd.",
    "section": "Overview",
    "text": "Overview\nThe analysis revolves around answering critical questions:\n\nWhich market has the highest video game sales from 1980 to 2020?\nWhat are the total sales of the top 5 game genres and top 5 platforms worldwide during this period?\nWhich game genres dominated different regions from 1980 to 2020?\nHow did the total sales trend evolve globally during specific time periods?"
  },
  {
    "objectID": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#data-source",
    "href": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#data-source",
    "title": "Video Game Sales Analysis for Synergy Ltd.",
    "section": "Data Source",
    "text": "Data Source\nThe dataset used is sourced from Kaggle and contains information on video games with sales exceeding 16,000 copies. It includes essential fields such as:\n\nRank: Overall sales ranking\nName: Game title\nPlatform: Release platform (e.g., PC, PS4)\nYear: Year of the game’s release"
  },
  {
    "objectID": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#methodology",
    "href": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#methodology",
    "title": "Video Game Sales Analysis for Synergy Ltd.",
    "section": "Methodology",
    "text": "Methodology\nI followed a structured approach, adhering to the six steps of the data analysis process:\n\nAsk: I defined the problem, communicated with stakeholders, and understood the business context. Synergy Ltd. requested an interactive dashboard showcasing game sales trends by region, genre, and platform.\nPrepare: I obtained the dataset, ensuring data integrity and cleanliness. Our primary analysis occurred on a duplicate worksheet to preserve the original data.\nProcess: I cleaned and transformed the data, preparing it for visualization.\nShare: I created an interactive dashboard in Excel, allowing users to explore sales trends based on their preferences.\nAnalyze: I visualized the data, identifying patterns and drawing meaningful conclusions.\nAct: Our insights informed strategic decisions for Synergy Ltd.\nExamine the Dataset\nA peek into the data; the first 10 rows of data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRank\nName\nPlatform\nYear\nGenre\nPublisher\nNA_Sales\nEU_Sales\nJP_Sales\nOther_Sales\nGlobal_Sales\n\n\n\n\n1\nWii Sports\nWii\n2006\nSports\nNintendo\n$41,490,000\n$29,020,000\n$3,770,000.00\n$8,460,000\n$82,740,000\n\n\n2\nSuper Mario Bros.\nNES\n1985\nPlatform\nNintendo\n$29,080,000\n$3,580,000\n$6,810,000.00\n$770,000\n$40,240,000\n\n\n3\nMario Kart Wii\nWii\n2008\nRacing\nNintendo\n$15,850,000\n$12,880,000\n$3,790,000.00\n$3,310,000\n$35,820,000\n\n\n4\nWii Sports Resort\nWii\n2009\nSports\nNintendo\n$15,750,000\n$11,010,000\n$3,280,000.00\n$2,960,000\n$33,000,000\n\n\n5\nPokemon Red/Pokemon Blue\nGB\n1996\nRole-Playing\nNintendo\n$11,270,000\n$8,890,000\n$10,220,000.00\n$1,000,000\n$31,370,000\n\n\n6\nTetris\nGB\n1989\nPuzzle\nNintendo\n$23,200,000\n$2,260,000\n$4,220,000.00\n$580,000\n$30,260,000\n\n\n7\nNew Super Mario Bros.\nDS\n2006\nPlatform\nNintendo\n$11,380,000\n$9,230,000\n$6,500,000.00\n$2,900,000\n$30,010,000\n\n\n8\nWii Play\nWii\n2006\nMisc\nNintendo\n$14,030,000\n$9,200,000\n$2,930,000.00\n$2,850,000\n$29,020,000\n\n\n9\nNew Super Mario Bros. Wii\nWii\n2009\nPlatform\nNintendo\n$14,590,000\n$7,060,000\n$4,700,000.00\n$2,260,000\n$28,620,000\n\n\n10\nDuck Hunt\nNES\n1984\nShooter\nNintendo\n$26,930,000\n$630,000\n$280,000.00\n$470,000\n$28,310,000"
  },
  {
    "objectID": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#key-dashboard-requirements",
    "href": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#key-dashboard-requirements",
    "title": "Video Game Sales Analysis for Synergy Ltd.",
    "section": "Key Dashboard Requirements",
    "text": "Key Dashboard Requirements\nOur interactive dashboard fulfills the following requirements:\n\nUsers can select specific years, regions, platforms, and genres to compare sales trends.\nThe dashboard displays the top 5 game genres and platforms by sales, corresponding to the chosen criteria.\nIt provides the percentage of sales for genres and platforms based on selected years and regions among other things."
  },
  {
    "objectID": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#conclusion",
    "href": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#conclusion",
    "title": "Video Game Sales Analysis for Synergy Ltd.",
    "section": "Conclusion",
    "text": "Conclusion\nIn conclusion, the video game sales analysis for Synergy Ltd. has yielded valuable insights into the gaming industry:\n\nInsights:\n\nNorth America dominated video game sales and Europe and Japan follow closely.\nAction and Sports genres lead in sales.\nPlayStation and Xbox platforms remain popular globally.\nSales reached a peak in the year 2008 at $678.9M, followed by gradual decline."
  },
  {
    "objectID": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#dashboard",
    "href": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#dashboard",
    "title": "Video Game Sales Analysis for Synergy Ltd.",
    "section": "Dashboard",
    "text": "Dashboard"
  },
  {
    "objectID": "Excel Projects/ISRPAL/isrpal.html",
    "href": "Excel Projects/ISRPAL/isrpal.html",
    "title": "FATALITIES IN THE ISRAEL-PALESTINE CONFLICT: 2000-2023 ANALYSIS",
    "section": "",
    "text": "The Israel-Palestine conflict has spanned decades, resulting in significant loss of life. The analysis aims to explore fatality trends, identify patterns, and provide insights based on the available data.\nThe Israel-Palestine conflict from 2000 to 2023 was a period marked by significant events and escalating tensions.This period was characterized by a cycle of violence and attempts at peace negotiations. It’s important to note that this is a complex issue with deep historical roots and differing narratives.The specific causes of the conflict during 2000-2003 are multifaceted and include:\n1. Al-Aqsa Intifada (2000)\n2. Failed Peace Negotiations (2000)\n3. Political Changes (2001)\n4. Violence and Retaliation (2002)\n5. Roadmap for Peace (2003)\n\n\n\n\nData Source: The dataset, sourced from Kaggle, contains information about fatalities in the Israel-Palestine conflict. Each record represents an individual who lost their life during specific incidents.\nFields:\n\nDate: The date of the incident.\nLocation: Where the incident occurred (e.g., Gaza, West Bank).\nFatalities: The number of people killed.\nCitizenship:The Citizenship of fatalities recorded\nPerpetrator: The group responsible (e.g., IDF, Hamas).\nTarget: The affected group (e.g., civilians, militants)\n\n\n\n\n\n\nTemporal Trends: How have fatalities evolved over time? Are there specific periods of heightened violence?\nGeographical Patterns: Which regions (Gaza, West Bank, etc.) have experienced the most fatalities?\nPerpetrators and Targets: Who are the main perpetrators, and who bears the brunt of the violence (civilians, militants, etc.)?\n\n\n\n\n\n\n\n\n\nImportant!!!\n\n\n\nRight-click on image to open dashboard in new tab, if content too tiny"
  },
  {
    "objectID": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#section",
    "href": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#section",
    "title": "Video Game Sales Analysis for Synergy Ltd.",
    "section": "",
    "text": "Important!!!\n\n\n\nRight-click on image to open dashboard in new tab, if content too tiny\n\n\n\nTo interact with the Excel Dashboard, click here"
  },
  {
    "objectID": "Excel Projects/ISRPAL/isrpal.html#conclusion",
    "href": "Excel Projects/ISRPAL/isrpal.html#conclusion",
    "title": "Fatalities in the Israel-Palestine Conflict: 2000-2023 Analysis",
    "section": "Conclusion",
    "text": "Conclusion\nIn conclusion, the Israel-Palestine analysis has yielded valuable insights into the deaths recorded and how distributed they are:\n\nInsights:\n\nPalestinians suffered a high fatality count at 10,092 and only 1 American Died.\n2014 is peak year for highest death toll at 2326.\nOver 9000 people died by Gunfire losely followed by Explosion at 555\n\n\n\n\nThese insights can guide strategic decisions for conflict resolution efforts. 🕊️🌍"
  },
  {
    "objectID": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#recommendations",
    "href": "Excel Projects/SYNERGY VIDEO GAME/synergy.html#recommendations",
    "title": "Video Game Sales Analysis for Synergy Ltd.",
    "section": "Recommendations",
    "text": "Recommendations\n1. Regions aside from Europe, Japan and North America should be looked into as to why Video Game purchases are not made and strategic marketing of these video games should be upped in the region\n2. I strongly advise that marketing and promotion be reinforced to resolve the issue of low sales for Game Genres and less purchased games.\n3. Collaborations with brands and sponsorship deals can help Game Platforms and Publishers with low sales."
  },
  {
    "objectID": "Excel Projects/ISRPAL/isrpal.html#introduction",
    "href": "Excel Projects/ISRPAL/isrpal.html#introduction",
    "title": "Fatalities in the Israel-Palestine Conflict: 2000-2023 Analysis",
    "section": "Introduction",
    "text": "Introduction\nThe Israel-Palestine conflict has spanned decades, resulting in significant loss of life. The analysis aims to explore fatality trends, identify patterns, and provide insights based on the available data.\nThe Israel-Palestine conflict from 2000 to 2023 was a period marked by significant events and escalating tensions.This period was characterized by a cycle of violence and attempts at peace negotiations. It’s important to note that this is a complex issue with deep historical roots and differing narratives.The specific causes of the conflict during 2000-2023 are multifaceted and include:\n1. Al-Aqsa Intifada (2000)\n2. Failed Peace Negotiations (2000)\n3. Political Changes (2001)\n4. Violence and Retaliation (2002)\n5. Roadmap for Peace (2003)\nBeyond 2003, the conflict persisted with sporadic violence, peace talks, and ongoing tensions. Efforts toward a lasting resolution continued, but obstacles remained, including territorial disputes, security concerns, and differing visions for the future."
  },
  {
    "objectID": "Excel Projects/ISRPAL/isrpal.html#methodology",
    "href": "Excel Projects/ISRPAL/isrpal.html#methodology",
    "title": "Fatalities in the Israel-Palestine Conflict: 2000-2023 Analysis",
    "section": "Methodology",
    "text": "Methodology\nI followed a structured approach, adhering to the six steps of the data analysis process:\n\nDefine Objective and Stakeholders: Clearly state the goal (analyze Israel-Palestine fatalities) and identify who needs this information (researchers, policymakers).\nCollect and Validate Data: Get the fatality dataset and ensure it’s accurate.\nClean and Transform Data: Fix any issues in the data and make it ready for analysis.\nCreate Interactive Dashboard: Build a user-friendly tool for exploring the data.\nVisualize Trends: Use charts to see patterns (e.g., fatalities over time).\nDraw Conclusions: Analyze findings (e.g., age disparities, regional impact).\nInform Decisions: Share insights to guide conflict resolution efforts. 🌍🔍\nExamine the Dataset\nA peek into the data; the first 10 rows of data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\ndate_of_event\nage\ncitizenship\nevent_location\nevent_location_district\nevent_location_region\ndate_of_death\ngender\ntook_part_in_the_hostilities\nplace_of_residence\nplace_of_residence_district\ntype_of_injury\nammunition\nkilled_by\n\n\n\n\n’Abd a-Rahman Suleiman Muhammad Abu Daghash\n24/09/2023\n32\nPalestinian\nNur Shams R.C.\nTulkarm\nWest Bank\n24/09/2023\nM\nNA\nNur Shams R.C.\nTulkarm\ngunfire\nlive ammunition\nIsraeli security forces\n\n\nUsayed Farhan Muhammad ’Ali Abu ’Ali\n24/09/2023\n21\nPalestinian\nNur Shams R.C.\nTulkarm\nWest Bank\n24/09/2023\nM\nNA\nNur Shams R.C.\nTulkarm\ngunfire\nlive ammunition\nIsraeli security forces\n\n\n’Abdallah ’Imad Sa’ed Abu Hassan\n22/09/2023\n16\nPalestinian\nKfar Dan\nJenin\nWest Bank\n22/09/2023\nM\nNA\nal-Yamun\nJenin\ngunfire\nlive ammunition\nIsraeli security forces\n\n\nDurgham Muhammad Yihya al-Akhras\n20/09/2023\n19\nPalestinian\n’Aqbat Jaber R.C.\nJericho\nWest Bank\n20/09/2023\nM\nNA\n’Aqbat Jaber R.C.\nJericho\ngunfire\nlive ammunition\nIsraeli security forces\n\n\nRaafat ’Omar Ahmad Khamaisah\n19/09/2023\n15\nPalestinian\nJenin R.C.\nJenin\nWest Bank\n19/09/2023\nM\nNA\nJenin\nJenin\ngunfire\nlive ammunition\nIsraeli security forces\n\n\n’Ata Yasser ’Ata Musa\n19/09/2023\n29\nPalestinian\nJenin R.C.\nJenin\nWest Bank\n20/09/2023\nM\nNA\nJenin\nJenin\ngunfire\nmissile\nIsraeli security forces\n\n\nYusef Salem Yusef Radwan\n19/09/2023\n24\nPalestinian\nGaza City\nGaza\nGaza Strip\n19/09/2023\nM\nNo\nKhan Yunis\nKhan Yunis\ngunfire\nlive ammunition\nIsraeli security forces\n\n\nMahmoud Khaled S’ud ’Ar’arawi\n19/09/2023\n25\nPalestinian\nJenin R.C.\nJenin\nWest Bank\n19/09/2023\nM\nNA\nJenin R.C.\nJenin\ngunfire\nmissile\nIsraeli security forces\n\n\nMahmoud ’Ali Nafe’a a-S’adi\n19/09/2023\n23\nPalestinian\nJenin R.C.\nJenin\nWest Bank\n19/09/2023\nM\nNA\nJenin R.C.\nJenin\ngunfire\nmissile\nIsraeli security forces\n\n\nMilad Munzer Wajih a-Ra’i\n09/09/2023\n15\nPalestinian\nal-’Arrub R.C.\nHebron\nWest Bank\n09/09/2023\nM\nNA\nal-’Arrub Camp\nHebron\ngunfire\nlive ammunition\nIsraeli security forces"
  },
  {
    "objectID": "Excel Projects/ISRPAL/isrpal.html#key-dashboard-requirements",
    "href": "Excel Projects/ISRPAL/isrpal.html#key-dashboard-requirements",
    "title": "Fatalities in the Israel-Palestine Conflict: 2000-2023 Analysis",
    "section": "Key Dashboard Requirements",
    "text": "Key Dashboard Requirements\n\nKey Questions\n\nTemporal Trends: How have fatalities evolved over time? Are there specific periods of heightened violence?\nGeographical Patterns: Which regions (Gaza, West Bank, etc.) have experienced the most fatalities?\nPerpetrators and Targets: Who are the main perpetrators, and who bears the brunt of the violence (civilians, militants, etc.)?"
  },
  {
    "objectID": "Excel Projects/ISRPAL/isrpal.html#overview",
    "href": "Excel Projects/ISRPAL/isrpal.html#overview",
    "title": "Fatalities in the Israel-Palestine Conflict: 2000-2023 Analysis",
    "section": "Overview",
    "text": "Overview\nData Source: The dataset, sourced from Kaggle, contains information about fatalities in the Israel-Palestine conflict. Each record represents an individual who lost their life during specific incidents.\nThis dataset on fatalities related to the Israel-Palestine conflict can be explored to gain insights such as :\nInsights:\n\nFatality Trends\nDemographic Analysis\nGeospatial Analysis\nHostilities Participation Analysis\nWeapons Used\nPerpetrator Profiles"
  },
  {
    "objectID": "Excel Projects/ISRPAL/isrpal.html#dashboard",
    "href": "Excel Projects/ISRPAL/isrpal.html#dashboard",
    "title": "Fatalities in the Israel-Palestine Conflict: 2000-2023 Analysis",
    "section": "Dashboard",
    "text": "Dashboard\n\n\n\n\n\n\n\nImportant!!!\n\n\n\nRight-click on image to open dashboard in new tab, if content too tiny\n\n\n\nTo interact with the Excel Dashboard, click here"
  },
  {
    "objectID": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#introduction",
    "href": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#introduction",
    "title": "Quantum Sales Solutions Analysis",
    "section": "Introduction",
    "text": "Introduction\nWelcome to the Quantum Sales Solutions dataset documentation! In this comprehensive guide, we explore the captivating world of beverage and snack sales, focusing on the year 2023. Whether you’re a data analyst, a business strategist, or simply curious about the flavors that defined that era, this documentation promises valuable insights."
  },
  {
    "objectID": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#overview",
    "href": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#overview",
    "title": "Quantum Sales Solutions Analysis",
    "section": "Overview",
    "text": "Overview\nQuantum Sales Solutions, a dynamic player in the market, orchestrates the distribution and delight of delectable treats. The dataset spans the year 2023 and encompasses a rich tapestry of products, regions, and consumer preferences. Let’s dive into the pixelated aisles of Quantum Sales Solutions and uncover the stories behind the sales for the year."
  },
  {
    "objectID": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#data-source",
    "href": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#data-source",
    "title": "Quantum Sales Solutions Analysis",
    "section": "Data Source",
    "text": "Data Source\nThe dataset for this project was meticulously collected by Quantum Sales Solutions. It captures transactions, quantities, and other relevant information related to beverages, dried fruits, nuts, candy, and soups.This dataset has been cleaned, organized, and prepared for analysis."
  },
  {
    "objectID": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#methodology",
    "href": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#methodology",
    "title": "Quantum Sales Solutions Analysis",
    "section": "Methodology",
    "text": "Methodology\nI followed a structured approach, adhering to the six steps of the data analysis process:\n\nAsk: I defined the problem, communicated with stakeholders, and understood the business context. Synergy Ltd. requested an interactive dashboard showcasing game sales trends by region, genre, and platform.\nPrepare: I obtained the dataset, ensuring data integrity and cleanliness. Our primary analysis occurred on a duplicate worksheet to preserve the original data.\nProcess: I cleaned and transformed the data, preparing it for visualization.\nShare: I created an interactive dashboard in Excel, allowing users to explore sales trends based on their preferences.\nAnalyze: I visualized the data, identifying patterns and drawing meaningful conclusions.\nAct: Our insights informed strategic decisions for Synergy Ltd.\nExamine the Dataset\nA peek into the data; the first 10 rows of data:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOrder ID\nOrder Date\nCustomer ID\nCustomer Name\nAddress\nCity\nState\nZIP/Postal Code\nCountry/Region\nSalesperson\nRegion\nShipped Date\nShipper Name\nShip Name\nShip Address\nShip City\nShip State\nShip ZIP/Postal Code\nShip Country/Region\nPayment Type\nProduct Name\nCategory\nUnit Price\nQuantity\nRevenue\nShipping Fee\n\n\n\n\n1001\n01/27/14\n27\nCompany AA\n789 27th Street\nLas Vegas\nNV\n99999\nUSA\nMariya Sergienko\nWest\n01/29/14\nShipping Company B\nKaren Toh\n789 27th Street\nLas Vegas\nNV\n99999\nUSA\nCheck\nBeer\nBeverages\n$14.00\n49\n$686.00\n$66.54\n\n\n1002\n01/27/14\n27\nCompany AA\n789 27th Street\nLas Vegas\nNV\n99999\nUSA\nMariya Sergienko\nWest\n01/29/14\nShipping Company B\nKaren Toh\n789 27th Street\nLas Vegas\nNV\n99999\nUSA\nCheck\nDried Plums\nDried Fruit & Nuts\n$3.50\n47\n$164.50\n$16.61\n\n\n1003\n01/04/2014\n4\nCompany D\n123 4th Street\nNew York\nNY\n99999\nUSA\nAndrew Cencini\nEast\n01/06/2014\nShipping Company A\nChristina Lee\n123 4th Street\nNew York\nNY\n99999\nUSA\nCredit Card\nDried Pears\nDried Fruit & Nuts\n$30.00\n69\n$2,070.00\n$198.72\n\n\n1004\n01/04/2014\n4\nCompany D\n123 4th Street\nNew York\nNY\n99999\nUSA\nAndrew Cencini\nEast\n01/06/2014\nShipping Company A\nChristina Lee\n123 4th Street\nNew York\nNY\n99999\nUSA\nCredit Card\nDried Apples\nDried Fruit & Nuts\n$53.00\n89\n$4,717.00\n$448.12\n\n\n1005\n01/04/2014\n4\nCompany D\n123 4th Street\nNew York\nNY\n99999\nUSA\nAndrew Cencini\nEast\n01/06/2014\nShipping Company A\nChristina Lee\n123 4th Street\nNew York\nNY\n99999\nUSA\nCredit Card\nDried Plums\nDried Fruit & Nuts\n$3.50\n11\n$38.50\n$3.73\n\n\n1006\n01/12/2014\n12\nCompany L\n123 12th Street\nLas Vegas\nNV\n99999\nUSA\nMariya Sergienko\nWest\n01/14/14\nShipping Company B\nJohn Edwards\n123 12th Street\nLas Vegas\nNV\n99999\nUSA\nCredit Card\nChai\nBeverages\n$18.00\n81\n$1,458.00\n$141.43\n\n\n1007\n01/12/2014\n12\nCompany L\n123 12th Street\nLas Vegas\nNV\n99999\nUSA\nMariya Sergienko\nWest\n01/14/14\nShipping Company B\nJohn Edwards\n123 12th Street\nLas Vegas\nNV\n99999\nUSA\nCredit Card\nCoffee\nBeverages\n$46.00\n44\n$2,024.00\n$198.35\n\n\n1008\n01/08/2014\n8\nCompany H\n123 8th Street\nPortland\nOR\n99999\nUSA\nNancy Freehafer\nNorth\n01/10/2014\nShipping Company C\nElizabeth Andersen\n123 8th Street\nPortland\nOR\n99999\nUSA\nCredit Card\nChocolate Biscuits Mix\nBaked Goods & Mixes\n$9.20\n38\n$349.60\n$36.01\n\n\n1009\n01/04/2014\n4\nCompany D\n123 4th Street\nNew York\nNY\n99999\nUSA\nAndrew Cencini\nEast\n01/06/2014\nShipping Company C\nChristina Lee\n123 4th Street\nNew York\nNY\n99999\nUSA\nCheck\nChocolate Biscuits Mix\nBaked Goods & Mixes\n$9.20\n88\n$809.60\n$79.34\n\n\n1010\n01/29/14\n29\nCompany CC\n789 29th Street\nDenver\nCO\n99999\nUSA\nJan Kotas\nWest\n01/31/14\nShipping Company B\nSoo Jung Lee\n789 29th Street\nDenver\nCO\n99999\nUSA\nCheck\nChocolate\nCandy\n$12.75\n94\n$1,198.50\n$122.25"
  },
  {
    "objectID": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#key-dashboard-requirements",
    "href": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#key-dashboard-requirements",
    "title": "Quantum Sales Solutions Analysis",
    "section": "Key Dashboard Requirements",
    "text": "Key Dashboard Requirements\n\nThe interactive dashboard fulfills the following requirements:\n\nUsers can select Customers that patronize Quantum Sales Solutions, Regions, Products and Cities to compare sales trends.\nThe dashboard displays the top 7 Salespersons, Sales by Product Category corresponding to the chosen criteria."
  },
  {
    "objectID": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#dashboard",
    "href": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#dashboard",
    "title": "Quantum Sales Solutions Analysis",
    "section": "Dashboard",
    "text": "Dashboard\n\n\n\n\n\n\n\nImportant!!!\n\n\n\nRight-click on image to open dashboard in new tab, if content too tiny\n\n\n\nTo interact with the Excel Dashboard, click here"
  },
  {
    "objectID": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#recommendations",
    "href": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#recommendations",
    "title": "Quantum Sales Solutions Analysis",
    "section": "Recommendations",
    "text": "Recommendations\n\nRecognize top performers like Nancy Freehafer with rewards and provide training opportunities for those underperforming to improve their skills.\nPromote top-selling product categories more prominently, and analyze low-performing categories for potential improvements or discontinuation.\nDevelop growth strategies for regions that are underperforming like in the West and Increase investment in high-performing regions"
  },
  {
    "objectID": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#conclusion",
    "href": "Excel Projects/QUANTUM SALES SOLUTIONS/quantumsales.html#conclusion",
    "title": "Quantum Sales Solutions Analysis",
    "section": "Conclusion",
    "text": "Conclusion\nIn conclusion, the product sales analysis for Quantum Sales Solutions has yielded valuable insights into the sales for the year 2023:\n\nInsights:\n\nThe North had more Sales garnering 32% of total sales .\nBeverages sold the most at ₦110,577\nDecember grossed highest sales by month at ₦66,643\nSales for the year 2023 totaled the sum of ₦435,036"
  },
  {
    "objectID": "R Projects/audible/audible.html#authornarrator",
    "href": "R Projects/audible/audible.html#authornarrator",
    "title": "Audible Data Cleaning",
    "section": "Author and Narrator Columns",
    "text": "Author and Narrator Columns\nThe Author and Narrator columns contain the names of the Authors and Narrators of the Audiobooks.\n\n#select Author and Narrator columns\naudible %&gt;% select(author,narrator) %&gt;% head(10) %&gt;%kable()\n\n\n\n\nauthor\nnarrator\n\n\n\n\nWrittenby:GeronimoStilton\nNarratedby:BillLobely\n\n\nWrittenby:RickRiordan\nNarratedby:RobbieDaymond\n\n\nWrittenby:JeffKinney\nNarratedby:DanRussell\n\n\nWrittenby:RickRiordan\nNarratedby:SoneelaNankani\n\n\nWrittenby:RickRiordan\nNarratedby:JesseBernstein\n\n\nWrittenby:SuzanneCollins\nNarratedby:TatianaMaslany\n\n\nWrittenby:WinterMorgan\nNarratedby:LukeDaniels\n\n\nWrittenby:RickRiordan\nNarratedby:RobbieDaymond\n\n\nWrittenby:MaryPopeOsborne\nNarratedby:MaryPopeOsborne\n\n\nWrittenby:RickRiordan\nNarratedby:RobbieDaymond\n\n\n\n\n\nThese columns in the dataset have a common issue known as string concatenation errors. This occurs when two or more strings are joined together without appropriate spacing or delimiters. In this case, the names of authors and narrators are concatenated without spaces, making it difficult to distinguish between first and last names.\nAdditionally, the strings ‘Writtenby:’ and ‘Narratedby:’ are concatenated with the names, adding unnecessary clutter to our data; hence the need to remove unnecessary strings and add spaces between the names using regular expressions.\n\n\n#author and narrator column cleaned of unwanted characters and spaces added where necessary\naudible&lt;-audible %&gt;%mutate_at(vars(author,narrator),\n  ~if_else(str_detect(.,\"(Writtenby:)|(Narratedby:)\"),\n        str_replace_all(str_remove(.,\"(Writtenby:)|(Narratedby:)|\\\\d+\"),\n                        \"(?&lt;=[a-z])(?=[A-Z])\", \" \"),\n        .)\n  )\n\n\ncross-check\nIt becomes important to check the content of these columns after performing the operation\n\n\naudible %&gt;% select(author,narrator) %&gt;% head(5) %&gt;% kable()\n\n\n\n\nauthor\nnarrator\n\n\n\n\nGeronimo Stilton\nBill Lobely\n\n\nRick Riordan\nRobbie Daymond\n\n\nJeff Kinney\nDan Russell\n\n\nRick Riordan\nSoneela Nankani\n\n\nRick Riordan\nJesse Bernstein"
  },
  {
    "objectID": "R Projects/audible/audible.html#time",
    "href": "R Projects/audible/audible.html#time",
    "title": "Audible Data Cleaning",
    "section": "Time Column",
    "text": "Time Column\nThe Time column is the total duration of each audiobook\n\naudible %&gt;% select(time) %&gt;% head(5) %&gt;%kable()\n\n\n\n\ntime\n\n\n\n\n2 hrs and 20 mins\n\n\n13 hrs and 8 mins\n\n\n2 hrs and 3 mins\n\n\n11 hrs and 16 mins\n\n\n10 hrs\n\n\n\n\n\nIt is a column of string datatype and the contents are needed to be extracted and typecasted to numeric values to aid further analysis.\n\n# Create new columns off the time column and typecast to numeric \naudible &lt;- audible %&gt;%\n  mutate(\n    # Extract hours and minutes into separate columns\n    hours = as.numeric(str_extract(time, \"\\\\d+(?=\\\\s*hr)\")),\n    minutes = as.numeric(str_extract(time, \"\\\\d+(?=\\\\s*min)\")),\n    \n    # Convert time to seconds\n    time_seconds = case_when(\n      str_detect(time, \"hrs|hr\") & !str_detect(time, \"mins|min\") ~\n        as.numeric(str_extract(time, \"\\\\d+(?=\\\\s*hr)\")) * 3600,\n      str_detect(time, \"hrs|hr\") & str_detect(time, \"min|mins\") ~\n        as.numeric(str_extract(time, \"\\\\d+(?=\\\\s*hr)\")) * 3600 +\n        as.numeric(str_extract(time, \"\\\\d+(?=\\\\s*min)\")) * 60,\n      str_detect(time, \"mins|min\") ~\n        as.numeric(str_extract(time, \"\\\\d+\")) * 60,\n      TRUE ~ as.numeric(time)\n    )\n  )\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `time_seconds = case_when(...)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\n\n\n\n\n\n\nNA values\n\n\n\nThe NA values are introduced because there are some observations that may not have either hours or minutes. In such instances, since there is no hour or minute to extract as the case may be, the newly created ‘hours’ or ‘minutes’ columns return NA. This is a common occurrence in data processing when the expected data is not present in certain observations. And to handle such instances, NA values are replaced with zero\n\n\n\n# Handle NA values (if there are cases like \"2 hours\" with no mins or \"45 mins\" with no hours)\naudible$hours[is.na(audible$hours)] &lt;- 0\naudible$minutes[is.na(audible$minutes)] &lt;- 0 \n\ncross-check\n\naudible %&gt;% select(time,hours,minutes,time_seconds) %&gt;% head(6) %&gt;% kable()\n\n\n\n\ntime\nhours\nminutes\ntime_seconds\n\n\n\n\n2 hrs and 20 mins\n2\n20\n8400\n\n\n13 hrs and 8 mins\n13\n8\n47280\n\n\n2 hrs and 3 mins\n2\n3\n7380\n\n\n11 hrs and 16 mins\n11\n16\n40560\n\n\n10 hrs\n10\n0\n36000\n\n\n10 hrs and 35 mins\n10\n35\n38100"
  },
  {
    "objectID": "R Projects/audible/audible.html#releasedate",
    "href": "R Projects/audible/audible.html#releasedate",
    "title": "Audible Data Cleaning",
    "section": "Release Date Column",
    "text": "Release Date Column\nThe Release Date Column just as the name implies is the release date of each and every audiobook contained in the dataset.\n\naudible %&gt;% select(releasedate) %&gt;% head(5) %&gt;% kable()\n\n\n\n\nreleasedate\n\n\n\n\n04-08-08\n\n\n01-05-18\n\n\n06-11-20\n\n\n05-10-21\n\n\n13-01-10\n\n\n\n\n\nIt is of string datatype, hence the need to convert to Date in its truest form.\n\n#converted releasedate column of data type string to date as should be\naudible$releasedate&lt;- as.Date(audible$releasedate,format=\"%d-%m-%y\")\n#Extract the Year COlumn from the releasedate Column\naudible&lt;-audible %&gt;%mutate(Year=year(audible$releasedate)) \n\n\nstr(audible$releasedate)\n\n Date[1:87489], format: \"2008-08-04\" \"2018-05-01\" \"2020-11-06\" \"2021-10-05\" \"2010-01-13\" ..."
  },
  {
    "objectID": "R Projects/audible/audible.html#stars",
    "href": "R Projects/audible/audible.html#stars",
    "title": "Audible Data Cleaning",
    "section": "Stars Column",
    "text": "Stars Column\nThe Stars Column represents the average rating given by users for a particular audiobook. It has a band of 1 to 5. But during scraping of the data, the rating was scraped into the same column as the stars bringing about a string concatenation error. There should be a separate rating column that represents the number of users who have rated the audiobook.\n\naudible %&gt;% select(stars) %&gt;% head(6)\n\n# A tibble: 6 × 1\n  stars                        \n  &lt;chr&gt;                        \n1 5 out of 5 stars34 ratings   \n2 4.5 out of 5 stars41 ratings \n3 4.5 out of 5 stars38 ratings \n4 4.5 out of 5 stars12 ratings \n5 4.5 out of 5 stars181 ratings\n6 5 out of 5 stars72 ratings   \n\n\n\n#split stars column into Stars and Rating Column,remove unwanted characters and convert columns to numeric \n  audible &lt;- audible %&gt;% \n    separate(stars, into = c(\"Stars\", \"Rating\"), sep = \"out of 5 stars\") %&gt;% \n    mutate(\n      Stars = as.numeric(str_remove_all(Stars, \" \")),\n      Rating = as.numeric(str_remove_all(Rating, \",|ratings\"))\n    ) %&gt;% \n    mutate_at(\n      vars(Stars, Rating),\n      ~if_else(is.na(.), 0, .)\n    )\n\ncross-check\n\naudible %&gt;% select(Stars,Rating) %&gt;% head(7) %&gt;% kable()\n\n\n\n\nStars\nRating\n\n\n\n\n5.0\n34\n\n\n4.5\n41\n\n\n4.5\n38\n\n\n4.5\n12\n\n\n4.5\n181\n\n\n5.0\n72\n\n\n5.0\n11"
  },
  {
    "objectID": "R Projects/audible/audible.html#price-column",
    "href": "R Projects/audible/audible.html#price-column",
    "title": "Audible Data Cleaning",
    "section": "Price Column",
    "text": "Price Column\nThe Price column represents the price of the audiobook.\n\naudible %&gt;% select(price) %&gt;% head(10) \n\n# A tibble: 10 × 1\n   price   \n   &lt;chr&gt;   \n 1 468.00  \n 2 820.00  \n 3 410.00  \n 4 615.00  \n 5 820.00  \n 6 656.00  \n 7 233.00  \n 8 820.00  \n 9 1,256.00\n10 820.00  \n\n\nThis column is of string datatype and it has some unwanted characters such as the , and Free indicating that these books come at no cost at all.\n\naudible %&gt;% select(price) %&gt;% filter(price==\"Free\")%&gt;% head(3)\n\n# A tibble: 3 × 1\n  price\n  &lt;chr&gt;\n1 Free \n2 Free \n3 Free \n\n\nIt is imperative to remove these characters and typecast the data type\n\n  audible &lt;- audible %&gt;% mutate(\n    price = case_when(\n      str_detect(price, \",\") ~ as.numeric(str_remove(price, \",\")),\n      str_detect(price, \"Free\") ~ as.numeric(str_remove(price, \"Free\")),\n      TRUE ~ as.numeric(price)\n    ),price=if_else(is.na(price),0,price)\n  )\n\ncross-check\n\naudible %&gt;% select(price) %&gt;% head(10)\n\n# A tibble: 10 × 1\n   price\n   &lt;dbl&gt;\n 1   468\n 2   820\n 3   410\n 4   615\n 5   820\n 6   656\n 7   233\n 8   820\n 9  1256\n10   820"
  },
  {
    "objectID": "R Projects/audible/audible.html#subsetting",
    "href": "R Projects/audible/audible.html#subsetting",
    "title": "Audible Data Cleaning",
    "section": "Subsetting Needed Columns",
    "text": "Subsetting Needed Columns\nSelecting useful columns\n\naudible %&gt;% select(name:time,hours:time_seconds,releasedate,Year,language,Stars:price) %&gt;% head(10) %&gt;% kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\nauthor\nnarrator\ntime\nhours\nminutes\ntime_seconds\nreleasedate\nYear\nlanguage\nStars\nRating\nprice\n\n\n\n\nGeronimo Stilton #11 & #12\nGeronimo Stilton\nBill Lobely\n2 hrs and 20 mins\n2\n20\n8400\n2008-08-04\n2008\nEnglish\n5.0\n34\n468\n\n\nThe Burning Maze\nRick Riordan\nRobbie Daymond\n13 hrs and 8 mins\n13\n8\n47280\n2018-05-01\n2018\nEnglish\n4.5\n41\n820\n\n\nThe Deep End\nJeff Kinney\nDan Russell\n2 hrs and 3 mins\n2\n3\n7380\n2020-11-06\n2020\nEnglish\n4.5\n38\n410\n\n\nDaughter of the Deep\nRick Riordan\nSoneela Nankani\n11 hrs and 16 mins\n11\n16\n40560\n2021-10-05\n2021\nEnglish\n4.5\n12\n615\n\n\nThe Lightning Thief: Percy Jackson, Book 1\nRick Riordan\nJesse Bernstein\n10 hrs\n10\n0\n36000\n2010-01-13\n2010\nEnglish\n4.5\n181\n820\n\n\nThe Hunger Games: Special Edition\nSuzanne Collins\nTatiana Maslany\n10 hrs and 35 mins\n10\n35\n38100\n2018-10-30\n2018\nEnglish\n5.0\n72\n656\n\n\nQuest for the Diamond Sword\nWinter Morgan\nLuke Daniels\n2 hrs and 23 mins\n2\n23\n8580\n2014-11-25\n2014\nEnglish\n5.0\n11\n233\n\n\nThe Dark Prophecy\nRick Riordan\nRobbie Daymond\n12 hrs and 32 mins\n12\n32\n45120\n2017-05-02\n2017\nEnglish\n5.0\n50\n820\n\n\nMerlin Mission Collection\nMary Pope Osborne\nMary Pope Osborne\n10 hrs and 56 mins\n10\n56\n39360\n2017-05-02\n2017\nEnglish\n5.0\n5\n1256\n\n\nThe Tyrant’s Tomb\nRick Riordan\nRobbie Daymond\n13 hrs and 22 mins\n13\n22\n48120\n2019-09-24\n2019\nEnglish\n5.0\n58\n820"
  },
  {
    "objectID": "R Projects/audible/audible.html#data-validity",
    "href": "R Projects/audible/audible.html#data-validity",
    "title": "Audible Data Cleaning",
    "section": "Data Validity",
    "text": "Data Validity\nThis is measure to ensure that all columns have the right datatype\n\naudible %&gt;% str()\n\ntibble [87,489 × 13] (S3: tbl_df/tbl/data.frame)\n $ name        : chr [1:87489] \"Geronimo Stilton #11 & #12\" \"The Burning Maze\" \"The Deep End\" \"Daughter of the Deep\" ...\n $ author      : chr [1:87489] \"Geronimo Stilton\" \"Rick Riordan\" \"Jeff Kinney\" \"Rick Riordan\" ...\n $ narrator    : chr [1:87489] \"Bill Lobely\" \"Robbie Daymond\" \"Dan Russell\" \"Soneela Nankani\" ...\n $ time        : chr [1:87489] \"2 hrs and 20 mins\" \"13 hrs and 8 mins\" \"2 hrs and 3 mins\" \"11 hrs and 16 mins\" ...\n $ releasedate : Date[1:87489], format: \"2008-08-04\" \"2018-05-01\" ...\n $ language    : chr [1:87489] \"English\" \"English\" \"English\" \"English\" ...\n $ Stars       : num [1:87489] 5 4.5 4.5 4.5 4.5 5 5 5 5 5 ...\n $ Rating      : num [1:87489] 34 41 38 12 181 72 11 50 5 58 ...\n $ price       : num [1:87489] 468 820 410 615 820 ...\n $ hours       : num [1:87489] 2 13 2 11 10 10 2 12 10 13 ...\n $ minutes     : num [1:87489] 20 8 3 16 0 35 23 32 56 22 ...\n $ time_seconds: num [1:87489] 8400 47280 7380 40560 36000 ...\n $ Year        : num [1:87489] 2008 2018 2020 2021 2010 ..."
  },
  {
    "objectID": "R Projects/audible/audible.html#saving-the-data",
    "href": "R Projects/audible/audible.html#saving-the-data",
    "title": "Audible Data Cleaning",
    "section": "Saving the Data",
    "text": "Saving the Data\n\nwrite.csv(audible,\"C:/Users/SAMMY/Desktop/Audible/audible_cleaned.csv\")"
  },
  {
    "objectID": "R Projects/audible/audible.html#top-5-authors-on-audible",
    "href": "R Projects/audible/audible.html#top-5-authors-on-audible",
    "title": "Audible Data Cleaning",
    "section": "Top 5 Authors on Audible",
    "text": "Top 5 Authors on Audible\n\n# Filter top 5 authors\ntop_authors &lt;- audible %&gt;%\n  group_by(author) %&gt;%\n  summarise(n = n()) %&gt;%\n  arrange(n) %&gt;%\n  top_n(5)\n\nSelecting by n\n\n# Bar plot of top 5 Audible Authors\nggplot(top_authors, aes(x = reorder(author, n), y = n, fill = author)) +\n  geom_bar(stat = \"identity\") +\n   geom_text(aes(label = n), hjust = -0.1, color = \"black\", size = 3.5) +\n  scale_fill_manual(values = c(\"矢島雅弘,石橋遊\"=\"#FFA000\",\"Smart Reading\"=\"#FFB347\",\"中西貴之,BJ\"=\"#FFC680\",\"div.\"=\"#FFDAB3\",\"Online Studio Productions\"=\"#FFEFE0\")) +\n  coord_flip() +\n  labs(x = \"Author\", y = \"Book Count\", title = \"Top 5 Authors in Audible Dataset\") +\n  theme_classic() +\n  theme(legend.position = \"none\",plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "R Projects/audible/audible.html#distribution-of-star-rating",
    "href": "R Projects/audible/audible.html#distribution-of-star-rating",
    "title": "Audible Data Cleaning",
    "section": "Distribution of Star Rating",
    "text": "Distribution of Star Rating\n\nstar_summary &lt;- audible %&gt;%\n  group_by(Stars) %&gt;%\n  summarise(count = n()) %&gt;%\n  arrange(desc(Stars))\n\n# Create the bar plot\nggplot(star_summary, aes(x =reorder(Stars,Stars), y = count)) +\n  geom_bar(stat = \"identity\", fill = \"#FFA000\", color = \"#000000\") +\n  geom_text(aes(label = count), vjust = -.5,hjust=0.5, color= \"black\", size = 3.5)+\n  labs(x = \"Star Rating\", y = \"Count\", title = \"Distribution of Star Ratings\") +\n  theme_classic() +\n  theme(plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "R Projects/audible/audible.html#heatmap-of-books-released-by-year",
    "href": "R Projects/audible/audible.html#heatmap-of-books-released-by-year",
    "title": "Audible Data Cleaning",
    "section": "Heatmap of Books Released By Year",
    "text": "Heatmap of Books Released By Year\n\nunique_years &lt;- unique(audible$Year)\nyear_summary &lt;- audible %&gt;%\n  group_by(Year) %&gt;%\n  summarise(count = n()) %&gt;%\n  arrange(Year)\n\n# Create heatmap\nggplot(year_summary, aes(x = \"\", y = Year, fill = count)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient(low = \"linen\", high = \"#FFA000\") +\n  geom_text(aes(label = count), vjust = 0.5, hjust = 1,color = \"black\", size = 2.8,alpha=1)+\n  scale_y_continuous(breaks = unique_years)+\n  labs(x = \"Book Count\", y = \"Year\", title = \"Heatmap of Books Released Each Year\") +\n  theme_classic() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nYou can access dataset here and source code here"
  },
  {
    "objectID": "R Projects/audible/audible.html",
    "href": "R Projects/audible/audible.html",
    "title": "Audible Data Cleaning",
    "section": "",
    "text": "The Audible dataset is a collection of data related to audiobooks gathered from Audible. It contains data from authors of audiobooks to release dates. The data represents the important details of audiobooks from 1998 till 2025 (pre-planned releases) and it was obtained from Kaggle. A peek into the Audible dataset indicates that there are some errors and inconsistencies which can be corrected using string manipulation techniques along side other data cleaning techniques."
  },
  {
    "objectID": "R Projects/audible/audible.html#top-5-authors-in-audible",
    "href": "R Projects/audible/audible.html#top-5-authors-in-audible",
    "title": "Audible Data Cleaning",
    "section": "Top 5 Authors in Audible",
    "text": "Top 5 Authors in Audible\n\n# Filter top 5 authors\ntop_authors &lt;- audible %&gt;%\n  group_by(author) %&gt;%\n  summarise(n = n()) %&gt;%\n  arrange(n) %&gt;%\n  top_n(5)\n\nSelecting by n\n\n# Bar plot of top 5 Audible Authors\nggplot(top_authors, aes(x = reorder(author, n), y = n, fill = author)) +\n  geom_bar(stat = \"identity\") +\n   geom_text(aes(label = n), hjust = -0.1, color = \"black\", size = 3.5) +\n  scale_fill_manual(values = c(\"矢島雅弘,石橋遊\"=\"#FFA000\",\"Smart Reading\"=\"#FFB347\",\"中西貴之,BJ\"=\"#FFC680\",\"div.\"=\"#FFDAB3\",\"Online Studio Productions\"=\"#FFEFE0\")) +\n  coord_flip() +\n  labs(x = \"Author\", y = \"Book Count\", title = \"Top 5 Authors in Audible\") +\n  theme_classic() +\n  theme(legend.position = \"none\",plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "Excel Projects/READALOT BOOKSTORE/Readalot.html#introduction",
    "href": "Excel Projects/READALOT BOOKSTORE/Readalot.html#introduction",
    "title": "Book Sales Analysis at Read-A-Lot Bookstore.",
    "section": "Introduction",
    "text": "Introduction\nIn this interesting data analysis project, I explore book sales at Read-A-Lot Bookstore. My goal is to understand trends, patterns, and insights related to global book sales at Read-A-Lot Bookstore. The dataset covers various genres, authors, and publishers from 1980 to 2020. By carefully analyzing this data, I aim to provide valuable business information for Read-A-Lot Ltd. 📚🔍"
  },
  {
    "objectID": "Excel Projects/READALOT BOOKSTORE/Readalot.html#overview",
    "href": "Excel Projects/READALOT BOOKSTORE/Readalot.html#overview",
    "title": "Book Sales Analysis at Read-A-Lot Bookstore.",
    "section": "Overview",
    "text": "Overview\nThe analysis revolves around answering critical questions:\n\nHistorical Book Production : An examination of books published anually?\nGenre and Publisher Trends: What are the total sales of the top 5 book genres and top 5 publishers worldwide during this period?\nRegional Dominance: Which book genres dominated?\nGlobal Sales Trends: How did the total book sales trend evolve globally during specific time period."
  },
  {
    "objectID": "Excel Projects/READALOT BOOKSTORE/Readalot.html#data-source",
    "href": "Excel Projects/READALOT BOOKSTORE/Readalot.html#data-source",
    "title": "Book Sales Analysis at Read-A-Lot Bookstore.",
    "section": "Data Source",
    "text": "Data Source\nThe dataset used is sourced from Kaggleand contains information on books with sales exceeding a certain threshold."
  },
  {
    "objectID": "Excel Projects/READALOT BOOKSTORE/Readalot.html#examine-the-dataset",
    "href": "Excel Projects/READALOT BOOKSTORE/Readalot.html#examine-the-dataset",
    "title": "Book Sales Analysis at Read-A-Lot Bookstore.",
    "section": "Examine the Dataset",
    "text": "Examine the Dataset\nA peek into the data; the first 10 rows of data:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nindex\nPublishing Year\nBook Name\nAuthor\nlanguage_code\nAuthor_Rating\nBook_average_rating\nBook_ratings_count\ngenre\ngross sales\npublisher revenue\nsale price\nsales rank\nPublisher\nunits sold\nsales\n\n\n\n\n0\n1975\nBeowulf\nUnknown, Seamus Heaney\nen-US\nNovice\n3.42\n155903\ngenre fiction\n34160.00\n20496.0\n4.88\n1\nHarperCollins Publishers\n7000\n$34,160\n\n\n1\n1987\nBatman: Year One\nFrank Miller, David Mazzucchelli, Richmond Lewis, Dennis O’Neil\neng\nIntermediate\n4.23\n145267\ngenre fiction\n12437.50\n7462.5\n1.99\n2\nHarperCollins Publishers\n6250\n$12,438\n\n\n2\n2015\nGo Set a Watchman\nHarper Lee\neng\nNovice\n3.31\n138669\ngenre fiction\n47795.00\n28677.0\n8.69\n3\nAmazon Digital Services, Inc.\n5500\n$47,795\n\n\n3\n2008\nWhen You Are Engulfed in Flames\nDavid Sedaris\nen-US\nIntermediate\n4.04\n150898\nfiction\n41250.00\n24750.0\n7.50\n3\nHachette Book Group\n5500\n$41,250\n\n\n4\n2011\nDaughter of Smoke & Bone\nLaini Taylor\neng\nIntermediate\n4.04\n198283\ngenre fiction\n37952.50\n22771.5\n7.99\n4\nPenguin Group (USA) LLC\n4750\n$37,953\n\n\n5\n2015\nRed Queen\nVictoria Aveyard\neng\nIntermediate\n4.08\n83354\ngenre fiction\n19960.00\n0.0\n4.99\n5\nAmazon Digital Services, Inc.\n4000\n$19,960\n\n\n6\n2011\nThe Power of Habit\nCharles Duhigg\neng\nIntermediate\n4.03\n155977\ngenre fiction\n27491.67\n16495.0\n6.99\n6\nHarperCollins Publishers\n3933\n$27,492\n\n\n7\n1994\nMidnight in the Garden of Good and Evil\nJohn Berendt\neng\nIntermediate\n3.90\n167997\nnonfiction\n26182.00\n15709.2\n6.89\n8\nHachette Book Group\n3800\n$26,182\n\n\n8\n2012\nHopeless\nColleen Hoover\neng\nIntermediate\n4.34\n189938\ngenre fiction\n26093.67\n15656.2\n6.99\n9\nHarperCollins Publishers\n3733\n$26,094\n\n\n10\n2004\nThe Truth About Forever\nSarah Dessen\nen-US\nIntermediate\n4.13\n179415\ngenre fiction\n17964.00\n0.0\n4.99\n11\nAmazon Digital Services, Inc.\n3600\n$17,964"
  },
  {
    "objectID": "Excel Projects/READALOT BOOKSTORE/Readalot.html#key-dashboard-requirements",
    "href": "Excel Projects/READALOT BOOKSTORE/Readalot.html#key-dashboard-requirements",
    "title": "Book Sales Analysis at Read-A-Lot Bookstore.",
    "section": "Key Dashboard Requirements",
    "text": "Key Dashboard Requirements\n\nThe interactive dashboard fulfills the following requirements:\n\nUsers can select Publishers and Authors that have their books on Read-A-Lot platformand Cities to compare sales and quantity trends.\nThe dashboard displays the top 5 Genres, top 5 Books by revenue corresponding to the chosen criteria."
  },
  {
    "objectID": "Excel Projects/READALOT BOOKSTORE/Readalot.html#dashboard",
    "href": "Excel Projects/READALOT BOOKSTORE/Readalot.html#dashboard",
    "title": "Book Sales Analysis at Read-A-Lot Bookstore.",
    "section": "Dashboard",
    "text": "Dashboard\n\n\n\n\n\n\n\nImportant!\n\n\n\nRight-click on image to open dashboard in new tab, if content too tiny\n\n\n\nTo interact with the Excel Dashboard, click here"
  },
  {
    "objectID": "Excel Projects/READALOT BOOKSTORE/Readalot.html#recommendations",
    "href": "Excel Projects/READALOT BOOKSTORE/Readalot.html#recommendations",
    "title": "Book Sales Analysis at Read-A-Lot Bookstore.",
    "section": "Recommendations",
    "text": "Recommendations\n\nIdentify a Target Audience: Understand your readers’ demographics, psychographics, and online behavior to better market to them.\n\n\n\nBuild an Author Platform: This can help amplify a book’s exposure and reach more readers.\n\n\n\nDesign a Book’s Cover: A well-designed cover can attract potential readers."
  },
  {
    "objectID": "Excel Projects/READALOT BOOKSTORE/Readalot.html#conclusion",
    "href": "Excel Projects/READALOT BOOKSTORE/Readalot.html#conclusion",
    "title": "Book Sales Analysis at Read-A-Lot Bookstore.",
    "section": "Conclusion",
    "text": "Conclusion\nIn conclusion, the book sales analysis for Read-A-Lot Bookstore has yielded valuable insights into the sales for the year 2023:\n\nInsights:\n\nTotal Book Sales grossed $47.74M in the year 2023.\nFiction Genre sold the most of all Genres.\nAmazon Digital Services Inc. grossed in a Revenue of $19.69M topping all publishers.\n2010-2014 marked the years books were published the most, totalling a count of 226 Books."
  },
  {
    "objectID": "index.html#good-morning-oyindamola-adegoke",
    "href": "index.html#good-morning-oyindamola-adegoke",
    "title": "\nSAMMY ODEYEMI\n",
    "section": "Good Morning 🌞 ~ Oyindamola Adegoke   ",
    "text": "Good Morning 🌞 ~ Oyindamola Adegoke   \n\n\nMy Portfolio\n\n\n\nExcel Projects\n\n\n\n\n\n\n\n  \n    \n  \n  \n    This is an Analysis on Read-A-Lot Bookstore data for the year 2023. The company specializes in the sales of books. I employed Microsoft Excel to perform various operations, ranging from data cleaning up to visualization.\n  \n  View Project\n  \n\n\n\n\n\n  \n    \n  \n  \n    This is an Analysis on Quantum Sales Solutions data for the year 2023. The company specializes in the sales of edible products. I employed Microsoft Excel to perform various operations, ranging from data cleaning up to visualization.\n  \n  View Project\n  \n\n\n\n\n\n  \n    \n  \n  \n    This is an Analysis on the Israel-Palestine conflict and the fatalities that occurred. I employed Microsoft Excel to perform various operations, ranging from data cleaning to visualization.\n  \n  View Project\n  \n\n\n\n\n\n  \n    \n    \n  \n    This is a Video Game Sales Analysis for Synergy Ltd. I employed Microsoft Excel to perform various operations, ranging from data cleaning to visualization.\n  \n  View Project\n  \n\n\n\n\n\n\nR Projects\n\n\n\n\n   \n   \n    \n   \nThis is a Data Cleaning Project for Audible. I employed R and RStudio to perform Data Cleaning, and took it a nudge further by analysing and making Visualizations.     \nView Project"
  },
  {
    "objectID": "R Projects/audible/fistmarkdown.html",
    "href": "R Projects/audible/fistmarkdown.html",
    "title": "Ibrahim Alayo",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.2.0\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nlibrary(pROC)\n\nType 'citation(\"pROC\")' for a citation.\n\n\n\nAttaching package: 'pROC'\n\n\nThe following objects are masked from 'package:stats':\n\n    cov, smooth, var\n\n\n\nndhsrasheeddata &lt;- read_csv(\"ndhsrasheed.csv\") %&gt;% view()\n\n\nndhsrasheedselect&lt;-select(ndhsrasheeddata, wealth, edu, rworking, resid, relig, visithosp,\nteenmom, agefbirth, hofistula, tchild) \n\n\nndhsrasheedselect&lt;-drop_na(ndhsrasheedselect) %&gt;% view()\n\n\n# Factor the columns for logistic regression \nndhsrasheedselect$wealth &lt;- as.factor(ndhsrasheedselect$wealth) \nndhsrasheedselect$edu &lt;- as.factor(ndhsrasheedselect$edu) \nndhsrasheedselect$rworking &lt;- as.factor(ndhsrasheedselect$rworking) \nndhsrasheedselect$resid &lt;- as.factor(ndhsrasheedselect$resid)\nndhsrasheedselect$relig &lt;- as.factor(ndhsrasheedselect$relig)\nndhsrasheedselect$visithosp &lt;- as.factor(ndhsrasheedselect$visithosp) \nndhsrasheedselect$teenmom &lt;- as.factor(ndhsrasheedselect$teenmom)\n\n\nfistulamodel1 &lt;-    glm(ndhsrasheedselect$hofistula~ wealth + edu + rworking + resid + \nrelig + visithosp + teenmom + agefbirth + tchild, family=binomial(link = \"logit\"), \ndata=ndhsrasheedselect)\n\n\nsummary(fistulamodel1)\n\n\nCall:\nglm(formula = ndhsrasheedselect$hofistula ~ wealth + edu + rworking + \n    resid + relig + visithosp + teenmom + agefbirth + tchild, \n    family = binomial(link = \"logit\"), data = ndhsrasheedselect)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.0460  -1.0689   0.6700   0.9219   1.9440  \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.301056   0.086359 -15.066  &lt; 2e-16 ***\nwealth2     -0.377643   0.021212 -17.803  &lt; 2e-16 ***\nwealth3     -0.352264   0.023153 -15.215  &lt; 2e-16 ***\nedu1        -0.276620   0.022697 -12.187  &lt; 2e-16 ***\nedu2        -0.302114   0.025248 -11.966  &lt; 2e-16 ***\nedu3         0.304739   0.038866   7.841 4.48e-15 ***\nrworking1    0.101677   0.018614   5.462 4.70e-08 ***\nresid2       0.263481   0.018746  14.055  &lt; 2e-16 ***\nrelig2       0.913443   0.019232  47.496  &lt; 2e-16 ***\nrelig3      -0.894714   0.092886  -9.632  &lt; 2e-16 ***\nvisithosp1   0.563839   0.015825  35.629  &lt; 2e-16 ***\nteenmom1     0.264171   0.026870   9.831  &lt; 2e-16 ***\nagefbirth    0.018573   0.003277   5.668 1.45e-08 ***\ntchild       0.064631   0.003113  20.760  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 108090  on 79536  degrees of freedom\nResidual deviance:  97156  on 79523  degrees of freedom\nAIC: 97184\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nfistulamodel2 &lt;-  glm(hofistula~ wealth + edu + rworking + resid + relig + visithosp + teenmom\n+ agefbirth + tchild, family=binomial(link = \"cloglog\"),\ndata=ndhsrasheedselect)\n\n\nsummary(fistulamodel2)\n\n\nCall:\nglm(formula = hofistula ~ wealth + edu + rworking + resid + relig + \n    visithosp + teenmom + agefbirth + tchild, family = binomial(link = \"cloglog\"), \n    data = ndhsrasheedselect)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1678  -1.0577   0.6513   0.9379   1.8849  \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.279116   0.057918 -22.085  &lt; 2e-16 ***\nwealth2     -0.232683   0.013836 -16.818  &lt; 2e-16 ***\nwealth3     -0.240078   0.015518 -15.471  &lt; 2e-16 ***\nedu1        -0.141903   0.014818  -9.576  &lt; 2e-16 ***\nedu2        -0.196713   0.017281 -11.383  &lt; 2e-16 ***\nedu3         0.241282   0.026031   9.269  &lt; 2e-16 ***\nrworking1    0.040466   0.011441   3.537 0.000405 ***\nresid2       0.155610   0.012603  12.347  &lt; 2e-16 ***\nrelig2       0.632866   0.013280  47.657  &lt; 2e-16 ***\nrelig3      -0.688587   0.078555  -8.766  &lt; 2e-16 ***\nvisithosp1   0.350590   0.009992  35.087  &lt; 2e-16 ***\nteenmom1     0.190890   0.017930  10.647  &lt; 2e-16 ***\nagefbirth    0.014073   0.002215   6.353 2.11e-10 ***\ntchild       0.040288   0.001886  21.367  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 108090  on 79536  degrees of freedom\nResidual deviance:  97193  on 79523  degrees of freedom\nAIC: 97221\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nfistulamodel3 &lt;-glm(hofistula~ wealth + edu + rworking + resid + relig + visithosp\n+ teenmom + agefbirth + tchild, family=binomial(link = \"probit\"),\ndata=ndhsrasheedselect)\n\n\nsummary(fistulamodel3)\n\n\nCall:\nglm(formula = hofistula ~ wealth + edu + rworking + resid + relig + \n    visithosp + teenmom + agefbirth + tchild, family = binomial(link = \"probit\"), \n    data = ndhsrasheedselect)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.0732  -1.0704   0.6680   0.9244   1.9671  \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.800068   0.052549 -15.225  &lt; 2e-16 ***\nwealth2     -0.230090   0.012927 -17.799  &lt; 2e-16 ***\nwealth3     -0.214818   0.014143 -15.189  &lt; 2e-16 ***\nedu1        -0.165623   0.013865 -11.946  &lt; 2e-16 ***\nedu2        -0.182596   0.015480 -11.796  &lt; 2e-16 ***\nedu3         0.188716   0.023829   7.920 2.38e-15 ***\nrworking1    0.057653   0.011234   5.132 2.87e-07 ***\nresid2       0.158214   0.011431  13.841  &lt; 2e-16 ***\nrelig2       0.563867   0.011822  47.698  &lt; 2e-16 ***\nrelig3      -0.549484   0.054597 -10.064  &lt; 2e-16 ***\nvisithosp1   0.339822   0.009558  35.553  &lt; 2e-16 ***\nteenmom1     0.163358   0.016378   9.974  &lt; 2e-16 ***\nagefbirth    0.011790   0.001997   5.903 3.56e-09 ***\ntchild       0.039144   0.001871  20.921  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 108090  on 79536  degrees of freedom\nResidual deviance:  97167  on 79523  degrees of freedom\nAIC: 97195\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nus &lt;- predict(fistulamodel1, type = \"response\")\n\n\nroc_curve&lt;- roc(ndhsrasheedselect$hofistula, us)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\n\n\nauc_value &lt;- auc(roc_curve)\n\n\nplot(roc_curve, main=\"ROC curve\", col=\"#007c80\")\ntext(0.5, 0.5, paste(\"AUC =\", round(auc_value, 4)), cex=0.8)"
  },
  {
    "objectID": "fistmarkdown.html",
    "href": "fistmarkdown.html",
    "title": "Ibrahim Alayo",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.2.0\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nlibrary(pROC)\n\nType 'citation(\"pROC\")' for a citation.\n\n\n\nAttaching package: 'pROC'\n\n\nThe following objects are masked from 'package:stats':\n\n    cov, smooth, var\n\n\n\nlibrary(ggplot2)\n\n\nndhsrasheeddata &lt;- read_csv(\"ndhsrasheed.csv\") %&gt;% view()\n\n\nndhsrasheedselect&lt;-select(ndhsrasheeddata, wealth, edu, rworking, resid, relig, visithosp, teenmom, agefbirth, hofistula, tchild)\n\n\nndhsrasheedselect&lt;-drop_na(ndhsrasheedselect) %&gt;% view()\n\n\n# Factor the columns for logistic regression  \nndhsrasheedselect$wealth &lt;- as.factor(ndhsrasheedselect$wealth) \nndhsrasheedselect$edu &lt;- as.factor(ndhsrasheedselect$edu)  \nndhsrasheedselect$rworking &lt;- as.factor(ndhsrasheedselect$rworking) \nndhsrasheedselect$resid &lt;- as.factor(ndhsrasheedselect$resid)\nndhsrasheedselect$relig &lt;- as.factor(ndhsrasheedselect$relig) \nndhsrasheedselect$visithosp &lt;- as.factor(ndhsrasheedselect$visithosp) \nndhsrasheedselect$teenmom &lt;- as.factor(ndhsrasheedselect$teenmom)\n\n\nfistulamodel1 &lt;-glm(ndhsrasheedselect$hofistula~ wealth + edu + rworking + resid + relig + visithosp + teenmom + agefbirth + tchild, family=binomial(link = \"logit\"), data=ndhsrasheedselect)\n\n\nsummary(fistulamodel1)\n\n\nCall:\nglm(formula = ndhsrasheedselect$hofistula ~ wealth + edu + rworking + \n    resid + relig + visithosp + teenmom + agefbirth + tchild, \n    family = binomial(link = \"logit\"), data = ndhsrasheedselect)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.0460  -1.0689   0.6700   0.9219   1.9440  \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.301056   0.086359 -15.066  &lt; 2e-16 ***\nwealth2     -0.377643   0.021212 -17.803  &lt; 2e-16 ***\nwealth3     -0.352264   0.023153 -15.215  &lt; 2e-16 ***\nedu1        -0.276620   0.022697 -12.187  &lt; 2e-16 ***\nedu2        -0.302114   0.025248 -11.966  &lt; 2e-16 ***\nedu3         0.304739   0.038866   7.841 4.48e-15 ***\nrworking1    0.101677   0.018614   5.462 4.70e-08 ***\nresid2       0.263481   0.018746  14.055  &lt; 2e-16 ***\nrelig2       0.913443   0.019232  47.496  &lt; 2e-16 ***\nrelig3      -0.894714   0.092886  -9.632  &lt; 2e-16 ***\nvisithosp1   0.563839   0.015825  35.629  &lt; 2e-16 ***\nteenmom1     0.264171   0.026870   9.831  &lt; 2e-16 ***\nagefbirth    0.018573   0.003277   5.668 1.45e-08 ***\ntchild       0.064631   0.003113  20.760  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 108090  on 79536  degrees of freedom\nResidual deviance:  97156  on 79523  degrees of freedom\nAIC: 97184\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nfistulamodel2 &lt;- glm(hofistula~ wealth + edu + rworking + resid + relig + visithosp + teenmom + agefbirth +\ntchild, family=binomial(link = \"cloglog\"),data=ndhsrasheedselect)\n\n\nsummary(fistulamodel2)\n\n\nCall:\nglm(formula = hofistula ~ wealth + edu + rworking + resid + relig + \n    visithosp + teenmom + agefbirth + tchild, family = binomial(link = \"cloglog\"), \n    data = ndhsrasheedselect)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1678  -1.0577   0.6513   0.9379   1.8849  \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.279116   0.057918 -22.085  &lt; 2e-16 ***\nwealth2     -0.232683   0.013836 -16.818  &lt; 2e-16 ***\nwealth3     -0.240078   0.015518 -15.471  &lt; 2e-16 ***\nedu1        -0.141903   0.014818  -9.576  &lt; 2e-16 ***\nedu2        -0.196713   0.017281 -11.383  &lt; 2e-16 ***\nedu3         0.241282   0.026031   9.269  &lt; 2e-16 ***\nrworking1    0.040466   0.011441   3.537 0.000405 ***\nresid2       0.155610   0.012603  12.347  &lt; 2e-16 ***\nrelig2       0.632866   0.013280  47.657  &lt; 2e-16 ***\nrelig3      -0.688587   0.078555  -8.766  &lt; 2e-16 ***\nvisithosp1   0.350590   0.009992  35.087  &lt; 2e-16 ***\nteenmom1     0.190890   0.017930  10.647  &lt; 2e-16 ***\nagefbirth    0.014073   0.002215   6.353 2.11e-10 ***\ntchild       0.040288   0.001886  21.367  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 108090  on 79536  degrees of freedom\nResidual deviance:  97193  on 79523  degrees of freedom\nAIC: 97221\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nfistulamodel3 &lt;-glm(hofistula~ wealth + edu + rworking + resid + relig + visithosp + teenmom + agefbirth + tchild, family=binomial(link = \"probit\"),data=ndhsrasheedselect)\n\n\nsummary(fistulamodel3)\n\n\nCall:\nglm(formula = hofistula ~ wealth + edu + rworking + resid + relig + \n    visithosp + teenmom + agefbirth + tchild, family = binomial(link = \"probit\"), \n    data = ndhsrasheedselect)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.0732  -1.0704   0.6680   0.9244   1.9671  \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.800068   0.052549 -15.225  &lt; 2e-16 ***\nwealth2     -0.230090   0.012927 -17.799  &lt; 2e-16 ***\nwealth3     -0.214818   0.014143 -15.189  &lt; 2e-16 ***\nedu1        -0.165623   0.013865 -11.946  &lt; 2e-16 ***\nedu2        -0.182596   0.015480 -11.796  &lt; 2e-16 ***\nedu3         0.188716   0.023829   7.920 2.38e-15 ***\nrworking1    0.057653   0.011234   5.132 2.87e-07 ***\nresid2       0.158214   0.011431  13.841  &lt; 2e-16 ***\nrelig2       0.563867   0.011822  47.698  &lt; 2e-16 ***\nrelig3      -0.549484   0.054597 -10.064  &lt; 2e-16 ***\nvisithosp1   0.339822   0.009558  35.553  &lt; 2e-16 ***\nteenmom1     0.163358   0.016378   9.974  &lt; 2e-16 ***\nagefbirth    0.011790   0.001997   5.903 3.56e-09 ***\ntchild       0.039144   0.001871  20.921  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 108090  on 79536  degrees of freedom\nResidual deviance:  97167  on 79523  degrees of freedom\nAIC: 97195\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nus &lt;- predict(fistulamodel1, type = \"response\")\n\n\nroc_curve&lt;- roc(ndhsrasheedselect$hofistula, us)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\n\n\nauc_value &lt;- auc(roc_curve)\n\n\nplot(roc_curve, main=\"ROC curve\", col=\"#007c80\") \ntext(0.5, 0.5, paste(\"AUC =\", round(auc_value, 4)), cex=0.8)\n\n\n\n\n\n\n\n\n\ncoefficients &lt;- coef(fistulamodel1)\nodds_ratios &lt;- exp(coefficients)\nconf_intervals &lt;- exp(confint(fistulamodel1))\n\nWaiting for profiling to be done...\n\n\n\nodds_ratios_df &lt;- data.frame(Variable = names(odds_ratios),Odds_Ratio = odds_ratios,CI_Lower = conf_intervals[, 1],\n  CI_Upper = conf_intervals[, 2])\n\n\nprint(odds_ratios_df)\n\n               Variable Odds_Ratio  CI_Lower  CI_Upper\n(Intercept) (Intercept)  0.2722441 0.2298430 0.3224416\nwealth2         wealth2  0.6854753 0.6575677 0.7145818\nwealth3         wealth3  0.7030946 0.6719063 0.7357399\nedu1               edu1  0.7583424 0.7253608 0.7928564\nedu2               edu2  0.7392534 0.7035685 0.7767631\nedu3               edu3  1.3562708 1.2568574 1.4637022\nrworking1     rworking1  1.1070256 1.0673614 1.1481552\nresid2           resid2  1.3014527 1.2544972 1.3501560\nrelig2           relig2  2.4928911 2.4007163 2.5887025\nrelig3           relig3  0.4087246 0.3398236 0.4891940\nvisithosp1   visithosp1  1.7574061 1.7037602 1.8127995\nteenmom1       teenmom1  1.3023504 1.2355301 1.3727700\nagefbirth     agefbirth  1.0187461 1.0122230 1.0253096\ntchild           tchild  1.0667651 1.0602799 1.0732984\n\n\n\nggplot(odds_ratios_df, aes(x = Variable, y = Odds_Ratio)) +\n  geom_point() +\n  geom_errorbar(aes(ymin = CI_Lower, ymax = CI_Upper), width = 0.2) +\n  coord_flip() +\n  labs(title = \"Odds Ratios for Fistula Model\",\n       x = \"Predictor Variables\",\n       y = \"Odds Ratio (log scale)\") +\n  scale_y_log10() +\n  theme_minimal()"
  },
  {
    "objectID": "docs/R Projects/audible/fistmarkdown.html",
    "href": "docs/R Projects/audible/fistmarkdown.html",
    "title": "Ibrahim Alayo",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.2.0\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nlibrary(pROC)\n\nType 'citation(\"pROC\")' for a citation.\n\n\n\nAttaching package: 'pROC'\n\n\nThe following objects are masked from 'package:stats':\n\n    cov, smooth, var\n\n\n\nndhsrasheeddata &lt;- read_csv(\"ndhsrasheed.csv\") %&gt;% view()\n\n\nndhsrasheedselect&lt;-select(ndhsrasheeddata, wealth, edu, rworking, resid, relig, visithosp, teenmom, agefbirth, hofistula, tchild) \n\n\nndhsrasheedselect&lt;-drop_na(ndhsrasheedselect) %&gt;% view()\n\n\n# Factor the columns for logistic regression \nndhsrasheedselect$wealth &lt;- as.factor(ndhsrasheedselect$wealth) \nndhsrasheedselect$edu &lt;- as.factor(ndhsrasheedselect$edu) \nndhsrasheedselect$rworking &lt;- as.factor(ndhsrasheedselect$rworking) \nndhsrasheedselect$resid &lt;- as.factor(ndhsrasheedselect$resid)\nndhsrasheedselect$relig &lt;- as.factor(ndhsrasheedselect$relig)\nndhsrasheedselect$visithosp &lt;- as.factor(ndhsrasheedselect$visithosp) \nndhsrasheedselect$teenmom &lt;- as.factor(ndhsrasheedselect$teenmom)\n\n\nfistulamodel1 &lt;-    glm(ndhsrasheedselect$hofistula~ wealth + edu + rworking + resid + relig + visithosp + teenmom + agefbirth + tchild, family=binomial(link = \"logit\"), data=ndhsrasheedselect)\n\n\nsummary(fistulamodel1)\n\n\nCall:\nglm(formula = ndhsrasheedselect$hofistula ~ wealth + edu + rworking + \n    resid + relig + visithosp + teenmom + agefbirth + tchild, \n    family = binomial(link = \"logit\"), data = ndhsrasheedselect)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.0460  -1.0689   0.6700   0.9219   1.9440  \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.301056   0.086359 -15.066  &lt; 2e-16 ***\nwealth2     -0.377643   0.021212 -17.803  &lt; 2e-16 ***\nwealth3     -0.352264   0.023153 -15.215  &lt; 2e-16 ***\nedu1        -0.276620   0.022697 -12.187  &lt; 2e-16 ***\nedu2        -0.302114   0.025248 -11.966  &lt; 2e-16 ***\nedu3         0.304739   0.038866   7.841 4.48e-15 ***\nrworking1    0.101677   0.018614   5.462 4.70e-08 ***\nresid2       0.263481   0.018746  14.055  &lt; 2e-16 ***\nrelig2       0.913443   0.019232  47.496  &lt; 2e-16 ***\nrelig3      -0.894714   0.092886  -9.632  &lt; 2e-16 ***\nvisithosp1   0.563839   0.015825  35.629  &lt; 2e-16 ***\nteenmom1     0.264171   0.026870   9.831  &lt; 2e-16 ***\nagefbirth    0.018573   0.003277   5.668 1.45e-08 ***\ntchild       0.064631   0.003113  20.760  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 108090  on 79536  degrees of freedom\nResidual deviance:  97156  on 79523  degrees of freedom\nAIC: 97184\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nfistulamodel2 &lt;-    glm(hofistula~ wealth + edu + rworking + resid + relig + visithosp + teenmom + agefbirth + tchild, family=binomial(link = \"cloglog\"),       data=ndhsrasheedselect)\n\n\nsummary(fistulamodel2)\n\n\nCall:\nglm(formula = hofistula ~ wealth + edu + rworking + resid + relig + \n    visithosp + teenmom + agefbirth + tchild, family = binomial(link = \"cloglog\"), \n    data = ndhsrasheedselect)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1678  -1.0577   0.6513   0.9379   1.8849  \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.279116   0.057918 -22.085  &lt; 2e-16 ***\nwealth2     -0.232683   0.013836 -16.818  &lt; 2e-16 ***\nwealth3     -0.240078   0.015518 -15.471  &lt; 2e-16 ***\nedu1        -0.141903   0.014818  -9.576  &lt; 2e-16 ***\nedu2        -0.196713   0.017281 -11.383  &lt; 2e-16 ***\nedu3         0.241282   0.026031   9.269  &lt; 2e-16 ***\nrworking1    0.040466   0.011441   3.537 0.000405 ***\nresid2       0.155610   0.012603  12.347  &lt; 2e-16 ***\nrelig2       0.632866   0.013280  47.657  &lt; 2e-16 ***\nrelig3      -0.688587   0.078555  -8.766  &lt; 2e-16 ***\nvisithosp1   0.350590   0.009992  35.087  &lt; 2e-16 ***\nteenmom1     0.190890   0.017930  10.647  &lt; 2e-16 ***\nagefbirth    0.014073   0.002215   6.353 2.11e-10 ***\ntchild       0.040288   0.001886  21.367  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 108090  on 79536  degrees of freedom\nResidual deviance:  97193  on 79523  degrees of freedom\nAIC: 97221\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nfistulamodel3 &lt;-    glm(hofistula~ wealth + edu + rworking + resid + relig + visithosp + teenmom + agefbirth + tchild, family=binomial(link = \"probit\"),       data=ndhsrasheedselect)\n\n\nsummary(fistulamodel3)\n\n\nCall:\nglm(formula = hofistula ~ wealth + edu + rworking + resid + relig + \n    visithosp + teenmom + agefbirth + tchild, family = binomial(link = \"probit\"), \n    data = ndhsrasheedselect)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.0732  -1.0704   0.6680   0.9244   1.9671  \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -0.800068   0.052549 -15.225  &lt; 2e-16 ***\nwealth2     -0.230090   0.012927 -17.799  &lt; 2e-16 ***\nwealth3     -0.214818   0.014143 -15.189  &lt; 2e-16 ***\nedu1        -0.165623   0.013865 -11.946  &lt; 2e-16 ***\nedu2        -0.182596   0.015480 -11.796  &lt; 2e-16 ***\nedu3         0.188716   0.023829   7.920 2.38e-15 ***\nrworking1    0.057653   0.011234   5.132 2.87e-07 ***\nresid2       0.158214   0.011431  13.841  &lt; 2e-16 ***\nrelig2       0.563867   0.011822  47.698  &lt; 2e-16 ***\nrelig3      -0.549484   0.054597 -10.064  &lt; 2e-16 ***\nvisithosp1   0.339822   0.009558  35.553  &lt; 2e-16 ***\nteenmom1     0.163358   0.016378   9.974  &lt; 2e-16 ***\nagefbirth    0.011790   0.001997   5.903 3.56e-09 ***\ntchild       0.039144   0.001871  20.921  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 108090  on 79536  degrees of freedom\nResidual deviance:  97167  on 79523  degrees of freedom\nAIC: 97195\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nus &lt;- predict(fistulamodel1, type = \"response\")\n\n\nroc_curve&lt;- roc(ndhsrasheedselect$hofistula, us)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\n\n\nauc_value &lt;- auc(roc_curve)\n\n\nplot(roc_curve, main=\"ROC curve\", col=\"#007c80\")\ntext(0.5, 0.5, paste(\"AUC =\", round(auc_value, 4)), cex=0.8)"
  },
  {
    "objectID": "SQL x POWER BI Projects/MURDER MYSTERY/murdermystery.html",
    "href": "SQL x POWER BI Projects/MURDER MYSTERY/murdermystery.html",
    "title": "SAMMY ODEYEMI",
    "section": "",
    "text": "title: \"Investigative Analysis of A Murder Mystery\"\ntoc: true\nmonofont: 'Consolas'\n---"
  },
  {
    "objectID": "SQL x POWER BI Projects/MURDER MYSTERY/murdermystery.html#introduction",
    "href": "SQL x POWER BI Projects/MURDER MYSTERY/murdermystery.html#introduction",
    "title": "MURDER MYSTERY WITH SQL",
    "section": "Introduction",
    "text": "Introduction\n\nThe SQL Murder Mystery is an engaging SQL exercise designed to flex SQL skills through a fun and interactive crime-solving scenario. Developed by the Knight Lab at Northwestern University, this mystery challenges participants to use SQL queries to investigate a fictional murder that occurred in SQL City on January 15, 2018. By exploring the database, analyzing clues, and piecing together evidence, participants can identify the culprit and solve the case.\n\n\nThe primary objective of the SQL Murder Mystery is to solve the murder case that is unsolved with the use of SQL to query the crime database . It entirely entails:\n\nExploring Database Structure: Understand the layout and relationships within the database by examining tables and their schemas.\nRetrieve and Analyze Data: Use SQL queries to extract relevant information from the database, such as crime scene reports, witness statements, and suspect details.\nIdentify Patterns and Clues: Analyze the data to uncover patterns and connections that point to the suspect.\nSolve the Mystery: Combine the gathered evidence to determine the identity of the murderer and understand the motive behind the crime.\n\n\n\nHere is the Entity Relationship Diagram to the database.\n\n\n\n\nFINDING THE KILLER\n\nFrom the clues left with, the murder occurred in SQL City on January 15, 2018\n\n\n\n\n\n\n\n\nOur search leads us to two witnesses whom we have to look to in the person table\n\nWITNESS 1\n\n\n\n\n\n\nWITNESS 2\n\n\n\n\n\nIt becomes imperative to check the interviews of these witnesses\n\n\n\n\nTaking into consideration the descriptive words both witnesses used in telling their side of the story from the query result:\n\n\n\n\nI take the initiative to check this Person of Interest out and cross check if they have been interviewed:\n\n\n\n\nThis Person of Interest checks out as the culprit and his interview Transcript indicates there is also an accomplice whom we will find out according to Jeremy Bowers’ confession and description\n\n\n\n\n\n\n\n\n\nSuccess!!!\n\n\n\nThe Culprit; Jeremy Bowers and the Mastermind Miranda Priestly are both complicit and the Murder Mystery has been resolved!\n\n\n\nTo access source code, click here"
  },
  {
    "objectID": "SQL x POWER BI Projects/HEART ATTACK/heartattack.html",
    "href": "SQL x POWER BI Projects/HEART ATTACK/heartattack.html",
    "title": "Global Heart Attack Analysis",
    "section": "",
    "text": "Important!!!\n\n\n\nRight-click on image to open dashboard in new tab, if content too tiny\n\n\n\nTo access sql source code, click here"
  },
  {
    "objectID": "R Projects/Health Analysis/HEALTHDATA.html",
    "href": "R Projects/Health Analysis/HEALTHDATA.html",
    "title": "HEALTH ANALYTICS WITH R",
    "section": "",
    "text": "Health Analytics is a rapidly growing field that leverages data analysis to improve healthcare outcomes, optimize operations, and inform policy decisions. By analyzing health-related data, we can uncover patterns, trends, and insights that can lead to better patient care, cost management, and overall health system efficiency.\nIn this project, I use R, a powerful statistical programming language, to analyze a dataset containing various health-related variables. The dataset includes information on individuals’ age, sex, body mass index (BMI), number of children, smoking status, region of residence, and insurance charges. The goal is to explore how these factors influence health insurance costs and identify key drivers of these costs."
  },
  {
    "objectID": "R Projects/Health Analysis/HEALTHDATA.html#introduction-to-health-analytics-with-r",
    "href": "R Projects/Health Analysis/HEALTHDATA.html#introduction-to-health-analytics-with-r",
    "title": "HEALTH ANALYTICS WITH R",
    "section": "INTRODUCTION TO HEALTH ANALYTICS WITH R ⚕️",
    "text": "INTRODUCTION TO HEALTH ANALYTICS WITH R ⚕️\n\nHealth Analytics is a rapidly growing field that leverages data analysis to improve healthcare outcomes, optimize operations, and inform policy decisions. By analyzing health-related data, we can uncover patterns, trends, and insights that can lead to better patient care, cost management, and overall health system efficiency.\nIn this project, I use R, a powerful statistical programming language, to analyze a dataset containing various health-related variables. The dataset includes information on individuals’ age, sex, body mass index (BMI), number of children, smoking status, region of residence, and insurance charges. The goal is to explore how these factors influence health insurance costs and identify key drivers of these costs."
  },
  {
    "objectID": "R Projects/Health Analysis/HEALTHDATA.html#install-necessary-packages",
    "href": "R Projects/Health Analysis/HEALTHDATA.html#install-necessary-packages",
    "title": "HEALTH ANALYTICS WITH R",
    "section": "INSTALL NECESSARY PACKAGES 📦",
    "text": "INSTALL NECESSARY PACKAGES 📦\n\ninstall.packages(c(\"corrplot\",\"ggplot2\",\"tidyr\",\"dplyr\",\"readr\",\"knitr\"))\n\nThe install.packages function in R is used to install one or more packages from CRAN (the Comprehensive R Archive Network). The codeblock instruction is to install five packages: corrplot, ggplot2, tidyr, dplyr, and readr. Here’s a brief description of each:\n\ncorrplot: This package is used for visualizing correlation matrices. It provides a variety of methods to display correlations, making it easier to understand the relationships between variables in your dataset.\nggplot2: A powerful and widely-used package for data visualization. It implements the grammar of graphics, allowing you to create complex and aesthetically pleasing plots with a high degree of customization.\ntidyr: This package helps in tidying your data. It provides functions to reshape and clean your data, making it easier to work with and analyze. Key functions include gather, spread, separate, and unite.\ndplyr: A package for data manipulation. It provides a set of functions (verbs) that help you perform common data manipulation tasks such as filtering, selecting, mutating, summarizing, and arranging data. It’s known for its simplicity and speed.\nreadr: This package is used for reading rectangular data (like CSV files) into R. It provides functions that are faster and more convenient than the base R functions for reading data.\nknitr: This package is used for dynamic report generation in R. It allows to integrate R code with LaTeX, HTML, Markdown, and other formats, making it easier to create reproducible reports and documents that include both code and output."
  },
  {
    "objectID": "R Projects/Health Analysis/HEALTHDATA.html#load-libraries",
    "href": "R Projects/Health Analysis/HEALTHDATA.html#load-libraries",
    "title": "HEALTH ANALYTICS WITH R",
    "section": "LOAD LIBRARIES",
    "text": "LOAD LIBRARIES\n\nlibrary(corrplot)\n\ncorrplot 0.92 loaded\n\nlibrary(ggplot2) \nlibrary(tidyr) \nlibrary(dplyr) \n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(readr)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.2     ✔ tibble    3.2.0\n✔ purrr     1.0.1     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(knitr)\n\nBy calling these packages, one is equipped with powerful tools to clean, manipulate, visualize, and analyze the health dataset effectively."
  },
  {
    "objectID": "R Projects/Health Analysis/HEALTHDATA.html#check-working-directory",
    "href": "R Projects/Health Analysis/HEALTHDATA.html#check-working-directory",
    "title": "HEALTH ANALYTICS WITH R",
    "section": "CHECK WORKING DIRECTORY",
    "text": "CHECK WORKING DIRECTORY\n\ngetwd()\n\n[1] \"C:/Users/SAMMY/Desktop/Portfoliooo/Sammy Odeyemi/R Projects/Health Analysis\"\n\n\nThe getwd() function in R stands for “get working directory.” It returns the current working directory of the R session. The working directory is the folder where R reads and saves files by default. Knowing the current working directory is important because it helps to understand where your files are being stored and accessed from."
  },
  {
    "objectID": "R Projects/Health Analysis/HEALTHDATA.html#set-working-directory",
    "href": "R Projects/Health Analysis/HEALTHDATA.html#set-working-directory",
    "title": "HEALTH ANALYTICS WITH R",
    "section": "SET WORKING DIRECTORY",
    "text": "SET WORKING DIRECTORY\n\nsetwd(\"C:/Users/SAMMY/Desktop/Portfoliooo/Sammy Odeyemi/R Projects/Health Analysis\")\n\nThe setwd() function in R sets the working directory to a specified path. This means R will read and write files from this directory by default.\n\n\n\n\n\n\nNote\n\n\n\nAs in your Desktop/Workspace, the Working Directory would be different!"
  },
  {
    "objectID": "R Projects/Health Analysis/HEALTHDATA.html#import-health-dataset-and-view",
    "href": "R Projects/Health Analysis/HEALTHDATA.html#import-health-dataset-and-view",
    "title": "HEALTH ANALYTICS WITH R",
    "section": "IMPORT HEALTH DATASET AND VIEW",
    "text": "IMPORT HEALTH DATASET AND VIEW\n\nhealthdata&lt;-read_csv(\"Health-Insurance-Dataset.csv\")\n\nRows: 1338 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): sex, smoker, region\ndbl (4): age, bmi, children, charges\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nkable(head(healthdata,20))\n\n\n\n\nage\nsex\nbmi\nchildren\nsmoker\nregion\ncharges\n\n\n\n\n19\nfemale\n27.900\n0\nyes\nsouthwest\n16884.924\n\n\n18\nmale\n33.770\n1\nno\nsoutheast\n1725.552\n\n\n28\nmale\n33.000\n3\nno\nsoutheast\n4449.462\n\n\n33\nmale\n22.705\n0\nno\nnorthwest\n21984.471\n\n\n32\nmale\n28.880\n0\nno\nnorthwest\n3866.855\n\n\n31\nfemale\n25.740\n0\nno\nsoutheast\n3756.622\n\n\n46\nfemale\n33.440\n1\nno\nsoutheast\n8240.590\n\n\n37\nfemale\n27.740\n3\nno\nnorthwest\n7281.506\n\n\n37\nmale\n29.830\n2\nno\nnortheast\n6406.411\n\n\n60\nfemale\n25.840\n0\nno\nnorthwest\n28923.137\n\n\n25\nmale\n26.220\n0\nno\nnortheast\n2721.321\n\n\n62\nfemale\n26.290\n0\nyes\nsoutheast\n27808.725\n\n\n23\nmale\n34.400\n0\nno\nsouthwest\n1826.843\n\n\n56\nfemale\n39.820\n0\nno\nsoutheast\n11090.718\n\n\n27\nmale\n42.130\n0\nyes\nsoutheast\n39611.758\n\n\n19\nmale\n24.600\n1\nno\nsouthwest\n1837.237\n\n\n52\nfemale\n30.780\n1\nno\nnortheast\n10797.336\n\n\n23\nmale\n23.845\n0\nno\nnortheast\n2395.172\n\n\n56\nmale\n40.300\n0\nno\nsouthwest\n10602.385\n\n\n30\nmale\n35.300\n0\nyes\nsouthwest\n36837.467\n\n\n\n\n\n\nhealthdata &lt;- read_csv(\"Health-Insurance-Dataset.csv\"): Reads the CSV file named “Health-Insurance-Dataset.csv” into a data frame called healthdata. This function is part of the readr package and is used to import data into R for analysis.\nView(healthdata): Opens a spreadsheet-like view of the healthdata data frame in RStudio, allowing to inspect the data visually."
  },
  {
    "objectID": "R Projects/Health Analysis/HEALTHDATA.html#display-structure-of-dataframe",
    "href": "R Projects/Health Analysis/HEALTHDATA.html#display-structure-of-dataframe",
    "title": "HEALTH ANALYTICS WITH R",
    "section": "DISPLAY STRUCTURE OF DATAFRAME",
    "text": "DISPLAY STRUCTURE OF DATAFRAME\n\nstr(healthdata)\n\nspc_tbl_ [1,338 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ age     : num [1:1338] 19 18 28 33 32 31 46 37 37 60 ...\n $ sex     : chr [1:1338] \"female\" \"male\" \"male\" \"male\" ...\n $ bmi     : num [1:1338] 27.9 33.8 33 22.7 28.9 ...\n $ children: num [1:1338] 0 1 3 0 0 0 1 3 2 0 ...\n $ smoker  : chr [1:1338] \"yes\" \"no\" \"no\" \"no\" ...\n $ region  : chr [1:1338] \"southwest\" \"southeast\" \"southeast\" \"northwest\" ...\n $ charges : num [1:1338] 16885 1726 4449 21984 3867 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   age = col_double(),\n  ..   sex = col_character(),\n  ..   bmi = col_double(),\n  ..   children = col_double(),\n  ..   smoker = col_character(),\n  ..   region = col_character(),\n  ..   charges = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\nstr(healthdata): Provides a compact, human-readable summary of the structure of the healthdata data frame, including the type of each variable and a preview of the data.\nVISUALIZATIONS 📊\n\n\nVISUALIZE PREDICTOR VARIABLE AGE\n\nggplot(healthdata,aes(x=age)) +   \n  geom_histogram(fill=\"#004046\",binwidth = 5,color=\"bisque\") + \n  ggtitle(\"Visualization for Predictor Variable Age\") +  \n  theme_minimal()\n\n\n\n\n\n\n\n\nThis block of code creates a histogram to visualize the distribution of the age variable in the healthdata data frame. The histogram uses bins of 5 years to group the ages, and it is styled with specific fill and border colors. The plot is titled “Visualization for Predictor Variable Age” and uses a minimal theme for a clean look.\nThis visualization helps in understanding the distribution of ages in the dataset, which can be useful for identifying patterns or anomalies in the data.\n\n\nVISUALIZE PREDICTOR VARIABLE SEX\n\nggplot(healthdata,aes(x=sex, fill = sex)) +\n  geom_bar(color=\"bisque\") +   \n  scale_fill_manual(values = c(\"male\"=\"#004046\",\"female\"=\"#007d76\")) +\n  geom_text(aes(label = ..count..), stat = \"count\", vjust = -0.3) +\n  ggtitle(\"Visualization for Predictor Variable Sex\") +   \n  theme_minimal()\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n\n\n\n\n\n\n\n\n\nThis block of code creates a bar plot to visualize the distribution of the sex variable in the healthdata dataset. The bars are colored based on sex, with custom colors for “male” and “female.” The plot includes count labels above each bar, a title “Visualization for Predictor Variable Sex,” and uses a minimal theme for a clean look.\nThis visualization helps in understanding the distribution of sexes in the dataset, which can be useful for identifying patterns or anomalies in the data.\n\n\nVISUALIZE PREDICTOR VARIABLE BMI\n\nggplot(healthdata, aes(x = bmi)) +\n  geom_histogram(binwidth = 2, fill = \"#004046\", color = \"bisque\") +   \n  labs(title = \"BMI Distribution\", x = \"BMI\", y = \"Count\") +   \n  theme_minimal()    \n\n\n\n\n\n\n\n\nThis block of code creates a histogram to visualize the distribution of the bmi variable in the healthdata dataset. The histogram uses bins of 2 units to group the BMI values and is styled with a specific fill color and border color. The plot is titled “BMI Distribution” and uses a minimal theme for a clean look.\nThis visualization helps in understanding the distribution of BMI values in the dataset, which can be useful for identifying patterns or anomalies in the data.\n\n\nVISUALIZE PREDICTOR VARIABLE CHILDREN\n\nggplot(healthdata, aes(x = factor(children))) +\n  geom_bar(fill = \"#004046\", color=\"bisque\") +\n  labs(title = \"Number of Children\", x = \"Children\", y = \"Count\") +\n  geom_text(aes(label = ..count..), stat = \"count\", vjust = -0.3) +\n  theme_minimal() \n\n\n\n\n\n\n\n\nThis block of code creates a bar plot to visualize the distribution of the children variable in the healthdata dataset. The bars are colored with a specific fill and border color. The plot includes count labels above each bar, a title “Number of Children,” and uses a minimal theme for a clean look.\nThis visualization helps in understanding the distribution of the number of children in the dataset, which can be useful for identifying patterns or anomalies in the data.\n\n\nVISUALIZE PREDICTOR VARIABLE SMOKER\n\nggplot(healthdata, aes(x = smoker, fill = smoker)) +\ngeom_bar() +   \nlabs(title = \"Smoker vs. Non-Smoker\", x = \"Smoker\", y = \"Count\") +       scale_fill_manual(values = c(\"yes\" = \"antiquewhite4\", \"no\" = \"#004046\")) +     geom_text(stat = \"count\", aes(label = ..count..), vjust = -0.5) +\ntheme_minimal() \n\n\n\n\n\n\n\n\nThis block of code creates a bar plot to visualize the distribution of the smoker variable in the healthdata dataset. The bars are colored based on smoking status, with custom colors for “yes” and “no.” The plot includes count labels above each bar, a title “Smoker vs. Non-Smoker,” and uses a minimal theme for a clean look.\nThis visualization helps in understanding the distribution of smokers and non-smokers in the dataset, which can be useful for identifying patterns or anomalies in the data.\n\n\nVISUALIZE PREDICTOR VARIABLE REGION\n\nggplot(healthdata, aes(x = region, fill = region)) +\n  geom_bar() +\n  labs(title = \"Distribution by Region\", x = \"Region\", y = \"Count\") +   scale_fill_manual(values = c(\"southwest\" = \"darkorchid\", \"southeast\" = \"#004046\", \"northwest\" = \"antiquewhite4\", \"northeast\" = \"darkgoldenrod\")) +\n  geom_text(stat = \"count\", aes(label = ..count..), vjust = -0.5) +\n  theme_minimal() \n\n\n\n\n\n\n\n\nThis block of code creates a bar plot to visualize the distribution of the region variable in the healthdata dataset. The bars are colored based on the region, with custom colors for “southwest,” “southeast,” “northwest,” and “northeast.” The plot includes count labels above each bar, a title “Distribution by Region,” and uses a minimal theme for a clean look.\nThis visualization helps in understanding the distribution of regions in the dataset, which can be useful for identifying patterns or anomalies in the data.\n\n\nVISUALIZE PREDICTOR VARIABLE CHARGES\n\nggplot(healthdata, aes(x = charges)) +   \n  geom_density(fill = \"#004046\", alpha = 0.9, color=\"bisque\") +   \n  labs(title = \"Density of Charges\", x = \"Charges\", y = \"Density\") +   theme_minimal() \n\n\n\n\n\n\n\n\nThis block of code creates a density plot to visualize the distribution of the charges variable in the healthdata dataset. The density plot is styled with a specific fill color, transparency level, and border color. The plot is titled “Density of Charges” and uses a minimal theme for a clean look.\nThis visualization helps in understanding the distribution of charges in the dataset, which can be useful for identifying patterns or anomalies in the data."
  },
  {
    "objectID": "R Projects/Health Analysis/HEALTHDATA.html#report",
    "href": "R Projects/Health Analysis/HEALTHDATA.html#report",
    "title": "HEALTH ANALYTICS WITH R",
    "section": "REPORT",
    "text": "REPORT\nPiecing it altogether, we make a report off of the charts generated in RStudio using the viz Tool: Power BI"
  },
  {
    "objectID": "R Projects/Health Analysis/HEALTHDATA.html#summary-stats",
    "href": "R Projects/Health Analysis/HEALTHDATA.html#summary-stats",
    "title": "HEALTH ANALYTICS WITH R",
    "section": "SUMMARY STATS",
    "text": "SUMMARY STATS\n\nsummary(healthdata)\n\n      age            sex                 bmi           children    \n Min.   :18.00   Length:1338        Min.   :15.96   Min.   :0.000  \n 1st Qu.:27.00   Class :character   1st Qu.:26.30   1st Qu.:0.000  \n Median :39.00   Mode  :character   Median :30.40   Median :1.000  \n Mean   :39.21                      Mean   :30.66   Mean   :1.095  \n 3rd Qu.:51.00                      3rd Qu.:34.69   3rd Qu.:2.000  \n Max.   :64.00                      Max.   :53.13   Max.   :5.000  \n    smoker             region             charges     \n Length:1338        Length:1338        Min.   : 1122  \n Class :character   Class :character   1st Qu.: 4740  \n Mode  :character   Mode  :character   Median : 9382  \n                                       Mean   :13270  \n                                       3rd Qu.:16640  \n                                       Max.   :63770  \n\n\nASSUMPTION TEST ON PREDICTOR VARIABLES ARE INDEPENDENT USING CORRELATION COEFFS\n\n# convert to numeric and factors, the columns that are non-numeric \nhealthdata$sex&lt;-as.numeric(as.factor(healthdata$sex))\nhealthdata$smoker&lt;-as.numeric(as.factor(healthdata$smoker))\nhealthdata$region&lt;-as.numeric(as.factor(healthdata$region))\n\n\n#USING SCATTERPLOTS AND CORRELATION MATRIX \ncorr_matrix&lt;- cor(healthdata[,c(\"age\",\"sex\",\"bmi\",\"children\",\"smoker\",\"region\",\"charges\")])\ncorr_matrix\n\n                  age          sex         bmi   children       smoker\nage       1.000000000 -0.020855872 0.109271882 0.04246900 -0.025018752\nsex      -0.020855872  1.000000000 0.046371151 0.01716298  0.076184817\nbmi       0.109271882  0.046371151 1.000000000 0.01275890  0.003750426\nchildren  0.042468999  0.017162978 0.012758901 1.00000000  0.007673120\nsmoker   -0.025018752  0.076184817 0.003750426 0.00767312  1.000000000\nregion    0.002127313  0.004588385 0.157565849 0.01656945 -0.002180682\ncharges   0.299008193  0.057292062 0.198340969 0.06799823  0.787251430\n               region      charges\nage       0.002127313  0.299008193\nsex       0.004588385  0.057292062\nbmi       0.157565849  0.198340969\nchildren  0.016569446  0.067998227\nsmoker   -0.002180682  0.787251430\nregion    1.000000000 -0.006208235\ncharges  -0.006208235  1.000000000\n\n\n\n#Visualizing for correlation \ncorr_colors &lt;- colorRampPalette(c(\"#E0F2F1\", \"#007D76\"))(100) \ncorrplot(corr_matrix,method=\"color\",addCoef.col = \"black\",col=corr_colors)\n\n\n\n\n\n\n\n\n\npairs(~ age + sex + bmi + children + smoker + region + charges, data = healthdata)\n\n\n\n\n\n\n\n\n\n# Logistic regression models for predictor variables \n# Age, Smoker and BMI  \nlm1&lt;- lm(charges ~ smoker + age + bmi, healthdata) \nsummary(lm1)\n\n\nCall:\nlm(formula = charges ~ smoker + age + bmi, data = healthdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12415.4  -2970.9   -980.5   1480.0  28971.8 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -35500.51    1060.50  -33.48   &lt;2e-16 ***\nsmoker       23823.68     412.87   57.70   &lt;2e-16 ***\nage            259.55      11.93   21.75   &lt;2e-16 ***\nbmi            322.62      27.49   11.74   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6092 on 1334 degrees of freedom\nMultiple R-squared:  0.7475,    Adjusted R-squared:  0.7469 \nF-statistic:  1316 on 3 and 1334 DF,  p-value: &lt; 2.2e-16\n\n\n\n# Logistic regression models for predictor variables \n# Age, Smoker, children, region, sex and BMI   \nlm2&lt;- lm(charges ~ smoker + age + bmi + children + region + sex, healthdata) \n\nsummary(lm2)\n\n\nCall:\nlm(formula = charges ~ smoker + age + bmi + children + region + \n    sex, data = healthdata)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-11343  -2807  -1017   1408  29752 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -35151.14    1174.41 -29.931  &lt; 2e-16 ***\nsmoker       23820.43     411.84  57.839  &lt; 2e-16 ***\nage            257.29      11.89  21.647  &lt; 2e-16 ***\nbmi            332.57      27.72  11.997  &lt; 2e-16 ***\nchildren       479.37     137.64   3.483 0.000513 ***\nregion        -353.64     151.93  -2.328 0.020077 *  \nsex           -131.11     332.81  -0.394 0.693681    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6060 on 1331 degrees of freedom\nMultiple R-squared:  0.7507,    Adjusted R-squared:  0.7496 \nF-statistic: 668.1 on 6 and 1331 DF,  p-value: &lt; 2.2e-16\n\n\n\n# Logistic regression models for predictor variables \n# Age, Smoker, children, region, BMI   \nlm3&lt;- lm(charges ~ smoker + age + bmi + children + region, healthdata) \n\nsummary(lm3)\n\n\nCall:\nlm(formula = charges ~ smoker + age + bmi + children + region, \n    data = healthdata)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-11404  -2805   -992   1400  29694 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -35321.62    1091.42 -32.363  &lt; 2e-16 ***\nsmoker       23808.21     410.54  57.992  &lt; 2e-16 ***\nage            257.41      11.88  21.670  &lt; 2e-16 ***\nbmi            332.04      27.68  11.995  &lt; 2e-16 ***\nchildren       478.44     137.58   3.478 0.000522 ***\nregion        -353.45     151.88  -2.327 0.020104 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6058 on 1332 degrees of freedom\nMultiple R-squared:  0.7507,    Adjusted R-squared:  0.7498 \nF-statistic: 802.2 on 5 and 1332 DF,  p-value: &lt; 2.2e-16\n\n\n\n#Calculate residuals and fitted values for residuals\nresidualslm1&lt;-data.frame(residuals=resid(lm1), Fitted=fitted(lm3))\n\n\n#Create Visuals for Residuals and Fitted Values  \nggplot(residualslm1, aes(Fitted,residuals))+\n  geom_point(aes(color=\"#004046\")) +\n  geom_hline(yintercept = 0,linetype=\"dashed\",color=\"#004046\")+\n  labs(title = \"Residuals vs Fitted Plot\", x=\"Fitted Values\",y=\"Residuals\")+   theme_minimal()\n\n\n\n\n\n\n\n\n\n#QQ Plot of Residuals\nggplot(residualslm1, aes(sample=residuals))+   stat_qq(color=\"#004046\")+   stat_qq_line(color=\"#004046\")+   labs(title = \"Q-Q Plot of Residuals\", x=\"Theoretical Quantiles\",y=\"Sample Quantiles\")+   theme_minimal()\n\n\n\n\n\n\n\n\n\ngetOption(\"repos\")\n\n    CRAN \n\"@CRAN@\""
  },
  {
    "objectID": "R Projects/Health Analysis/HEALTHDATA.html#descriptive-summary",
    "href": "R Projects/Health Analysis/HEALTHDATA.html#descriptive-summary",
    "title": "HEALTH ANALYTICS WITH R",
    "section": "DESCRIPTIVE SUMMARY",
    "text": "DESCRIPTIVE SUMMARY\nThe summary() function in R provides a quick overview of the dataset, including basic statistics for each variable\n\nsummary(healthdata)\n\n      age            sex                 bmi           children    \n Min.   :18.00   Length:1338        Min.   :15.96   Min.   :0.000  \n 1st Qu.:27.00   Class :character   1st Qu.:26.30   1st Qu.:0.000  \n Median :39.00   Mode  :character   Median :30.40   Median :1.000  \n Mean   :39.21                      Mean   :30.66   Mean   :1.095  \n 3rd Qu.:51.00                      3rd Qu.:34.69   3rd Qu.:2.000  \n Max.   :64.00                      Max.   :53.13   Max.   :5.000  \n    smoker             region             charges     \n Length:1338        Length:1338        Min.   : 1122  \n Class :character   Class :character   1st Qu.: 4740  \n Mode  :character   Mode  :character   Median : 9382  \n                                       Mean   :13270  \n                                       3rd Qu.:16640  \n                                       Max.   :63770  \n\n\n\n\n\n\n\n\nInterpretation of Descriptive Statistics\n\n\n\n\nAge: The ages in your dataset range from 18 to 64 years, with a median age of 39. This indicates a fairly balanced distribution of ages around the middle age group.\nBMI: BMI values range from 15.96 to 53.13, with a median of 30.40. The mean BMI is slightly higher at 30.66, suggesting a slight skew towards higher BMI values.\nChildren: The number of children ranges from 0 to 5, with a median of 1. This shows that most individuals have one or no children.\nCharges: Medical charges vary widely from $1,122 to $63,770, with a median charge of $9,382. The mean charge is $13,270, indicating a right-skewed distribution with some high-cost outliers.\nSex, Smoker, Region: These are categorical variables, and their summary indicates the dataset includes diverse categories for each."
  },
  {
    "objectID": "R Projects/Health Analysis/HEALTHDATA.html#assumption-test-on-predictor-variables-to-determine-independence-using-correlation-coefficients",
    "href": "R Projects/Health Analysis/HEALTHDATA.html#assumption-test-on-predictor-variables-to-determine-independence-using-correlation-coefficients",
    "title": "HEALTH ANALYTICS WITH R",
    "section": "ASSUMPTION TEST ON PREDICTOR VARIABLES TO DETERMINE INDEPENDENCE USING CORRELATION COEFFICIENTS",
    "text": "ASSUMPTION TEST ON PREDICTOR VARIABLES TO DETERMINE INDEPENDENCE USING CORRELATION COEFFICIENTS\nIt becomes imperative to convert non-numeric columns in the healthdata dataset to numeric values and this is essential for performing further numerical analyses and visualizations\n\n#convert to numeric and factors, the columns that are non-numeric \nhealthdata$sex&lt;-as.numeric(as.factor(healthdata$sex))\nhealthdata$smoker&lt;-as.numeric(as.factor(healthdata$smoker))\nhealthdata$region&lt;-as.numeric(as.factor(healthdata$region))\n\n\n#USING SCATTERPLOTS AND CORRELATION MATRIX \ncorr_matrix&lt;- cor(healthdata[,c(\"age\",\"sex\",\"bmi\",\"children\",\"smoker\",\"region\",\"charges\")])\ncorr_matrix\n\n                  age          sex         bmi   children       smoker\nage       1.000000000 -0.020855872 0.109271882 0.04246900 -0.025018752\nsex      -0.020855872  1.000000000 0.046371151 0.01716298  0.076184817\nbmi       0.109271882  0.046371151 1.000000000 0.01275890  0.003750426\nchildren  0.042468999  0.017162978 0.012758901 1.00000000  0.007673120\nsmoker   -0.025018752  0.076184817 0.003750426 0.00767312  1.000000000\nregion    0.002127313  0.004588385 0.157565849 0.01656945 -0.002180682\ncharges   0.299008193  0.057292062 0.198340969 0.06799823  0.787251430\n               region      charges\nage       0.002127313  0.299008193\nsex       0.004588385  0.057292062\nbmi       0.157565849  0.198340969\nchildren  0.016569446  0.067998227\nsmoker   -0.002180682  0.787251430\nregion    1.000000000 -0.006208235\ncharges  -0.006208235  1.000000000\n\n\nIn this block of code, we calculate the correlation matrix for selected variables in the healthdata dataset. This matrix helps in understanding the linear relationships between pairs of variables such as age, sex, bmi, children, smoker, region, and charges.\n\n#Visualizing for correlation \ncorr_colors &lt;- colorRampPalette(c(\"#E0F2F1\", \"#007D76\"))(100) \ncorrplot(corr_matrix,method=\"color\",addCoef.col = \"black\",col=corr_colors)\n\n\n\n\n\n\n\n\nAbove is a color-coded plot that clearly shows the strength and direction of relationships between the variables, aiding in the identification of patterns and potential multicollinearity.\n\n\n\n\n\n\nInterpretation of Correlation Matrix\n\n\n\n\nAge: Positively correlated with charges (0.299).\nSex: Weak correlations with all variables.\nBMI: Positively correlated with charges (0.198) and region (0.158).\nChildren: Weak correlations with all variables.\nSmoker: Strongly correlated with charges (0.787).\nRegion: Weak correlations with all variables.\nCharges: Strongly correlated with smoker (0.787), moderately with age (0.299) and BMI (0.198).\n\nKey relationships: smoker and charges (strong), age and charges (moderate), BMI and charges (moderate). Other variables show weak correlations.\n\n\n\npairs(~ age + sex + bmi + children + smoker + region + charges, data = healthdata)\n\n\n\n\n\n\n\n\nThe above chart and block of code helps in visualizing a pairwise relationship between the variables.\nA scatterplot matrix is visualized, where each cell in the matrix is a scatterplot of one variable against another."
  },
  {
    "objectID": "R Projects/Health Analysis/HEALTHDATA.html#interpretation-of-correlation-matrix-1",
    "href": "R Projects/Health Analysis/HEALTHDATA.html#interpretation-of-correlation-matrix-1",
    "title": "HEALTH ANALYTICS WITH R",
    "section": "Interpretation of Correlation Matrix",
    "text": "Interpretation of Correlation Matrix\n\nAge: Positively correlated with charges (0.299).\nSex: Weak correlations with all variables.\nBMI: Positively correlated with charges (0.198) and region (0.158).\nChildren: Weak correlations with all variables.\nSmoker: Strongly correlated with charges (0.787).\nRegion: Weak correlations with all variables.\nCharges: Strongly correlated with smoker (0.787), moderately with age (0.299) and BMI (0.198).\n\nKey relationships: smoker and charges (strong), age and charges (moderate), BMI and charges (moderate). Other variables show weak correlations."
  },
  {
    "objectID": "R Projects/Health Analysis/HEALTHDATA.html#linear-regression-models-for-predictor-variables",
    "href": "R Projects/Health Analysis/HEALTHDATA.html#linear-regression-models-for-predictor-variables",
    "title": "HEALTH ANALYTICS WITH R",
    "section": "LINEAR REGRESSION MODELS FOR PREDICTOR VARIABLES",
    "text": "LINEAR REGRESSION MODELS FOR PREDICTOR VARIABLES\n\nLINEAR MODEL 1\nThe codeblock below fits a linear regression model to predict charges based on smoker, age and bmi\nDescription:\n\nModel: Predicts charges using smoker, age, and bmi.\nSummary: Provides coefficients, significance, R-squared, and residuals.\n\nThis helps understand how these predictors influence charges.\n\n# Logistic regression models for predictor variables \n# Age, Smoker and BMI  \nlm1&lt;- lm(charges ~ smoker + age + bmi, healthdata) \nsummary(lm1)\n\n\nCall:\nlm(formula = charges ~ smoker + age + bmi, data = healthdata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12415.4  -2970.9   -980.5   1480.0  28971.8 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -35500.51    1060.50  -33.48   &lt;2e-16 ***\nsmoker       23823.68     412.87   57.70   &lt;2e-16 ***\nage            259.55      11.93   21.75   &lt;2e-16 ***\nbmi            322.62      27.49   11.74   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6092 on 1334 degrees of freedom\nMultiple R-squared:  0.7475,    Adjusted R-squared:  0.7469 \nF-statistic:  1316 on 3 and 1334 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nInterpretation of Linear Model 1\n\n\n\nCoefficients:\n\nIntercept: -35500.51\nSmoker: +23823.68 (higher charges for smokers)\nAge: +259.55 (increase per year)\nBMI: +322.62 (increase per unit)\n\nSignificance: All predictors are highly significant (p &lt; 2e-16).\nModel Fit:\n\nR-squared: 0.7475 (74.75% variability explained)\nResidual Standard Error: 6092\n\nConclusion: Smoking, age, and BMI significantly impact charges, with smoking having the largest effect.\n\n\n\n\nLINEAR MODEL 2\nThe codeblock below fits a linear regression model to predict charges based on smoker, age, bmi, children, region, and sex\nDescription:\n\nModel: Predicts charges using smoker, age, bmi, children, region, and sex.\nSummary: Provides coefficients, significance, R-squared, and residuals.\n\n\n  # Logistic regression models for predictor variables \n  # Age, Smoker, children, region, sex and BMI   \n  lm2&lt;- lm(charges ~ smoker + age + bmi + children + region + sex, healthdata) \n  summary(lm2)\n\n\nCall:\nlm(formula = charges ~ smoker + age + bmi + children + region + \n    sex, data = healthdata)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-11343  -2807  -1017   1408  29752 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -35151.14    1174.41 -29.931  &lt; 2e-16 ***\nsmoker       23820.43     411.84  57.839  &lt; 2e-16 ***\nage            257.29      11.89  21.647  &lt; 2e-16 ***\nbmi            332.57      27.72  11.997  &lt; 2e-16 ***\nchildren       479.37     137.64   3.483 0.000513 ***\nregion        -353.64     151.93  -2.328 0.020077 *  \nsex           -131.11     332.81  -0.394 0.693681    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6060 on 1331 degrees of freedom\nMultiple R-squared:  0.7507,    Adjusted R-squared:  0.7496 \nF-statistic: 668.1 on 6 and 1331 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nInterpretation of Linear Model 2\n\n\n\nCoefficients:\n\nSmoker: +23820.43 (higher charges)\nAge: +257.29 (per year)\nBMI: +332.57 (per unit)\nChildren: +479.37 (per child)\nRegion: -353.64 (slight decrease)\nSex: -131.11 (not significant)\n\nSignificance: All predictors except sex are significant.\nModel Fit:\n\nR-squared: 0.7507 (75.07% variability explained)\nResidual Standard Error: 6060\n\nConclusion: Smoking, age, BMI, children, and region significantly impact charges, with smoking having the largest effect.\n\n\n\n\nLINEAR MODEL 3\nThe codeblock below fits a linear regression model to predict charges based on smoker, age, bmi, children and region\n\n# Logistic regression models for predictor variables \n# Age, Smoker, children, region, BMI   \nlm3&lt;- lm(charges ~ smoker + age + bmi + children + region, healthdata) \n\nsummary(lm3)\n\n\nCall:\nlm(formula = charges ~ smoker + age + bmi + children + region, \n    data = healthdata)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-11404  -2805   -992   1400  29694 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -35321.62    1091.42 -32.363  &lt; 2e-16 ***\nsmoker       23808.21     410.54  57.992  &lt; 2e-16 ***\nage            257.41      11.88  21.670  &lt; 2e-16 ***\nbmi            332.04      27.68  11.995  &lt; 2e-16 ***\nchildren       478.44     137.58   3.478 0.000522 ***\nregion        -353.45     151.88  -2.327 0.020104 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6058 on 1332 degrees of freedom\nMultiple R-squared:  0.7507,    Adjusted R-squared:  0.7498 \nF-statistic: 802.2 on 5 and 1332 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nInterpretation of the Linear Regression Model\n\n\n\nCoefficients:\n\nSmoker: +23808.21 (higher charges)\nAge: +257.41 (per year)\nBMI: +332.04 (per unit)\nChildren: +478.44 (per child)\nRegion: -353.45 (slight decrease)\n\nSignificance:\n\nAll predictors are significant (p &lt; 0.05).\n\nModel Fit:\n\nR-squared: 0.7507 (75.07% variability explained)\nResidual Standard Error: 6058\n\nConclusion:\n\nSmoking, age, BMI, children, and region significantly impact charges, with smoking having the largest effect."
  },
  {
    "objectID": "R Projects/Health Analysis/HEALTHDATA.html#residuals-and-fitted-values-for-linear-model-1",
    "href": "R Projects/Health Analysis/HEALTHDATA.html#residuals-and-fitted-values-for-linear-model-1",
    "title": "HEALTH ANALYTICS WITH R",
    "section": "RESIDUALS AND FITTED VALUES FOR LINEAR MODEL 1",
    "text": "RESIDUALS AND FITTED VALUES FOR LINEAR MODEL 1\nThe codeblock below calculates the residuals and fitted values for the linear regression model lm1 and stores them in a data frame:\n\n#Calculate residuals and fitted values for residuals\nresidualslm1&lt;-data.frame(residuals=resid(lm1), Fitted=fitted(lm1))\n\nDescription:\n\nResiduals: Differences between observed and predicted values from lm1.\n\nresid(lm1): Extracts residuals from lm1.\n\nFitted Values: Predicted values from lm1.\n\nfitted(lm1): Extracts fitted values from lm1.\n\n\n\n#Create Visuals for Residuals and Fitted Values  \nggplot(residualslm1, aes(Fitted,residuals))+\n  geom_point(aes(color=\"#004046\")) +\n  geom_hline(yintercept = 0,linetype=\"dashed\",color=\"#004046\")+\n  labs(title = \"Residuals vs Fitted Plot\", x=\"Fitted Values\",y=\"Residuals\")+   theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation of the Residuals vs Fitted Plot\n\n\n\nThe plot visualizes the residuals (differences between observed and predicted values) against the fitted values from your linear regression model.\nKey Observations:\n\nNo Clear Pattern: The residuals are scattered randomly around the horizontal dashed line at zero, indicating no obvious pattern.\nHomoscedasticity: The spread of residuals appears consistent across all fitted values, suggesting constant variance (homoscedasticity).\nOutliers: There are a few points far from the zero line, which might be outliers.\n\nConclusion:\n\nThe random scatter and consistent spread suggest that the model’s assumptions are reasonably met.\nThe lack of a clear pattern indicates that the model does not suffer from major issues like non-linearity.\n\n\n\n\nQ-Q Plot of Residuals\nThe Q-Q plot compares the residuals’ quantiles to a normal distribution’s quantiles.\n\n#QQ Plot of Residuals\nggplot(residualslm1, aes(sample=residuals))+   stat_qq(color=\"#004046\")+   stat_qq_line(color=\"#004046\")+   labs(title = \"Q-Q Plot of Residuals\", x=\"Theoretical Quantiles\",y=\"Sample Quantiles\")+   theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation:\n\n\n\n\nCentral Points: Residuals are approximately normally distributed.\nDeviations at Extremes: More extreme residuals than expected, indicating heavier tails.\n\n\nConclusion:\nThe residuals deviate from normality at the extremes, suggesting potential issues with the model’s assumptions. Consider transformations or alternative models.\n\n\n\n\n\n\n\n\n\nSource file\n\n\n\nAccess source file here"
  },
  {
    "objectID": "R Projects/Health Analysis/HEALTHDATA.html#overall-conclusion",
    "href": "R Projects/Health Analysis/HEALTHDATA.html#overall-conclusion",
    "title": "HEALTH ANALYTICS WITH R",
    "section": "OVERALL CONCLUSION",
    "text": "OVERALL CONCLUSION\nIn this health analytics project, I explored various factors affecting medical charges using a dataset that included variables such as age, BMI, number of children, smoking status, region, and charges. Here’s a summary of our key findings and analyses:\n\nData Visualization:\n\n\nggplot2 was used to create visualizations that highlighted the relationships between different variables. For example, it was observed that smokers tend to have higher medical charges compared to non-smokers.\nThe corrplot package helped to visualize correlations between variables, revealing significant relationships, such as the positive correlation between BMI and charges.\n\n\nData Transformation and Cleaning:\n\n\nUsing dplyr and tidyr, the data was transformed to ensure it was ready for analysis. This creating new variables where necessary.\n\n\nLinear Regression Modeling:\n\n\nLinear regression modeling was performed to predict medical charges based on various predictor variables. The models showed that age, BMI, smoking status, and region are significant predictors of medical charges.\nThe Q-Q plot of residuals indicated that while the central residuals were approximately normally distributed, there were deviations at the extremes, suggesting potential issues with the model’s assumptions.\n\n\nModel Evaluation:\n\n\nI evaluated the model’s performance and identified areas where it could be improved. The deviations in the Q-Q plot suggest that there might be need to consider transformations or alternative models to better fit the data.\n\n\nFINAL THOUGHTS:\nThis analysis provides valuable insights into the factors influencing medical charges. The findings can help in understanding the cost drivers in healthcare and potentially inform policy decisions. Future work could involve exploring non-linear models or other advanced techniques to improve prediction accuracy."
  },
  {
    "objectID": "R Projects/fifa21/FIFA21.html#authornarrator",
    "href": "R Projects/fifa21/FIFA21.html#authornarrator",
    "title": "FIFA 21 Data Wrangling",
    "section": "Club Column",
    "text": "Club Column\nThe Club column contains clubs of respective players and upon examining the column, it is populated with nextline characters “\\n” which leaves the Club column in bad format.\nHere are first 10 observations in the column\n\nfifa21raw %&gt;% select(Club) %&gt;% head(10)\n\n# A tibble: 10 × 1\n   Club                         \n   &lt;chr&gt;                        \n 1 \"\\n\\n\\n\\nFC Barcelona\"       \n 2 \"\\n\\n\\n\\nJuventus\"           \n 3 \"\\n\\n\\n\\nAtlético Madrid\"    \n 4 \"\\n\\n\\n\\nManchester City\"    \n 5 \"\\n\\n\\n\\nParis Saint-Germain\"\n 6 \"\\n\\n\\n\\nFC Bayern München\"  \n 7 \"\\n\\n\\n\\nLiverpool\"          \n 8 \"\\n\\n\\n\\nLiverpool\"          \n 9 \"\\n\\n\\n\\nParis Saint-Germain\"\n10 \"\\n\\n\\n\\nFC Barcelona\"       \n\n\n\n#Removed nextline characters found in the club column\nfifa21raw&lt;-fifa21raw %&gt;% mutate(Club=str_remove_all(Club,\"\\n\"))\n\nThe code chunk above rids the Club column of any nextline characters by use of the str_remove_all()\n\ncheck\nTo crosscheck that the column is clear of any nextline characters:\n\nfifa21raw %&gt;% select(Club) %&gt;% head(10)\n\n# A tibble: 10 × 1\n   Club               \n   &lt;chr&gt;              \n 1 FC Barcelona       \n 2 Juventus           \n 3 Atlético Madrid    \n 4 Manchester City    \n 5 Paris Saint-Germain\n 6 FC Bayern München  \n 7 Liverpool          \n 8 Liverpool          \n 9 Paris Saint-Germain\n10 FC Barcelona"
  },
  {
    "objectID": "R Projects/fifa21/FIFA21.html#contract-column",
    "href": "R Projects/fifa21/FIFA21.html#contract-column",
    "title": "FIFA 21 Data Wrangling",
    "section": "Contract Column",
    "text": "Contract Column\nThe Contract column contains information about the duration of contracts and loan periods for players.\nHere are first 10 observations in the column\n\nfifa21raw %&gt;% select(Contract) \n\n# A tibble: 18,979 × 1\n   Contract   \n   &lt;chr&gt;      \n 1 2004 ~ 2021\n 2 2018 ~ 2022\n 3 2014 ~ 2023\n 4 2015 ~ 2023\n 5 2017 ~ 2022\n 6 2014 ~ 2023\n 7 2017 ~ 2023\n 8 2018 ~ 2024\n 9 2018 ~ 2022\n10 2014 ~ 2022\n# ℹ 18,969 more rows\n\n\n\nfifa21raw&lt;-separate(fifa21raw,col = Contract,into = c(\"start_year\",\"end_year\"),sep = \"~\",remove = F)\n\nfifa21raw&lt;-fifa21raw %&gt;% \n  mutate(Contract_type=case_when(str_detect(start_year,\"Free\")~\"Free\", \n                                 str_detect(start_year,\"On Loan\")~ \"Loan\",\n                                 TRUE~ \"Full-Time\"),\n         start_year=case_when(str_detect(Contract,\"Free\")~ NA_character_,\n                              str_detect(Contract,\"On Loan\")~NA_character_,\n                              TRUE~start_year),\n         end_year=case_when(str_detect(Contract,\"On Loan\")~ str_extract(Contract,\"\\\\d{4}\"),\n                            TRUE~end_year))\n\nfifa21raw &lt;-fifa21raw %&gt;% mutate(across(c(start_year,end_year),as.numeric))\n\nThis code chunk above separates the Contract column into start_year and end_year, classifies contracts as ‘Free’, ‘Loan’, or ‘Full-Time’, handles missing values for start_year and end_year based on contract type, and converts these columns to numeric values for further analysis.\n\ncheck\nTo crosscheck that the new columns are created off the existing column to determine what groups are the players’ Contract_type and all changes effected:\n\nknitr::kable(select(fifa21raw,Contract,Contract_type,start_year,end_year) %&gt;% head(10))\n\n\n\n\nContract\nContract_type\nstart_year\nend_year\n\n\n\n\n2004 ~ 2021\nFull-Time\n2004\n2021\n\n\n2018 ~ 2022\nFull-Time\n2018\n2022\n\n\n2014 ~ 2023\nFull-Time\n2014\n2023\n\n\n2015 ~ 2023\nFull-Time\n2015\n2023\n\n\n2017 ~ 2022\nFull-Time\n2017\n2022\n\n\n2014 ~ 2023\nFull-Time\n2014\n2023\n\n\n2017 ~ 2023\nFull-Time\n2017\n2023\n\n\n2018 ~ 2024\nFull-Time\n2018\n2024\n\n\n2018 ~ 2022\nFull-Time\n2018\n2022\n\n\n2014 ~ 2022\nFull-Time\n2014\n2022"
  },
  {
    "objectID": "R Projects/fifa21/FIFA21.html#height",
    "href": "R Projects/fifa21/FIFA21.html#height",
    "title": "FIFA 21 Data Wrangling",
    "section": "Height",
    "text": "Height\nThe height column comprises of Players’ Height, some in centimeter and some in feet and inches\nsuch as 199cmand \"5'7\\\"\" respectively\n\nknitr::kable(select(fifa21raw,Height) %&gt;% head(10))\n\n\n\n\nHeight\n\n\n\n\n170cm\n\n\n187cm\n\n\n188cm\n\n\n181cm\n\n\n175cm\n\n\n184cm\n\n\n175cm\n\n\n191cm\n\n\n178cm\n\n\n187cm\n\n\n\n\n\nThere is the need to then standardize all height measurements and to ensure all values are in the same unit (centimeters)\n\nconvert_height_fn&lt;-function(Height) {\n  counter&lt;&lt;-1\n  for (row in Height) {\n    if(str_detect(row,\"'\"))\n             {\n               row&lt;-strsplit(row,\"'\")[[1]]\n               feet&lt;-as.numeric(row[[1]])\n               inches&lt;-as.numeric(str_remove(row[[2]],\"\\\"\"))\n               cm&lt;-round(((feet*12)+ inches) * 2.54,digits=0)\n               Height[counter]&lt;-cm\n             }\n           else{\n             Height[counter]&lt;- as.numeric(str_remove(row,\"cm\"))\n           }\n    counter&lt;- counter+1\n  }\n  return(Height)\n  \n}\n\nfifa21raw&lt;- mutate(fifa21raw,Height=as.numeric(convert_height_fn(Height))) %&gt;% \n  rename(height_cm=Height)\n\n\n\n\n\n\n\nThe convert height function\n\n\n\nThis function helps to convert and standardize height values ~ some in feet and inches, and others in centimeters for the purpose of consistency and data quality\n\n\n\ncheck\nTo crosscheck that the height column has been standardized\n\nknitr::kable(select(fifa21raw,height_cm) %&gt;% head(10))\n\n\n\n\nheight_cm\n\n\n\n\n170\n\n\n187\n\n\n188\n\n\n181\n\n\n175\n\n\n184\n\n\n175\n\n\n191\n\n\n178\n\n\n187"
  },
  {
    "objectID": "R Projects/fifa21/FIFA21.html#weight",
    "href": "R Projects/fifa21/FIFA21.html#weight",
    "title": "FIFA 21 Data Wrangling",
    "section": "Weight",
    "text": "Weight\nThe Weight column comprises of Players’ Weight, some in kilogram, some in pounds such as 72kg and 192lbs respectively\n\nknitr::kable(select(fifa21raw,Weight_kg) %&gt;% head(10))\n\n\n\n\nWeight_kg\n\n\n\n\n72kg\n\n\n83kg\n\n\n87kg\n\n\n70kg\n\n\n68kg\n\n\n80kg\n\n\n71kg\n\n\n91kg\n\n\n73kg\n\n\n85kg\n\n\n\n\n\nThere is the need to then standardize all Weight measurements and to ensure all values are in the same unit (centimeters)\n\nconvert_weight_fn&lt;- function(Weight_kg){\n  counter&lt;&lt;-1\n    for (row in Weight_kg) {\n      if (str_detect(row,\"lbs\")) {\n        row&lt;-str_remove(row,\"lbs\")\n        row&lt;- round(as.numeric(row)/2.20462,digits=0)\n        Weight_kg[counter]&lt;-row\n      }\n      else{\n        row&lt;-str_remove(row,\"kg\")\n      row&lt;- as.numeric(row)\n      Weight_kg[counter]&lt;-row\n      }\n      counter&lt;-counter+1\n    }\n return(Weight_kg) \n}\n\nfifa21raw&lt;- mutate(fifa21raw,Weight_kg=as.numeric(convert_weight_fn(Weight_kg)))\n\n\n\n\n\n\n\nThe convert weight function\n\n\n\nThis function helps to convert and standardize weight values ~ some in pounds, kilogram and others in centimeters for the purpose of consistency and data quality\n\n\n\ncheck\nTo crosscheck that the weight column has been standardized\n\nknitr::kable(select(fifa21raw,Weight_kg) %&gt;% head())\n\n\n\n\nWeight_kg\n\n\n\n\n72\n\n\n83\n\n\n87\n\n\n70\n\n\n68\n\n\n80"
  },
  {
    "objectID": "R Projects/fifa21/FIFA21.html#joined-national-column",
    "href": "R Projects/fifa21/FIFA21.html#joined-national-column",
    "title": "FIFA 21 Data Wrangling",
    "section": "Joined National Column",
    "text": "Joined National Column\nThe Joined National column is a character column indicating when a player joined up with the National Team but it ideally should be of date datatype.\nHere’s what it looks like:\n\nfifa21raw%&gt;%select(`Joined_National`)%&gt;%head(10)%&gt;%knitr::kable()\n\n\n\n\nJoined_National\n\n\n\n\nJul 1, 2004\n\n\nJul 10, 2018\n\n\nJul 16, 2014\n\n\nAug 30, 2015\n\n\nAug 3, 2017\n\n\nJul 1, 2014\n\n\nJul 1, 2017\n\n\nJul 19, 2018\n\n\nJul 1, 2018\n\n\nJul 1, 2014\n\n\n\n\n\nIt should be in date format and the code chunk beneath ensures of that.\n\nfifa21raw&lt;-fifa21raw %&gt;% mutate(Joined_National=as.Date(Joined_National,format=\"%b %d, %Y\"))\n\n\ncheck\nTo crosscheck that the Joined National column has been standardized to date data type\n\nfifa21raw %&gt;% select(Joined_National) %&gt;% head(10) %&gt;% knitr::kable()\n\n\n\n\nJoined_National\n\n\n\n\n2004-07-01\n\n\n2018-07-10\n\n\n2014-07-16\n\n\n2015-08-30\n\n\n2017-08-03\n\n\n2014-07-01\n\n\n2017-07-01\n\n\n2018-07-19\n\n\n2018-07-01\n\n\n2014-07-01\n\n\n\n\nstr(fifa21raw$Joined_National)\n\n Date[1:18979], format: \"2004-07-01\" \"2018-07-10\" \"2014-07-16\" \"2015-08-30\" \"2017-08-03\" ..."
  },
  {
    "objectID": "R Projects/fifa21/FIFA21.html#value-wage-and-release-clause-columns",
    "href": "R Projects/fifa21/FIFA21.html#value-wage-and-release-clause-columns",
    "title": "FIFA 21 Data Wrangling",
    "section": "Value, Wage and Release Clause Columns",
    "text": "Value, Wage and Release Clause Columns\nThe Value, Wage and Release Clause columns house the worth of a player in the market, their earnings in their clubs and the fee to be paid to release a player from their contract respectively.\n\n knitr::kable(select(fifa21raw,Value,Wage,`Release Clause`) %&gt;% head(10))\n\n\n\n\nValue\nWage\nRelease Clause\n\n\n\n\n€103.5M\n€560K\n€138.4M\n\n\n€63M\n€220K\n€75.9M\n\n\n€120M\n€125K\n€159.4M\n\n\n€129M\n€370K\n€161M\n\n\n€132M\n€270K\n€166.5M\n\n\n€111M\n€240K\n€132M\n\n\n€120.5M\n€250K\n€144.3M\n\n\n€102M\n€160K\n€120.3M\n\n\n€185.5M\n€160K\n€203.1M\n\n\n€110M\n€260K\n€147.7M\n\n\n\n\n\nUpon close examination, the columns are of character datatype and contain the Euro currency symbol (€). Additionally, they use “M” to represent values in millions and “K” to represent values in thousands.\n\nfifa21raw&lt;-fifa21raw %&gt;% mutate(across(c(Value,Wage,`Release Clause`),\n function(col) {\n   case_when(\n  str_detect(col, \"M\") ~ as.double(str_replace_all(col, \"(€|M)\", \"\")) * 1000000,\n  str_detect(col, \"K\") ~ as.double(str_replace_all(col, \"(€|K)\", \"\")) * 1000,\n  TRUE ~ as.double(str_replace(col, \"€\", \"\")))}))\n\nThis code chunk above processes the value, wage, and release clause columns by removing currency symbols and suffixes, removing non-numeric characters and converting to numeric values.\n\ncheck\nTo crosscheck that the columns have been appropriately processed (cleaned of currency, millions and thousands symbols and converted to numeric values):\n\nknitr::kable(select(fifa21raw,Value,`Release Clause`,Wage) %&gt;% head(10))\n\n\n\n\nValue\nRelease Clause\nWage\n\n\n\n\n103500000\n138400000\n560000\n\n\n63000000\n75900000\n220000\n\n\n120000000\n159400000\n125000\n\n\n129000000\n161000000\n370000\n\n\n132000000\n166500000\n270000\n\n\n111000000\n132000000\n240000\n\n\n120500000\n144300000\n250000\n\n\n102000000\n120300000\n160000\n\n\n185500000\n203100000\n160000\n\n\n110000000\n147700000\n260000"
  },
  {
    "objectID": "R Projects/fifa21/FIFA21.html#weak-foot-skill-move-and-injury-rating-columns",
    "href": "R Projects/fifa21/FIFA21.html#weak-foot-skill-move-and-injury-rating-columns",
    "title": "FIFA 21 Data Wrangling",
    "section": "Weak Foot, Skill Move and Injury Rating Columns",
    "text": "Weak Foot, Skill Move and Injury Rating Columns\nThe Weak Foot, Skill Moves, and Injury Rating columns collectively provide insights into a player’s technical skills and physical resilience. The Weak Foot rating (1 to 5 stars) shows proficiency with the non-dominant foot, enhancing versatility. The Skill Moves rating (1 to 5 stars) reflects the ability to perform complex dribbles. The Injury Rating (1 to 5 stars) indicates susceptibility to injuries, with lower ratings suggesting better durability.\nA peek at some of the observations in these columns is as below:\n\nfifa21raw %&gt;% select(WeakFootRating,Skill_Moves,InjuryRating) %&gt;% head(5) %&gt;% knitr::kable()\n\n\n\n\nWeakFootRating\nSkill_Moves\nInjuryRating\n\n\n\n\n4 ★\n4★\n5 ★\n\n\n4 ★\n5★\n5 ★\n\n\n3 ★\n1★\n3 ★\n\n\n5 ★\n4★\n4 ★\n\n\n5 ★\n5★\n5 ★\n\n\n\n\n\nThey have similar inconsistency, hence the need to treat them altogether:\n\nfifa21raw &lt;- fifa21raw %&gt;%\n  mutate(across(c(WeakFootRating, Skill_Moves, InjuryRating), \n            ~ if_else(str_detect(., \"★\"), \n                      as.numeric(str_remove(., \"★\")), \n                      as.numeric(.))\n  ))\n\n\ncheck\nTo crosscheck that the columns are clear of the star symbol (★):\n\nfifa21raw %&gt;%select(WeakFootRating,Skill_Moves,InjuryRating) %&gt;% head(5) %&gt;% knitr::kable()\n\n\n\n\nWeakFootRating\nSkill_Moves\nInjuryRating\n\n\n\n\n4\n4\n5\n\n\n4\n5\n5\n\n\n3\n1\n3\n\n\n5\n4\n4\n\n\n5\n5\n5"
  },
  {
    "objectID": "R Projects/fifa21/FIFA21.html#sub-setting-columns",
    "href": "R Projects/fifa21/FIFA21.html#sub-setting-columns",
    "title": "FIFA 21 Data Wrangling",
    "section": "Sub-setting Columns",
    "text": "Sub-setting Columns\nThis is important so as to focus on relevant data and to be rid of unnecessary columns.\n\nfifa21raw &lt;- fifa21raw %&gt;%\n  select(ID:Contract, Contract_type, Positions, height_cm, Weight_kg, `Preferred Foot`:Hits)  \n\n\nfifa21raw %&gt;% select(ID:Hits)%&gt;% head(10) %&gt;% knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nID\nName\nLongName\nphotoUrl\nplayerUrl\nNationality\nAge\nOverall_Analysis\nPlayerPotential\nClub\nContract\nContract_type\nPositions\nheight_cm\nWeight_kg\nPreferred Foot\nBest_Overall\nBest Position\nJoined_National\nLoan Date End\nValue\nWage\nRelease Clause\nAttacking\nCrossing\nFinishing\nHeading Accuracy\nShort Passing\nVolleys\nSkill\nDribbling\nCurve\nFK Accuracy\nLong Passing\nBall Control\nMovement\nAcceleration\nSprint Speed\nAgility\nReactions\nBalance\nPower\nShot Power\nJumping\nStamina\nStrength\nLong Shots\nMentality\nAggression\nInterceptions\nPositioning\nVision\nPenalties\nComposure\nDefending\nMarking\nStanding Tackle\nSliding Tackle\nGoalkeeping\nGK Diving\nGK Handling\nGK Kicking\nGK Positioning\nGK Reflexes\nTotal Stats\nBase Stats\nWeakFootRating\nSkill_Moves\nAttackingWorkRate\nDefensiveWorkRate\nInjuryRating\nPace\nShooting\nPAS\nDRI\nDEF\nPHY\nHits\n\n\n\n\n158023\nL. Messi\nLionel Messi\nhttps://cdn.sofifa.com/players/158/023/21_60.png\nhttp://sofifa.com/player/158023/lionel-messi/210006/\nArgentina\n33\n93\n93\nFC Barcelona\n2004 ~ 2021\nFull-Time\nRW, ST, CF\n170\n72\nLeft\n93\nRW\n2004-07-01\nNA\n103500000\n560000\n138400000\n429\n85\n95\n70\n91\n88\n470\n96\n93\n94\n91\n96\n451\n91\n80\n91\n94\n95\n389\n86\n68\n72\n69\n94\n347\n44\n40\n93\n95\n75\n96\n91\n32\n35\n24\n54\n6\n11\n15\n14\n8\n2231\n466\n4\n4\nMedium\nLow\n5\n85\n92\n91\n95\n38\n65\n771\n\n\n20801\nCristiano Ronaldo\nC. Ronaldo dos Santos Aveiro\nhttps://cdn.sofifa.com/players/020/801/21_60.png\nhttp://sofifa.com/player/20801/c-ronaldo-dos-santos-aveiro/210006/\nPortugal\n35\n92\n92\nJuventus\n2018 ~ 2022\nFull-Time\nST, LW\n187\n83\nRight\n92\nST\n2018-07-10\nNA\n63000000\n220000\n75900000\n437\n84\n95\n90\n82\n86\n414\n88\n81\n76\n77\n92\n431\n87\n91\n87\n95\n71\n444\n94\n95\n84\n78\n93\n353\n63\n29\n95\n82\n84\n95\n84\n28\n32\n24\n58\n7\n11\n15\n14\n11\n2221\n464\n4\n5\nHigh\nLow\n5\n89\n93\n81\n89\n35\n77\n562\n\n\n200389\nJ. Oblak\nJan Oblak\nhttps://cdn.sofifa.com/players/200/389/21_60.png\nhttp://sofifa.com/player/200389/jan-oblak/210006/\nSlovenia\n27\n91\n93\nAtlético Madrid\n2014 ~ 2023\nFull-Time\nGK\n188\n87\nRight\n91\nGK\n2014-07-16\nNA\n120000000\n125000\n159400000\n95\n13\n11\n15\n43\n13\n109\n12\n13\n14\n40\n30\n307\n43\n60\n67\n88\n49\n268\n59\n78\n41\n78\n12\n140\n34\n19\n11\n65\n11\n68\n57\n27\n12\n18\n437\n87\n92\n78\n90\n90\n1413\n489\n3\n1\nMedium\nMedium\n3\n87\n92\n78\n90\n52\n90\n150\n\n\n192985\nK. De Bruyne\nKevin De Bruyne\nhttps://cdn.sofifa.com/players/192/985/21_60.png\nhttp://sofifa.com/player/192985/kevin-de-bruyne/210006/\nBelgium\n29\n91\n91\nManchester City\n2015 ~ 2023\nFull-Time\nCAM, CM\n181\n70\nRight\n91\nCAM\n2015-08-30\nNA\n129000000\n370000\n161000000\n407\n94\n82\n55\n94\n82\n441\n88\n85\n83\n93\n92\n398\n77\n76\n78\n91\n76\n408\n91\n63\n89\n74\n91\n408\n76\n66\n88\n94\n84\n91\n186\n68\n65\n53\n56\n15\n13\n5\n10\n13\n2304\n485\n5\n4\nHigh\nHigh\n4\n76\n86\n93\n88\n64\n78\n207\n\n\n190871\nNeymar Jr\nNeymar da Silva Santos Jr.\nhttps://cdn.sofifa.com/players/190/871/21_60.png\nhttp://sofifa.com/player/190871/neymar-da-silva-santos-jr/210006/\nBrazil\n28\n91\n91\nParis Saint-Germain\n2017 ~ 2022\nFull-Time\nLW, CAM\n175\n68\nRight\n91\nLW\n2017-08-03\nNA\n132000000\n270000\n166500000\n408\n85\n87\n62\n87\n87\n448\n95\n88\n89\n81\n95\n453\n94\n89\n96\n91\n83\n357\n80\n62\n81\n50\n84\n356\n51\n36\n87\n90\n92\n93\n94\n35\n30\n29\n59\n9\n9\n15\n15\n11\n2175\n451\n5\n5\nHigh\nMedium\n5\n91\n85\n86\n94\n36\n59\n595\n\n\n188545\nR. Lewandowski\nRobert Lewandowski\nhttps://cdn.sofifa.com/players/188/545/21_60.png\nhttp://sofifa.com/player/188545/robert-lewandowski/210006/\nPoland\n31\n91\n91\nFC Bayern München\n2014 ~ 2023\nFull-Time\nST\n184\n80\nRight\n91\nST\n2014-07-01\nNA\n111000000\n240000\n132000000\n423\n71\n94\n85\n84\n89\n407\n85\n79\n85\n70\n88\n407\n77\n78\n77\n93\n82\n420\n89\n84\n76\n86\n85\n391\n81\n49\n94\n79\n88\n88\n96\n35\n42\n19\n51\n15\n6\n12\n8\n10\n2195\n457\n4\n4\nHigh\nMedium\n4\n78\n91\n78\n85\n43\n82\n248\n\n\n209331\nM. Salah\nMohamed Salah\nhttps://cdn.sofifa.com/players/209/331/21_60.png\nhttp://sofifa.com/player/209331/mohamed-salah/210006/\nEgypt\n28\n90\n90\nLiverpool\n2017 ~ 2023\nFull-Time\nRW\n175\n71\nLeft\n90\nRW\n2017-07-01\nNA\n120500000\n250000\n144300000\n392\n79\n91\n59\n84\n79\n406\n90\n83\n69\n75\n89\n460\n94\n92\n91\n92\n91\n393\n80\n69\n85\n75\n84\n376\n63\n55\n91\n84\n83\n90\n122\n38\n43\n41\n62\n14\n14\n9\n11\n14\n2211\n470\n3\n4\nHigh\nMedium\n3\n93\n86\n81\n90\n45\n75\n246\n\n\n212831\nAlisson\nAlisson Ramses Becker\nhttps://cdn.sofifa.com/players/212/831/21_60.png\nhttp://sofifa.com/player/212831/alisson-ramses-becker/210006/\nBrazil\n27\n90\n91\nLiverpool\n2018 ~ 2024\nFull-Time\nGK\n191\n91\nRight\n90\nGK\n2018-07-19\nNA\n102000000\n160000\n120300000\n114\n17\n13\n19\n45\n20\n138\n27\n19\n18\n44\n30\n268\n56\n47\n40\n88\n37\n240\n64\n52\n32\n78\n14\n140\n27\n11\n13\n66\n23\n65\n50\n15\n19\n16\n439\n86\n88\n85\n91\n89\n1389\n490\n3\n1\nMedium\nMedium\n3\n86\n88\n85\n89\n51\n91\n120\n\n\n231747\nK. Mbappé\nKylian Mbappé\nhttps://cdn.sofifa.com/players/231/747/21_60.png\nhttp://sofifa.com/player/231747/kylian-mbappe/210006/\nFrance\n21\n90\n95\nParis Saint-Germain\n2018 ~ 2022\nFull-Time\nST, LW, RW\n178\n73\nRight\n91\nST\n2018-07-01\nNA\n185500000\n160000\n203100000\n408\n78\n91\n73\n83\n83\n394\n92\n79\n63\n70\n90\n458\n96\n96\n92\n92\n82\n404\n86\n77\n86\n76\n79\n341\n62\n38\n91\n80\n70\n84\n100\n34\n34\n32\n42\n13\n5\n7\n11\n6\n2147\n466\n4\n5\nHigh\nLow\n3\n96\n86\n78\n91\n39\n76\n1.6K\n\n\n192448\nM. ter Stegen\nMarc-André ter Stegen\nhttps://cdn.sofifa.com/players/192/448/21_60.png\nhttp://sofifa.com/player/192448/marc-andre-ter-stegen/210006/\nGermany\n28\n90\n93\nFC Barcelona\n2014 ~ 2022\nFull-Time\nGK\n187\n85\nRight\n90\nGK\n2014-07-01\nNA\n110000000\n260000\n147700000\n118\n18\n14\n11\n61\n14\n144\n21\n18\n12\n63\n30\n254\n38\n50\n37\n86\n43\n268\n66\n79\n35\n78\n10\n171\n43\n22\n11\n70\n25\n70\n48\n25\n13\n10\n439\n88\n85\n88\n88\n90\n1442\n484\n4\n1\nMedium\nMedium\n3\n88\n85\n88\n90\n45\n88\n130"
  },
  {
    "objectID": "R Projects/fifa21/FIFA21.html#saving-wrangled-data",
    "href": "R Projects/fifa21/FIFA21.html#saving-wrangled-data",
    "title": "FIFA 21 Data Wrangling",
    "section": "Saving Wrangled Data",
    "text": "Saving Wrangled Data\n\nwrite_csv(as.data.frame(fifa21raw),\"fifa21_cleaned.csv\")\n\n\n\n\n\n\n\nDataset and Source Code\n\n\n\nYou can access dataset here and source code here"
  },
  {
    "objectID": "R Projects/fifa21/FIFA21.html#conclusion",
    "href": "R Projects/fifa21/FIFA21.html#conclusion",
    "title": "FIFA 21 Data Wrangling",
    "section": "Conclusion",
    "text": "Conclusion\nIn this project, the FIFA 21 dataset was successfully wrangled by cleaning, transforming, and structuring the data. This process ensured the dataset was accurate, consistent, and ready for analysis. The cleaned data can now be used for various analytical tasks, providing valuable insights into player performance and team comparisons."
  }
]